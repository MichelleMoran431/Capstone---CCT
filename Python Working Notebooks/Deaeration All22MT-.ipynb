{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2fe209-8501-48ee-b35f-0b7d888f16c9",
   "metadata": {},
   "source": [
    "### Deaeration for Tanks 22MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351e04f5-c156-43f5-b04f-7aa88e1e6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac75ad5-8489-43d2-a1c5-a7912cb763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a42ef6-82d3-4d16-a479-1f451969c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>9482</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>TAKE A SAMPLE AND SUBMIT FOR QA.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:43</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>9483</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>08/05/2022 11:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>9484</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>STEP8_AGITATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>9485</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S4_BATCH_COMPLETE_QA_PENDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>9486</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S7_RELEASED_TO_FILLING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9487 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Material    BATCHID  Tank_1  \\\n",
       "0              0   1002150  107643491    2503   \n",
       "1              1   1002150  107643491    2503   \n",
       "2              2   1002150  107643491    2503   \n",
       "3              3   1002150  107643491    2503   \n",
       "4              4   1002150  107643491    2503   \n",
       "...          ...       ...        ...     ...   \n",
       "9482        9482   3055706  107737576    2502   \n",
       "9483        9483   3055706  107737576    2502   \n",
       "9484        9484   3055706  107737576    2502   \n",
       "9485        9485   3055706  107737576    2502   \n",
       "9486        9486   3055706  107737576    2502   \n",
       "\n",
       "                                   Instruction_Step INGRED_ID  \\\n",
       "0                              S3_BATCH_IN_PROGRESS       NaN   \n",
       "1                                        STEP1_CONS   1002565   \n",
       "2                       PLEASE VERIFY BULK ADDITION       NaN   \n",
       "3                                        STEP1_CONS   1037802   \n",
       "4                                        STEP1_CONS   1002818   \n",
       "...                                             ...       ...   \n",
       "9482               TAKE A SAMPLE AND SUBMIT FOR QA.       NaN   \n",
       "9483  SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)       NaN   \n",
       "9484                                STEP8_AGITATION       NaN   \n",
       "9485                   S4_BATCH_COMPLETE_QA_PENDING       NaN   \n",
       "9486                         S7_RELEASED_TO_FILLING       NaN   \n",
       "\n",
       "                               INGRED_Name  Quantity       Phase_start  \\\n",
       "0                                      NaN     0.000  09/03/2022 10:42   \n",
       "1                            WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2                                      NaN     0.000  09/03/2022 11:16   \n",
       "3     S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4     S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "...                                    ...       ...               ...   \n",
       "9482                                   NaN     0.000  08/05/2022 11:43   \n",
       "9483                                   NaN     0.000  08/05/2022 11:54   \n",
       "9484                                   NaN     0.000  08/05/2022 11:56   \n",
       "9485                                   NaN     0.000  08/05/2022 11:56   \n",
       "9486                                   NaN     0.000  08/05/2022 12:02   \n",
       "\n",
       "             Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0     09/03/2022 10:42               0                  0             1   \n",
       "1     09/03/2022 11:16              34                  0             2   \n",
       "2     09/03/2022 11:17               1                  0             3   \n",
       "3     09/03/2022 11:27              10                  0             4   \n",
       "4     09/03/2022 11:38              11                  0             5   \n",
       "...                ...             ...                ...           ...   \n",
       "9482  08/05/2022 11:54              11                  0            19   \n",
       "9483  08/05/2022 11:55               1                  0            20   \n",
       "9484  08/05/2022 11:56               0                  1            21   \n",
       "9485  08/05/2022 11:56               0                  0            22   \n",
       "9486  08/05/2022 12:02               0                  6            23   \n",
       "\n",
       "      Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0             0.0000              NaN                      0            NaN   \n",
       "1           169.4118         733.5050                      8           26.0   \n",
       "2             0.0000              NaN                      3            0.0   \n",
       "3             0.5629           6.3182                      1            9.0   \n",
       "4             7.1605           6.3182                     12            0.0   \n",
       "...              ...              ...                    ...            ...   \n",
       "9482          0.0000              NaN                     10            1.0   \n",
       "9483          0.0000              NaN                     10            0.0   \n",
       "9484          0.0000              NaN                      0            0.0   \n",
       "9485          0.0000              NaN                      0            NaN   \n",
       "9486          0.0000              NaN                     14            0.0   \n",
       "\n",
       "      Deaeration Phase  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "9482                 0  \n",
       "9483                 0  \n",
       "9484                 0  \n",
       "9485                 0  \n",
       "9486                 0  \n",
       "\n",
       "[9487 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf73d0c-7499-465d-8d22-5701d012c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29eb9da9-262d-406d-ba7a-38815a02423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Data = pd.DataFrame(ProductionTank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3327649b-010d-47d2-9241-b9bd93cd5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.replace(\"STEP2_CONS\", \n",
    "           \"STEP2_CONS-Deaeration\", \n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d862f7-a2d3-472d-87b3-1b3f350b6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction_Step     25\n",
      "Phase_start_delay     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Data[['Instruction_Step', 'Phase_start_delay']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e97f96b8-b75f-4036-8ea4-94bf7318ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = Data[Data['Instruction_Step'] == 'STEP2_CONS-Deaeration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268b431-79ca-455f-8f1b-7ebf01ae0b4d",
   "metadata": {},
   "source": [
    "#### Exploring the different deaeration times ( start Phase delay duration) for each of the groups of productions tanks and their common materials "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ec279-fc68-4b75-ad24-25f8e25665fb",
   "metadata": {},
   "source": [
    "#### Deaeration in  Production Tanks : '2202', '2203', '2204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4c09b9-f558-4a64-9b0d-423f998d4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanks_in_group1 = [2202, 2203, 2204]\n",
    "instruction_step_of_interest = 'STEP2_CONS-Deaeration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753d659e-387e-4571-94d1-6b6fcd317ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = Data[(Data['Tank_1'].isin(tanks_in_group1)) & \n",
    "                    (Data['Instruction_Step'] == instruction_step_of_interest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b5ee40-0fdf-4d30-81b4-9ee819779830",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_materials = filtered_data.groupby('Material').filter(lambda x: x['Tank_1'].nunique() == len(tanks_in_group1))['Material'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d032e018-1612-4023-b084-a98a797e4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data1 = filtered_data[filtered_data['Material'].isin(common_materials)]\n",
    "#filtered_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c373d248-daee-42cb-95cb-a27ca471c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'BATCHID','Instruction_Step'])['Phase_duration'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f4796b7-633c-4f6c-ab54-68e63139dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=filtered_data, x='Material', y='Phase_start_delay', hue='Tank_1', ci=None)\n",
    "\n",
    "plt.title('Phase_start_delay for ALL Materials during Deaeration Phase Across 22MT Tanks')\n",
    "plt.ylabel('Phase_start_delay')\n",
    "plt.xlabel('Material')\n",
    "plt.legend(title='Tank_1', loc='upper right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4f8229b-87ff-4d87-8131-2d4512ac1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=filtered_data1, x='Material', y='Phase_start_delay', hue='Tank_1', ci=None)\n",
    "\n",
    "plt.title('Phase_start_delay for Common Materials during Deaeration Phase Across 22MT Tanks')\n",
    "plt.ylabel('Phase_start_delay')\n",
    "plt.xlabel('Material')\n",
    "plt.legend(title='Tank_1', loc='upper right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f53f8-38a7-40f4-b42a-7607205f32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e33d6366-beb5-41e8-ac7f-639bc9e1bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredient_of_interest = ['1461896', '1254972','1031006','1243269','1196706','1815609']\n",
    "#ingredient_data = data[data['INGRED_ID'] == ingredient_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00cc340d-2365-4260-ad2b-13912e94dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Tank_1, BATCHID, Instruction_Step, Phase_start_delay]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = ['2202', '2203', '2204']\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP2_CONS-Deaeration']\n",
    "filtered_data = Data[(Data['Instruction_Step'].isin(desired_steps)) & (Data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_Phase_start_delay = filtered_data.groupby(['Tank_1','BATCHID','Instruction_Step'])['Phase_start_delay'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID','Material']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "#print(aggregated_total_durations_df2)\n",
    "print(total_Phase_start_delay)\n",
    "\n",
    "\n",
    "aggregated_total_durations_df2.to_csv('DeaerationPhase22MT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea720dac-c31d-41ba-8be7-c425a58ae6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2202  107867810   1648637              31           11.0   \n",
      "1     2202  107899926   1775253              26            6.0   \n",
      "2     2202  107956670   1397022              11            0.0   \n",
      "3     2202  107963677   1775253              70           50.0   \n",
      "4     2202  107964410   1775253              85           65.0   \n",
      "5     2202  107978116   1648637              16            3.0   \n",
      "6     2202  107999494   1775253              95           75.0   \n",
      "7     2202  108026759   1775253              28            9.0   \n",
      "8     2202  108033603   1428047              71           41.0   \n",
      "9     2202  108045117   1520984              32           20.0   \n",
      "10    2202  108073632   1451704              23            2.0   \n",
      "11    2203  107963676   1775253              59           39.0   \n",
      "12    2203  107971404   1520984              16            4.0   \n",
      "13    2203  107978117   1775253              25            5.0   \n",
      "14    2203  107999492   1428047              10            0.0   \n",
      "15    2203  108015838   1397022              22            6.0   \n",
      "16    2203  108030821   1451710              16            0.0   \n",
      "17    2203  108033608   1520984              23           11.0   \n",
      "18    2203  108042636   1775253              31           11.0   \n",
      "19    2203  108051514   1775253              84           64.0   \n",
      "20    2203  108059029   1698522              39           15.0   \n",
      "21    2203  108067819   1648637              25            7.0   \n",
      "22    2203  108073631   1428047              35            5.0   \n",
      "23    2204  107862335   1698522              78           58.0   \n",
      "24    2204  107872112   1520984              12            0.0   \n",
      "25    2204  107899925   1775253              25            6.0   \n",
      "26    2204  107907563   1428047               8            0.0   \n",
      "27    2204  107915806   1698522              11            0.0   \n",
      "28    2204  107925352   1520984              55           43.0   \n",
      "29    2204  107969769   1397022              92           74.0   \n",
      "30    2204  107978118   1775253              37           17.0   \n",
      "31    2204  107992045   1520984              60           48.0   \n",
      "32    2204  107999493   1775253              23            3.0   \n",
      "33    2204  108015839   1397022              23            0.0   \n",
      "34    2204  108026760   1775253              55           34.0   \n",
      "35    2204  108042635   1775253               7            0.0   \n",
      "36    2204  108075449   1428047              32            5.0   \n",
      "37    2204  108084749   1567195              38           12.0   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0                2144  1303.000         86.2927                   10.0   \n",
      "1                2175  1633.600        126.4238                   10.0   \n",
      "2                4691  2050.800        186.4364                   26.0   \n",
      "3                5297  1630.000         47.5417                   10.0   \n",
      "4                2863  1631.800         39.9932                   10.0   \n",
      "5                4169  1305.300        267.8436                   10.0   \n",
      "6                2778  1632.200         37.3960                   10.0   \n",
      "7                3489  1631.700        133.5865                   10.0   \n",
      "8                2573  2434.000        108.6360                   10.0   \n",
      "9                3227   910.022         28.4382                   12.0   \n",
      "10               4249   990.600         87.6346                   11.0   \n",
      "11               5376  1632.000         91.1818                   10.0   \n",
      "12               2181   909.100         56.8188                   12.0   \n",
      "13               2206  1629.900        130.6013                   10.0   \n",
      "14               2786  2436.600        243.6600                   31.0   \n",
      "15               3597  1233.000        129.1333                    9.0   \n",
      "16                150  1525.000         95.3125                   19.0   \n",
      "17               5258   910.331         39.5796                   12.0   \n",
      "18               3523  1632.200        106.3012                   10.0   \n",
      "19               3871  1631.600         51.7968                   10.0   \n",
      "20               4511  1878.400         97.9380                   12.0   \n",
      "21               4753  1307.300        120.1926                   10.0   \n",
      "22               2611  2432.400        212.7059                   10.0   \n",
      "23               5225  1880.000        130.9286                   12.0   \n",
      "24                 25   909.001         75.7501                   12.0   \n",
      "25               1840  1631.316        141.6073                   10.0   \n",
      "26               2343  2437.900        304.7375                   31.0   \n",
      "27               4882  1878.400        170.7636                   24.0   \n",
      "28               4091   909.100         16.5291                   12.0   \n",
      "29               4379  1231.000         30.9921                    9.0   \n",
      "30               2190  1632.500         93.7745                   10.0   \n",
      "31               3946   909.900         15.1650                   12.0   \n",
      "32               2903  1632.500        142.2341                   10.0   \n",
      "33               3437  2052.400        173.6731                   13.5   \n",
      "34               3097  1632.000         29.6727                   21.0   \n",
      "35               3490  1631.700        233.1000                   21.0   \n",
      "36               2073  2436.400        247.8266                   10.0   \n",
      "37               5268  2447.800        139.0784                   15.5   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0           65.4124  \n",
      "1           79.0160  \n",
      "2           79.0160  \n",
      "3           79.0160  \n",
      "4           79.0160  \n",
      "5           65.4124  \n",
      "6           79.0160  \n",
      "7           79.0160  \n",
      "8           79.0160  \n",
      "9           79.0160  \n",
      "10          45.2833  \n",
      "11          79.0160  \n",
      "12          79.0160  \n",
      "13          79.0160  \n",
      "14          79.0160  \n",
      "15          65.4124  \n",
      "16          79.0160  \n",
      "17          79.0160  \n",
      "18          79.0160  \n",
      "19          79.0160  \n",
      "20          79.0160  \n",
      "21          65.4124  \n",
      "22          79.0160  \n",
      "23          79.0160  \n",
      "24          79.0160  \n",
      "25          79.0160  \n",
      "26          79.0160  \n",
      "27          79.0160  \n",
      "28          79.0160  \n",
      "29          65.4124  \n",
      "30          79.0160  \n",
      "31          79.0160  \n",
      "32          79.0160  \n",
      "33          72.2142  \n",
      "34          79.0160  \n",
      "35          79.0160  \n",
      "36          79.0160  \n",
      "37          79.0160  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = [2202, 2203, 2204]\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP2_CONS-Deaeration']\n",
    "filtered_data = Data[(Data['Instruction_Step'].isin(desired_steps)) & (Data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_Phase_start_delay = filtered_data.groupby(['Tank_1','Material','Instruction_Step'])['Phase_start_delay'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID','Material']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "print(aggregated_total_durations_df2)\n",
    "aggregated_total_durations_df2.to_csv('DeaerationPhase22MT1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c827824-d055-4ce5-a232-697b9b4bddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "#aggregated_total_durations_df2.dropna(inplace=True)  # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1dd2246-274f-43c0-8e34-ce1380e376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling du# Handling duplicates\n",
    "#aggregated_total_durations_df2.drop_duplicates(inplace=True)  # Remove duplicate rowsplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff37f00e-5bfc-4898-9d25-43652b4b4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2202  107867810   1648637              31           11.0   \n",
      "1     2202  107899926   1775253              26            6.0   \n",
      "3     2202  107963677   1775253              70           50.0   \n",
      "4     2202  107964410   1775253              85           65.0   \n",
      "5     2202  107978116   1648637              16            3.0   \n",
      "6     2202  107999494   1775253              95           75.0   \n",
      "7     2202  108026759   1775253              28            9.0   \n",
      "8     2202  108033603   1428047              71           41.0   \n",
      "9     2202  108045117   1520984              32           20.0   \n",
      "10    2202  108073632   1451704              23            2.0   \n",
      "11    2203  107963676   1775253              59           39.0   \n",
      "12    2203  107971404   1520984              16            4.0   \n",
      "13    2203  107978117   1775253              25            5.0   \n",
      "15    2203  108015838   1397022              22            6.0   \n",
      "17    2203  108033608   1520984              23           11.0   \n",
      "18    2203  108042636   1775253              31           11.0   \n",
      "19    2203  108051514   1775253              84           64.0   \n",
      "20    2203  108059029   1698522              39           15.0   \n",
      "21    2203  108067819   1648637              25            7.0   \n",
      "22    2203  108073631   1428047              35            5.0   \n",
      "23    2204  107862335   1698522              78           58.0   \n",
      "24    2204  107872112   1520984              12            0.0   \n",
      "25    2204  107899925   1775253              25            6.0   \n",
      "28    2204  107925352   1520984              55           43.0   \n",
      "29    2204  107969769   1397022              92           74.0   \n",
      "30    2204  107978118   1775253              37           17.0   \n",
      "31    2204  107992045   1520984              60           48.0   \n",
      "32    2204  107999493   1775253              23            3.0   \n",
      "33    2204  108015839   1397022              23            0.0   \n",
      "36    2204  108075449   1428047              32            5.0   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0                2144  1303.000         86.2927                   10.0   \n",
      "1                2175  1633.600        126.4238                   10.0   \n",
      "3                5297  1630.000         47.5417                   10.0   \n",
      "4                2863  1631.800         39.9932                   10.0   \n",
      "5                4169  1305.300        267.8436                   10.0   \n",
      "6                2778  1632.200         37.3960                   10.0   \n",
      "7                3489  1631.700        133.5865                   10.0   \n",
      "8                2573  2434.000        108.6360                   10.0   \n",
      "9                3227   910.022         28.4382                   12.0   \n",
      "10               4249   990.600         87.6346                   11.0   \n",
      "11               5376  1632.000         91.1818                   10.0   \n",
      "12               2181   909.100         56.8188                   12.0   \n",
      "13               2206  1629.900        130.6013                   10.0   \n",
      "15               3597  1233.000        129.1333                    9.0   \n",
      "17               5258   910.331         39.5796                   12.0   \n",
      "18               3523  1632.200        106.3012                   10.0   \n",
      "19               3871  1631.600         51.7968                   10.0   \n",
      "20               4511  1878.400         97.9380                   12.0   \n",
      "21               4753  1307.300        120.1926                   10.0   \n",
      "22               2611  2432.400        212.7059                   10.0   \n",
      "23               5225  1880.000        130.9286                   12.0   \n",
      "24                 25   909.001         75.7501                   12.0   \n",
      "25               1840  1631.316        141.6073                   10.0   \n",
      "28               4091   909.100         16.5291                   12.0   \n",
      "29               4379  1231.000         30.9921                    9.0   \n",
      "30               2190  1632.500         93.7745                   10.0   \n",
      "31               3946   909.900         15.1650                   12.0   \n",
      "32               2903  1632.500        142.2341                   10.0   \n",
      "33               3437  2052.400        173.6731                   13.5   \n",
      "36               2073  2436.400        247.8266                   10.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0           65.4124  \n",
      "1           79.0160  \n",
      "3           79.0160  \n",
      "4           79.0160  \n",
      "5           65.4124  \n",
      "6           79.0160  \n",
      "7           79.0160  \n",
      "8           79.0160  \n",
      "9           79.0160  \n",
      "10          45.2833  \n",
      "11          79.0160  \n",
      "12          79.0160  \n",
      "13          79.0160  \n",
      "15          65.4124  \n",
      "17          79.0160  \n",
      "18          79.0160  \n",
      "19          79.0160  \n",
      "20          79.0160  \n",
      "21          65.4124  \n",
      "22          79.0160  \n",
      "23          79.0160  \n",
      "24          79.0160  \n",
      "25          79.0160  \n",
      "28          79.0160  \n",
      "29          65.4124  \n",
      "30          79.0160  \n",
      "31          79.0160  \n",
      "32          79.0160  \n",
      "33          72.2142  \n",
      "36          79.0160  \n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank22_df = pd.DataFrame(aggregated_total_durations_df2)\n",
    "ProductionTank22_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "  ProductionTank22_df = remove_outliers_iqr(ProductionTank22_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ea6a804-d22e-41f5-9e07-92934bbc8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2202  107867810   1648637       -0.459676      -0.510499   \n",
      "1     2202  107899926   1775253       -0.660701      -0.715793   \n",
      "3     2202  107963677   1775253        1.108315       1.090798   \n",
      "4     2202  107964410   1775253        1.711389       1.706681   \n",
      "5     2202  107978116   1648637       -1.062750      -0.838970   \n",
      "6     2202  107999494   1775253        2.113438       2.117270   \n",
      "7     2202  108026759   1775253       -0.580291      -0.592617   \n",
      "8     2202  108033603   1428047        1.148520       0.721268   \n",
      "9     2202  108045117   1520984       -0.419471      -0.140969   \n",
      "10    2202  108073632   1451704       -0.781315      -0.880029   \n",
      "11    2203  107963676   1775253        0.666061       0.639150   \n",
      "12    2203  107971404   1520984       -1.062750      -0.797911   \n",
      "13    2203  107978117   1775253       -0.700906      -0.756852   \n",
      "15    2203  108015838   1397022       -0.821520      -0.715793   \n",
      "17    2203  108033608   1520984       -0.781315      -0.510499   \n",
      "18    2203  108042636   1775253       -0.459676      -0.510499   \n",
      "19    2203  108051514   1775253        1.671184       1.665622   \n",
      "20    2203  108059029   1698522       -0.138037      -0.346263   \n",
      "21    2203  108067819   1648637       -0.700906      -0.674734   \n",
      "22    2203  108073631   1428047       -0.298856      -0.756852   \n",
      "23    2204  107862335   1698522        1.429954       1.419269   \n",
      "24    2204  107872112   1520984       -1.223569      -0.962147   \n",
      "25    2204  107899925   1775253       -0.700906      -0.715793   \n",
      "28    2204  107925352   1520984        0.505242       0.803386   \n",
      "29    2204  107969769   1397022        1.992823       2.076211   \n",
      "30    2204  107978118   1775253       -0.218447      -0.264145   \n",
      "31    2204  107992045   1520984        0.706266       1.008680   \n",
      "32    2204  107999493   1775253       -0.781315      -0.838970   \n",
      "33    2204  108015839   1397022       -0.781315      -0.962147   \n",
      "36    2204  108075449   1428047       -0.419471      -0.756852   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0           -0.986919  1303.000       -0.253042                   10.0   \n",
      "1           -0.961869  1633.600        0.381987                   10.0   \n",
      "3            1.560916  1630.000       -0.866232                   10.0   \n",
      "4           -0.405919  1631.800       -0.985679                   10.0   \n",
      "5            0.649416  1305.300        2.619794                   10.0   \n",
      "6           -0.474605  1632.200       -1.026777                   10.0   \n",
      "7            0.099931  1631.700        0.495328                   10.0   \n",
      "8           -0.640258  2434.000        0.100515                   10.0   \n",
      "9           -0.111783   910.022       -1.168524                   12.0   \n",
      "10           0.714062   990.600       -0.231808                   11.0   \n",
      "11           1.624753  1632.000       -0.175678                   10.0   \n",
      "12          -0.957021   909.100       -0.719433                   12.0   \n",
      "13          -0.936819  1629.900        0.448091                   10.0   \n",
      "15           0.187202  1233.000        0.424862                    9.0   \n",
      "17           1.529401   910.331       -0.992224                   12.0   \n",
      "18           0.127405  1632.200        0.063570                   10.0   \n",
      "19           0.408612  1631.600       -0.798900                   10.0   \n",
      "20           0.925775  1878.400       -0.068768                   12.0   \n",
      "21           1.121327  1307.300        0.283385                   10.0   \n",
      "22          -0.609552  2432.400        1.747303                   10.0   \n",
      "23           1.502735  1880.000        0.453270                   12.0   \n",
      "24          -2.699213   909.001       -0.419867                   12.0   \n",
      "25          -1.232571  1631.316        0.622248                   10.0   \n",
      "28           0.586387   909.100       -1.356972                   12.0   \n",
      "29           0.819110  1231.000       -1.128111                    9.0   \n",
      "30          -0.949748  1632.500       -0.134651                   10.0   \n",
      "31           0.469217   909.900       -1.378557                   12.0   \n",
      "32          -0.373596  1632.500        0.632167                   10.0   \n",
      "33           0.057911  2052.400        1.129653                   13.5   \n",
      "36          -1.044292  2436.400        2.303048                   10.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0           65.4124  \n",
      "1           79.0160  \n",
      "3           79.0160  \n",
      "4           79.0160  \n",
      "5           65.4124  \n",
      "6           79.0160  \n",
      "7           79.0160  \n",
      "8           79.0160  \n",
      "9           79.0160  \n",
      "10          45.2833  \n",
      "11          79.0160  \n",
      "12          79.0160  \n",
      "13          79.0160  \n",
      "15          65.4124  \n",
      "17          79.0160  \n",
      "18          79.0160  \n",
      "19          79.0160  \n",
      "20          79.0160  \n",
      "21          65.4124  \n",
      "22          79.0160  \n",
      "23          79.0160  \n",
      "24          79.0160  \n",
      "25          79.0160  \n",
      "28          79.0160  \n",
      "29          65.4124  \n",
      "30          79.0160  \n",
      "31          79.0160  \n",
      "32          79.0160  \n",
      "33          72.2142  \n",
      "36          79.0160  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "ProductionTank22_df[numerical_cols] = scaler.fit_transform(ProductionTank22_df[numerical_cols])\n",
    "print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58871e9d-b507-493d-8245-6443bda1dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Summary Statistics:\n",
      "            Tank_1       BATCHID      Material  Phase_duration  Phase_overrun  \\\n",
      "count    38.000000  3.800000e+01  3.800000e+01       38.000000      38.000000   \n",
      "mean   2203.105263  1.079912e+08  1.611049e+06       37.605263      19.710526   \n",
      "std       0.831458  6.267533e+04  1.521669e+05       25.478703      23.713274   \n",
      "min    2202.000000  1.078623e+08  1.397022e+06        7.000000       0.000000   \n",
      "25%    2202.000000  1.079637e+08  1.451706e+06       22.250000       3.000000   \n",
      "50%    2203.000000  1.079995e+08  1.648637e+06       29.500000       8.000000   \n",
      "75%    2204.000000  1.080404e+08  1.775253e+06       55.000000      37.750000   \n",
      "max    2204.000000  1.080847e+08  1.775253e+06       95.000000      75.000000   \n",
      "\n",
      "       Phase_start_delay     Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count          38.000000    38.000000       38.000000              38.000000   \n",
      "mean         3359.657895  1620.072895      117.665189              13.342105   \n",
      "std          1329.774057   482.605189       74.860980               5.950364   \n",
      "min            25.000000   909.001000       15.165000               9.000000   \n",
      "25%          2400.500000  1303.575000       53.052300              10.000000   \n",
      "50%          3463.000000  1631.750000      107.468600              10.000000   \n",
      "75%          4346.500000  1878.400000      142.077400              12.000000   \n",
      "max          5376.000000  2447.800000      304.737500              31.000000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count        38.000000  \n",
      "mean         76.159355  \n",
      "std           6.973605  \n",
      "min          45.283300  \n",
      "25%          79.016000  \n",
      "50%          79.016000  \n",
      "75%          79.016000  \n",
      "max          79.016000  \n",
      "\n",
      "Cleaned DataFrame Summary Statistics:\n",
      "            Tank_1       BATCHID      Material  Phase_duration  Phase_overrun  \\\n",
      "count    30.000000  3.000000e+01  3.000000e+01    3.000000e+01   3.000000e+01   \n",
      "mean   2203.000000  1.079900e+08  1.623294e+06    1.535809e-16  -3.330669e-17   \n",
      "std       0.830455  6.355257e+04  1.497759e+05    1.017095e+00   1.017095e+00   \n",
      "min    2202.000000  1.078623e+08  1.397022e+06   -1.223569e+00  -9.621466e-01   \n",
      "25%    2202.000000  1.079639e+08  1.520984e+06   -7.612129e-01  -7.568521e-01   \n",
      "50%    2203.000000  1.079958e+08  1.648637e+06   -4.395736e-01  -5.104988e-01   \n",
      "75%    2204.000000  1.080404e+08  1.775253e+06    6.962150e-01   7.828561e-01   \n",
      "max    2204.000000  1.080754e+08  1.775253e+06    2.113438e+00   2.117270e+00   \n",
      "\n",
      "       Phase_start_delay    Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count       3.000000e+01    30.00000    3.000000e+01              30.000000   \n",
      "mean       -1.110223e-16  1517.41900    8.881784e-17              10.616667   \n",
      "std         1.017095e+00   455.58556    1.017095e+00               1.111719   \n",
      "min        -2.699213e+00   909.00100   -1.378557e+00               9.000000   \n",
      "25%        -8.626787e-01  1231.50000   -8.493995e-01              10.000000   \n",
      "50%         7.892120e-02  1631.45800   -1.017098e-01              10.000000   \n",
      "75%         6.979004e-01  1632.50000    4.519754e-01              12.000000   \n",
      "max         1.624753e+00  2436.40000    2.619794e+00              13.500000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count        30.000000  \n",
      "mean         75.397583  \n",
      "std           7.693842  \n",
      "min          45.283300  \n",
      "25%          79.016000  \n",
      "50%          79.016000  \n",
      "75%          79.016000  \n",
      "max          79.016000  \n"
     ]
    }
   ],
   "source": [
    "# For the original DataFrame\n",
    "print(\"Original DataFrame Summary Statistics:\")\n",
    "print(aggregated_total_durations_df2.describe())\n",
    "\n",
    "# After removing outliers\n",
    "print(\"\\nCleaned DataFrame Summary Statistics:\")\n",
    "print(ProductionTank22_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32eccb79-e88b-4cd5-baa7-968f0f166525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.00245925  |  0.0192448 |   0.99784  |  0.939671 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.00619192  |  0.0288589 |   0.994561 |  0.909532 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.902454    |  0.392847  |   0.207311 | -0.231506 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.112666    |  0.115539  |   0.901038 |  0.637807 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 0.00724508  |  0.0346595 |   0.993636 |  0.891349 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0.104787    |  0.11294   |   0.907958 |  0.645952 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.00790183  |  0.0480902 |   0.993059 |  0.849246 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.00133291  |  0.0502316 |   0.998829 |  0.842533 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 3.04515e-30 |  0.0279382 |   1        |  0.912418 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank2203_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_start_delay'], axis=1)\n",
    "\n",
    "#y = df['Phase_start_delay']\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Tank_1','BATCHID','Material','Target_Phase_duration','Target_Flowrate','Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "#gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=5, subsample=0.8, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "#dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22DEresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f92c41cc-63b5-4881-9886-35d8d3f00469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.007541\n",
      "  Std MSE: 0.005857\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.013902\n",
      "  Std MSE: 0.010594\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.181350\n",
      "  Std MSE: 0.574493\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.047812\n",
      "  Std MSE: 0.036424\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.037063\n",
      "  Std MSE: 0.033994\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.349876\n",
      "  Std MSE: 0.743932\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 1029.380200\n",
      "  Std MSE: 1021.235898\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.054565\n",
      "  Std MSE: 0.031616\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.051450\n",
      "  Std MSE: 0.055232\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.041543\n",
      "  Std MSE: 0.036103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "    \n",
    "    # Save the results to an Excel file\n",
    "df.to_excel(\"22MTmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model. You can then open this file with Excel to view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245d25b8-fb9d-46b2-8aef-b2c04bdf2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge Regression: {'alpha': 0.1}\n",
      "Best parameters for Lasso Regression: {'alpha': 0.01}\n",
      "Best parameters for Random Forest Regressor: {'max_depth': 20, 'n_estimators': 300}\n",
      "Best parameters for Gradient Boosting Regressor: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best parameters for Decision Tree Regressor: {'max_depth': None}\n",
      "Best parameters for Bagging Regressor: {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 200}\n",
      "                         Model  Train MSE  Test MSE  Train R2   Test R2\n",
      "0            Linear Regression   0.002491  0.018616  0.997812  0.941642\n",
      "1             Ridge Regression   0.002532  0.018848  0.997776  0.940916\n",
      "2             Lasso Regression   0.003380  0.019448  0.997032  0.939035\n",
      "3      Random Forest Regressor   0.004885  0.038112  0.995709  0.880525\n",
      "4  Gradient Boosting Regressor   0.000003  0.027018  0.999997  0.915305\n",
      "5      Decision Tree Regressor   0.000000  0.057318  1.000000  0.820317\n",
      "6            Bagging Regressor   0.004395  0.035716  0.996139  0.888036\n",
      "7           AdaBoost Regressor   0.001834  0.040065  0.998389  0.874404\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.00249053  |  0.0186159 |   0.997812 |  0.941642 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.00253225  |  0.0188477 |   0.997776 |  0.940916 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.00337951  |  0.0194476 |   0.997032 |  0.939035 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.00488468  |  0.0381121 |   0.995709 |  0.880525 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 3.12221e-06 |  0.0270175 |   0.999997 |  0.915305 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           |  0.0573183 |   1        |  0.820317 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.00439525  |  0.0357162 |   0.996139 |  0.888036 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.00183402  |  0.0400648 |   0.998389 |  0.874404 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Tank_1','BATCHID','Material','Phase_start_delay','Target_Phase_duration','Target_Flowrate','Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Ridge Regression: {ridge_grid.best_params_}\")\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Lasso Regression: {lasso_grid.best_params_}\")\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Random Forest Regressor: {rf_grid.best_params_}\")\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Gradient Boosting Regressor: {gb_grid.best_params_}\")\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Decision Tree Regressor: {dt_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Bagging Regressor: {bag_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22DETUNresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f63c4b0-5239-45a8-9474-ac787a5855a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|    | Model                     |   Train MSE |    Test MSE |     Train R2 |      Test R2 |\n",
      "+====+===========================+=============+=============+==============+==============+\n",
      "|  0 | LinearRegression          | 0.00406106  | 0.00733306  |  0.995849    |  0.98653     |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  1 | Ridge                     | 0.00823068  | 0.0187822   |  0.991592    |  0.97523     |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  2 | Lasso                     | 0.904781    | 1.18055     |  0.0927615   | -0.322223    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  3 | RandomForestRegressor     | 0.0101814   | 0.046339    |  0.989669    |  0.928961    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  4 | GradientBoostingRegressor | 8.85041e-07 | 0.0343674   |  0.999999    |  0.948134    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  5 | SVR                       | 1.28826     | 1.27894     | -0.283956    | -0.363058    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  6 | MLPRegressor              | 7.42689e+12 | 7.43939e+12 | -7.92684e+12 | -6.31703e+12 |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  7 | DecisionTreeRegressor     | 0           | 0.0486082   |  1           |  0.923955    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  8 | BaggingRegressor          | 0.00876597  | 0.0518466   |  0.991001    |  0.923074    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  9 | AdaBoostRegressor         | 0.00201115  | 0.0466933   |  0.997954    |  0.926916    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Initialize k-fold cross-validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Iterate through each model and perform k-fold cross-validation\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    train_mse_list = []\n",
    "    test_mse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_mse_list.append(train_mse)\n",
    "        test_mse_list.append(test_mse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "    \n",
    "    mean_train_mse = sum(train_mse_list) / num_folds\n",
    "    mean_test_mse = sum(test_mse_list) / num_folds\n",
    "    mean_train_r2 = sum(train_r2_list) / num_folds\n",
    "    mean_test_r2 = sum(test_r2_list) / num_folds\n",
    "    \n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': mean_train_mse, 'Test MSE': mean_test_mse,\n",
    "                                    'Train R2': mean_train_r2, 'Test R2': mean_test_r2}, ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22MT DEAkfold_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ce4dbae-16ca-4505-adf9-1c17707f75d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |   0.152256  |  0.0665342 |   0.866263 |  0.791427 |      0.425497 |     0.280897 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |   0.0330963 |  0.0496367 |   0.970929 |  0.844397 |      0.385301 |     0.256455 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters for K-Nearest Neighbors: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for Support Vector Machine: {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |  0          |  0.0844392 |   1        |  0.735298 |     0.253225  |    0.169268  |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |  0.00559683 |  0.0220221 |   0.995084 |  0.930965 |     0.0178597 |    0.0126794 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('22MT DEAknn_svm_results_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fd02ca9-871d-4e1f-8913-50f665954635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |   0.0149416 |   0.139398 |   0.986876 |   0.56301 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |   0.0149416 |   0.139398 |   0.986876 |  0.56301  |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|  1 | LSTM Neural Network   |   0.637272  |   0.360407 |   0.440239 | -0.129812 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('22MTDEALSTMSNN Neural Network.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "038f4004-011d-4033-a9d2-1d48d469ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x0000020A0BB54D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x0000020A0BB54550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best Simple NN Params: {'batch_size': 64, 'dense1_neurons': 128, 'dense2_neurons': 64, 'epochs': 50}\n",
      "Training MSE: 0.002885827913774139\n",
      "Training R^2: 0.9974651750216327\n",
      "Test MSE: 0.026692551774552223\n",
      "Test R^2: 0.9163234739699693\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69fe7774-e5c2-4e17-9cd4-e54f04beca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best LSTM Params: {'batch_size': 16, 'epochs': 100, 'lstm_neurons': 50}\n",
      "Training MSE for LSTM: 0.016763364010392152\n",
      "Training R^2 for LSTM: 0.9852755621316889\n",
      "Test MSE for LSTM: 0.050485161835241175\n",
      "Test R^2 for LSTM: 0.8417377628742002\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62d85b5b-6257-45af-9f99-a0fe1c275fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|    |   param_neurons_layer1 |   param_neurons_layer2 |   param_batch_size |   param_epochs |   mean_test_score |   std_test_score |   rank_test_score |\n",
      "+====+========================+========================+====================+================+===================+==================+===================+\n",
      "|  0 |                    128 |                     32 |                 64 |             30 |         -0.196548 |        0.109622  |                 1 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  1 |                     32 |                     64 |                 32 |             30 |         -0.602315 |        0.356508  |                 5 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  2 |                     32 |                     64 |                 32 |            100 |         -0.298531 |        0.0877061 |                 3 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  3 |                    128 |                     16 |                 64 |             50 |         -0.203996 |        0.0666806 |                 2 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  4 |                     64 |                     16 |                 64 |             30 |         -0.355762 |        0.143351  |                 4 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "Best Simple NN Params: {'neurons_layer2': 32, 'neurons_layer1': 128, 'epochs': 30, 'batch_size': 64}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|    |   param_lstm_neurons |   param_batch_size |   param_epochs |   mean_test_score |   std_test_score |   rank_test_score |\n",
      "+====+======================+====================+================+===================+==================+===================+\n",
      "|  0 |                   70 |                 64 |            100 |         -0.469396 |         0.151902 |                 1 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  1 |                   30 |                 64 |             30 |         -0.983553 |         0.412183 |                 5 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  2 |                   30 |                 16 |             50 |         -0.890467 |         0.401249 |                 3 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  3 |                   50 |                 32 |             50 |         -0.82963  |         0.260734 |                 2 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  4 |                   30 |                 32 |             50 |         -0.971539 |         0.36685  |                 4 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "Best LSTM Params: {'lstm_neurons': 70, 'epochs': 100, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('simple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('22MTDEALSTM_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f76957cc-5509-49d3-b3a8-017b6fd87801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020A1037C4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+======================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network |  0.00300047 |  0.0714051 |   0.997364 |  0.776157 |\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "Best Score:  -0.11207947880029678\n",
      "Best Params:  {'neurons_layer3': 32, 'neurons_layer2': 32, 'neurons_layer1': 64, 'epochs': 100, 'batch_size': 64}\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020A0F244310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                            |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+==================================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network             | 0.00300047  |  0.0714051 |   0.997364 |  0.776157 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Dense Neural Network (Optimized) | 8.72869e-05 |  0.0649155 |   0.999923 |  0.796501 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Dense Neural Network (Optimized) | 8.72869e-05 |  0.0649155 |   0.999923 |  0.796501 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('neural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results_df.to_excel('22MTDEAdenseNN_results.xlsx', index=False)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

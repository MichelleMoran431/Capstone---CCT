{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2fe209-8501-48ee-b35f-0b7d888f16c9",
   "metadata": {},
   "source": [
    "### Deaeration for Tanks 23MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351e04f5-c156-43f5-b04f-7aa88e1e6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac75ad5-8489-43d2-a1c5-a7912cb763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a42ef6-82d3-4d16-a479-1f451969c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>9482</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>TAKE A SAMPLE AND SUBMIT FOR QA.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:43</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>9483</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>08/05/2022 11:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>9484</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>STEP8_AGITATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>9485</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S4_BATCH_COMPLETE_QA_PENDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>9486</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S7_RELEASED_TO_FILLING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9487 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Material    BATCHID  Tank_1  \\\n",
       "0              0   1002150  107643491    2503   \n",
       "1              1   1002150  107643491    2503   \n",
       "2              2   1002150  107643491    2503   \n",
       "3              3   1002150  107643491    2503   \n",
       "4              4   1002150  107643491    2503   \n",
       "...          ...       ...        ...     ...   \n",
       "9482        9482   3055706  107737576    2502   \n",
       "9483        9483   3055706  107737576    2502   \n",
       "9484        9484   3055706  107737576    2502   \n",
       "9485        9485   3055706  107737576    2502   \n",
       "9486        9486   3055706  107737576    2502   \n",
       "\n",
       "                                   Instruction_Step INGRED_ID  \\\n",
       "0                              S3_BATCH_IN_PROGRESS       NaN   \n",
       "1                                        STEP1_CONS   1002565   \n",
       "2                       PLEASE VERIFY BULK ADDITION       NaN   \n",
       "3                                        STEP1_CONS   1037802   \n",
       "4                                        STEP1_CONS   1002818   \n",
       "...                                             ...       ...   \n",
       "9482               TAKE A SAMPLE AND SUBMIT FOR QA.       NaN   \n",
       "9483  SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)       NaN   \n",
       "9484                                STEP8_AGITATION       NaN   \n",
       "9485                   S4_BATCH_COMPLETE_QA_PENDING       NaN   \n",
       "9486                         S7_RELEASED_TO_FILLING       NaN   \n",
       "\n",
       "                               INGRED_Name  Quantity       Phase_start  \\\n",
       "0                                      NaN     0.000  09/03/2022 10:42   \n",
       "1                            WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2                                      NaN     0.000  09/03/2022 11:16   \n",
       "3     S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4     S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "...                                    ...       ...               ...   \n",
       "9482                                   NaN     0.000  08/05/2022 11:43   \n",
       "9483                                   NaN     0.000  08/05/2022 11:54   \n",
       "9484                                   NaN     0.000  08/05/2022 11:56   \n",
       "9485                                   NaN     0.000  08/05/2022 11:56   \n",
       "9486                                   NaN     0.000  08/05/2022 12:02   \n",
       "\n",
       "             Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0     09/03/2022 10:42               0                  0             1   \n",
       "1     09/03/2022 11:16              34                  0             2   \n",
       "2     09/03/2022 11:17               1                  0             3   \n",
       "3     09/03/2022 11:27              10                  0             4   \n",
       "4     09/03/2022 11:38              11                  0             5   \n",
       "...                ...             ...                ...           ...   \n",
       "9482  08/05/2022 11:54              11                  0            19   \n",
       "9483  08/05/2022 11:55               1                  0            20   \n",
       "9484  08/05/2022 11:56               0                  1            21   \n",
       "9485  08/05/2022 11:56               0                  0            22   \n",
       "9486  08/05/2022 12:02               0                  6            23   \n",
       "\n",
       "      Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0             0.0000              NaN                      0            NaN   \n",
       "1           169.4118         733.5050                      8           26.0   \n",
       "2             0.0000              NaN                      3            0.0   \n",
       "3             0.5629           6.3182                      1            9.0   \n",
       "4             7.1605           6.3182                     12            0.0   \n",
       "...              ...              ...                    ...            ...   \n",
       "9482          0.0000              NaN                     10            1.0   \n",
       "9483          0.0000              NaN                     10            0.0   \n",
       "9484          0.0000              NaN                      0            0.0   \n",
       "9485          0.0000              NaN                      0            NaN   \n",
       "9486          0.0000              NaN                     14            0.0   \n",
       "\n",
       "      Deaeration Phase  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "9482                 0  \n",
       "9483                 0  \n",
       "9484                 0  \n",
       "9485                 0  \n",
       "9486                 0  \n",
       "\n",
       "[9487 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf73d0c-7499-465d-8d22-5701d012c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29eb9da9-262d-406d-ba7a-38815a02423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Data = pd.DataFrame(ProductionTank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3327649b-010d-47d2-9241-b9bd93cd5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.replace(\"STEP2_CONS\", \n",
    "           \"STEP2_CONS-Deaeration\", \n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d862f7-a2d3-472d-87b3-1b3f350b6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction_Step     25\n",
      "Phase_start_delay     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Data[['Instruction_Step', 'Phase_start_delay']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97f96b8-b75f-4036-8ea4-94bf7318ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = Data[Data['Instruction_Step'] == 'STEP2_CONS-Deaeration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268b431-79ca-455f-8f1b-7ebf01ae0b4d",
   "metadata": {},
   "source": [
    "#### Exploring the different deaeration times ( start Phase delay duration) for each of the groups of productions tanks and their common materials "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ec279-fc68-4b75-ad24-25f8e25665fb",
   "metadata": {},
   "source": [
    "#### Deaeration in  Production Tanks : ''2301','2302','2304','2305'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4c09b9-f558-4a64-9b0d-423f998d4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanks_in_group1 = [2301,2302,2304,2305]\n",
    "instruction_step_of_interest = 'STEP2_CONS-Deaeration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753d659e-387e-4571-94d1-6b6fcd317ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = Data[(Data['Tank_1'].isin(tanks_in_group1)) & \n",
    "                    (Data['Instruction_Step'] == instruction_step_of_interest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b5ee40-0fdf-4d30-81b4-9ee819779830",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_materials = filtered_data.groupby('Material').filter(lambda x: x['Tank_1'].nunique() == len(tanks_in_group1))['Material'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d032e018-1612-4023-b084-a98a797e4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data1 = filtered_data[filtered_data['Material'].isin(common_materials)]\n",
    "#filtered_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c373d248-daee-42cb-95cb-a27ca471c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'BATCHID','Instruction_Step'])['Phase_duration'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4796b7-633c-4f6c-ab54-68e63139dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAI4CAYAAACcFxlBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAABenUlEQVR4nO3deZhcVZn48e8bAoRICDuGhE1BCQ4aEQ0IgitLREFwFAwGECeKG47IiCKCKKi/kREVEHGAEEQRZTSIQUVlUSSyCIJsBhRJYggRCKvs7++PczoUTXfSDV3dt7u/n+fpp6vOvXXvW3WqbtV971kiM5EkSZIkSWqyEQMdgCRJkiRJ0vKYwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmNZwJDklpExMUR8f6BjqPJIuL1ETG/h+seFRHfbUMMq0TETyPivoj4YV9vfziIiAcj4kU9WG/jiMiIGPk899fj9003j39dRNzyfGIYynpan328T4+XeoaImBERXxzoOCQNXSYwJA07EXF7RPyr/uBfVH9wrTrQcfVUXyQFnu/JZAO8E1gPWCsz/72vNhoRm0TEUxHxrS6WZURs2kX5/hHxux5u//aIeCwi1u5Ufk3d/sY92EafJBQyc9XM/Ovz2UZ/yszfZuZL27HteiL+SEQ8EBH3R8TVEXFYRKzcjv09X10lDtpVn4PheBnFXyPixoGOpTsRsXJEnBoRf6/vs2sjYteW5VtExFURcW/9+1VEbNGyfEb93O/eabtfq+X7R8Rnaj09WN/PT7bcv6HT417Xsuyhuo0HW/42bP+rIkm9ZwJD0nD1tsxcFdgK2Br47ADH02+e74lvQ2wE/CUzn+jtA5fz/KcB9wLvbuPJ69+AfVri2RIY3aZ9PctgrP9+ivkjmTkGGAccAuwNzI6I6Id9L9XQ+mn68XIHYF3gRRHx6ueygX543UcC84AdgbGU1/CclqTlPyiJ2TWBtYHzgLM7beMvlGMUsDTmdwG3AWTmsTWRtSrwQeDyjvuZ+bLWDdWEYMe6HctWb1n/jr564pLUl0xgSBrWMnMBcAHwby3FG0XEZfUq2S9br5ZHxA8j4s7adeHSiHhZy7IpEXFjfdyCiPhky7Ld6hW3JRHx+4h4+fJii4hP1e08EBG3RMSbImIX4DOUE+wHI+JPdd0DIuKmuu5fI+IDLdt5fUTMr9u7E/h+fc7rt1xtW38ZcaxSr/7dW69wvrrT8vUj4tyIWBwRf4uIjy1jW12+fhHx6np1d4WWdffseH6dtvF54HMtr8GBETEiIj5br27eFREzI2JsXb+jxcKBEXEH8JtuYgvKycFngceBt3X3PJ6nM2k5CQH2A2Z2iuWtUVpl3B8R8yLiqJbFl9b/S+rz37Y+5n31PXBvRPwiIjZq2V5GxIcjYi4wt6Vs0x7s7xmiXOn9a32v/S0ipnaz3vLeN89o0RItTc+7eM+eHp1aDUVpGfDJiLiuvp9+EBGjWpb/V0QsjIh/RMT7O++vO5n5UGZeDLwd2BZ4a93eiCitMm6LiLsj4pyIWLNlf8s6NqwcEV+NiDvq+/zkiFhlGc91jYg4v36m7q23J9T1jwFeB5xQ6/+Ezq9nRIytn4HF9TPx2YgY0VJ/v6vx3FvrcGlLgOW8Nk09Xu4HzAJm19tLRcTLIuLCiLinvvafqeVHRcSPIuK7EXE/sH+UY9l5dd1bI+I/WrbzmigtJO6v2/mfWj6qbuPuGu+VEbFeF6/dQ5l5VGbenplPZeb5lGTmq+ryJXVZAgE8CXR+v/4U2D4i1qj3dwGuA+5czuvTK9Gz75NDohxrF0bEAd1sZ0xEXBQR34ii2zqXpJ4ygSFpWIuIDYApwDUtxe8BDqBc0VsJaP2RdQGwWV32R+CslmWnAh+oV3H/jXqiHBGvBE4DPgCsBXwbOC+WcYU/Il4KfAR4dd3ezsDtmflz4FjgB/Uq2SvqQ+4CdgNWq7F/LSK2atnkCylX9jainDzvCvyj5WrbP5bxMh0JvLj+7UzLCUI9Kfop8CdgPPAm4OMRsXM32+ry9cvMK4G7gZ1a1n0vnU7s67pHdnoNTgX2r39vAF4ErAqc0OmhOwIT63PoyvbABMpVz3PodCLUh+YAq0XExCgJm72Bzl2CHqLU0+qUE+iDImKPumyH+r/jaunlUZqVfwbYE1gH+C0lUdVqD2AysAXPtqz9LRURLwC+Aexa35evBa7t5nl2+77podb37PRu1nkX5SRuE+DllPcAURJ9nwDeTDkJfH0v9029An0VJVkA8FHKa7gjsD6lpc6JLQ9Z1rHhy8BLgEk1nvGUJFyHzs91BHB6vb8h8C/q+zkzD6fU70dq/X+ki/C/SbnK/6Ia7zTKcaHDZOAWypX+/wecGrH8liZNPF5GxGhKy4Wz6t/eEbFSXTYG+BXwc0qdbQr8uuXhuwM/orzvz6J89ufXdd8JHBsRb6zrfh34emauRnlPn1PL96O81hvUeD9Iqa9lqkmOlwCdu3YsAR6h1OGxnR72CCVRs3e9P40ujpF9oCffJ2Mp7+MDgRNbkioARMRalNf6ssz8WE3MdFnnktQrmemff/75N6z+gNuBB4ElwN+Bk4BV6rKLgc+2rPsh4OfdbGd1IIGx9f4dlB/dq3Va71vAFzqV3QLsuIwYN6X8iHwzsGKnZUcB313Oc/wJcHC9/XrgMWBUy/LXA/N7+Hr9Fdil5f70jsdSToTu6LT+p4HTlxdrF6/fp4Cz6u01gYeBcd089hnbpfxQ/lDL/ZdSWlGMBDau+3nRcp7n/wI/qbe3rY9ft2V5Apt28bj9gd/14r33Zkorjy9RTr4vrHEmsHE3jzse+Fq93fF8RrYsvwA4sOX+iPr6bdQS+xs7bbPL57Os/QEvoHxu9qJ+Zp7L+6ar/QMzgC/29D1bX8t9W+7/P+Dkevs04EudPk/Ler4XA+/vovxs4Dv19k3Am1qWjet4jy3rvU25mv4Q8OKW5dsCf+vuuXaxvUnAvcuKt+P5ASvU7W3RsuwDwMUt79dbW5aNro994TLes409XgL7Aosp789RwH3AO+qyfYBrunncUcClLfc3oLR6GNNS9iVgRr19KfB5YO1O23kf8Hvg5cv6PHR6zIqUxMq3u1n+gvpavrXz54OSaL28vp6LgFWA3wH7d9rG/vT8uLQxnY4pnZb/hGd+n/yLZx5/7gK2aYnzNODPwKGdttNlnfvnn3/+9ebPFhiShqs9MnP1zNwoMz+Uma1XzFqb4z5MuZpPRKwQEV+O0oT8fsoPeyhXMaGc1E0B/h4Rl0Rt2k+5inpIbV68pF5h24Byla9LmXkr8HHKj+y7IuLsWHY3j10jYk5t+rykxtE6UOTizHyk21dj2dan9N3u8PeW2xtRuqK0PrfPUAbY7Bzj8l6/7wJvq1f53wX8NjMX9iLG1rj+TjmhaY1jHt2I0pz/33m6RcjllB/b7+nh/nvrzLrt/eniCmpETK5NrxdHxH2Uq7prd16vxUbA11vq4B7KifP4lnWW9fx7tL/MfAh4d12+MCJ+FhGbd7PZZb1veqIn79kuP6td7Lvb574c4ymvJZTX+Mctr/FNlBPe9Zbz3l6HkiS4uuWxP6/lHZ7xXCNidER8O0r3j/spJ8+rR0sXq2VYm3KC3Pnz0PpeWPq6ZebD9eayBuZs8vFyP+CczHyivobn8nRrnw2o40N0o/V9sT5wT2Y+0FLW+rodSGkxcXPtJrJbLT8T+AVwdpTuSv8vIlbsboe11dqZlCRTV61nOj5nJwMzI2LdTst+R3nvHA6c36ku+kQPvk/uzmeOP9T62YPSimuV+hxadVfnktRjJjAkqefeQ2ly/GbKldWNa3lA6QaRmbtTmkv/hKebGM8DjqknAB1/ozOzcxP/Z8jM72Xm9pQf9Al8pWNR63q1afW5wFeB9TJzdUpf8NYm4c94TBf3l2Uh5USgQ+vo9PMoV5Jbn9uYzJzSxXaW9/otoFxZ3JPSfeTMXsT4D8rr1BrjE5QrlB2W9ZzfQWkufVKUPvt3Uk5c9lvGY56zzPw7pf/7FOD/uljle5RB/DbIzLGUE4GO+uzqecyjNM1urYdVMvP3rbtdRkjL2l/n2H+RmW+htEC4GfhON9tc1vsGyklP6+ClL+y8q2XEuzwLKd2BOmzQ3Yrdqd0lXkXprgHlNd6102s8qr5vl/Xe/iflivXLWh43NsvgiR06P9dDKK2IJmfpstDRbWhZ74EO/6S0DOn8eVjQk+fdh9p+vIwyLsgbgX1bPrfvBKZEGYtjHqUbTXdaX8d/AGvWbicdlr5umTk3M/ep8X4F+FFEvCAzH8/Mz2fmFpQuVbvxzDFuWuMNSjeK9YC9MvPxZcQ2gvL5GN/Fsu9S3iN93n2kh98ny/MdSpJudk1IA8usc0nqMRMYktRzY4BHKWM1jKalf3JErBQRUyNibP1Rej/wVF38HeCD9Sp3RMQLogyaOKbzDlq299KIeGP9MfkI5QSoY3uLgI3rlTwo/c5XpjSjfiLKgHw7dd5mJ4uAtaIOdLkc5wCfjjKw4ATKWAAdrgAeiDIA4Sr1quu/RdczAXT7+rWYCfwXsCVdn9h35/vAf0aZBnVVnh4jo6ezlOxHafa8JaW5/iRgO+AVUWYJ6bBSlEH7Ov46rohHp/JRLN+BlG4dD3WxbAzlavAjEfEantkSZDHlvdB6YnYypY46BkUdGxG9mV52WftbKiLWi4jd60nJo5SuBU91tS7Lft9AGTvjPfU9swtlrIa+cg5wQJRxRkYDR/T0gbX1w46UsQauoJy8QXmNj4k6OGpErBNPT2nZ7Xs7M5+iHAO+1nE1PSLGR/fjxHRs71+UgVrXpIwn0moR3ZyYZ+aTlOd/TJRBFDeijAfyvKZefg7643j5XsrMHC/l6c/tSyjjWOwDnA+Mi4iPRxlIdUxETO4q2MycR+kK8qX6GX455TP63RrzvhGxTq3PJfVhT0XEGyJiy3osuJ+SPOruM/Etyjg8b+vcciIi3hIRr6yfh9WA/6GMs3JTF9v5BvAWnh7Qty89l++TrnyE0vXnp/W7YVl1Lkk9ZgJDknpuJqVJ8QLgRspgjK3eC9wepbn0B4GpAJl5FfAflEH47gVupQ42uAwrUwb++yelifa6lLElAH5Y/98dEX+sTZ4/RjlpuZdy8nnesjaemTdTTvr/GqWZdrfdUyj9vjtaDPySlpYR9WRpN8qJw99qvP9LueLa2fJeP4AfU5vqtzRt74nTalyX1jge4dknzF2KiI7BR4/PzDtb/q6mXEVsbYVxA+XEsuOvY2DE13Yq/1csZ1rGzLytvje68iHg6Ih4gDLY4zktj3sYOAa4rNbdNpn5Y8pV4bPr++/PlIFae6rb/XUygnIy/A9K14odgYO6Wbfb9011MGWmlyWUz8pPehHvMmXmBZSTvIson7eO99qjy3jYCfX5L6KMAXIuZQyPjpOsr1M+V7+s682hjAEDy39vf6ojjlo/v6KcdHfneEoT/H/Wbf280/KvA++MMovIN7p4/Ecp4278lTI+wvcon5H+1B/Hy/2Akzp9bu+kJJv2q8fGt1DeZ3dSZuB5wzJi3ofSUuQflGPRkZn5q7psF+CGiHiQ8vrvXZMQL6QMBHo/JdlwCV20HquJpA9QjpV3xtMzQHXM4rM65Zh8H6Xby4sp779ndaPKzHsy89eZ+XxaKXXpuXyfdLOdpI57Q0kGjqKbOpek3og2HPskSXrOIuI2SneIXy13ZakHImIiJamzci9a5UiSpIaxBYYkqTEiYi9Kv3Sn19PzEhHvqN0G1qC0TvmpyQtJkgY3ExiSNEAiYsOWZsSd/zoPeNjuWC7oJo7P9GMMF1P6iH+4pdm+9Fx9gDK9422U2UK66+oiSZIGCbuQSJIkSZKkxrMFhiRJkiRJarxljpA+mK299tq58cYbD3QYkiRJkiSpF66++up/ZuY6ncuHbAJj44035qqrupudTpIkSZIkNVFE/L2rcruQSJIkSZKkxjOBIUmSJEmSGq9fEhgRsUJEXBMR59f7m0TEHyLi1oj4QUSsVMtXrvdvrcs3btnGp2v5LRGxc3/ELUmSJEmSmqG/xsA4GLgJWK3e/wrwtcw8OyJOBg4EvlX/35uZm0bE3nW9d0fEFsDewMuA9YFfRcRLMvPJfopfkiRJkqS2efzxx5k/fz6PPPLIQIfSb0aNGsWECRNYccUVe7R+2xMYETEBeCtwDPCJiAjgjcB76ipnAEdREhi719sAPwJOqOvvDpydmY8Cf4uIW4HXAJe3O35JkiRJktpt/vz5jBkzho033phyGjy0ZSZ333038+fPZ5NNNunRY/qjC8nxwH8BT9X7awFLMvOJen8+ML7eHg/MA6jL76vrLy3v4jFLRcT0iLgqIq5avHhxHz8NSZIkSZLa45FHHmGttdYaFskLgIhgrbXW6lWLk7YmMCJiN+CuzLy6nfvpkJmnZObWmbn1Ous8a8pYSZIkSZIaa7gkLzr09vm2uwvJdsDbI2IKMIoyBsbXgdUjYmRtZTEBWFDXXwBsAMyPiJHAWODulvIOrY+RJEmSJElDXFtbYGTmpzNzQmZuTBmE8zeZORW4CHhnXW0/YFa9fV69T13+m8zMWr53naVkE2Az4Ip2xi5JkiRJkpqjX6ZR7cKnKAN63koZ4+LUWn4qsFYt/wRwGEBm3gCcA9wI/Bz4sDOQSJIkSZKGu7vvvptJkyYxadIkXvjCFzJ+/Pil9x977LEebePiiy9mt91269G6N998M9tuuy0rr7wyX/3qV59P6L3WX9OokpkXAxfX23+lzCLSeZ1HgH/v5vHHUGYykSRJkiRJwFprrcW1114LwFFHHcWqq67KJz/5ybbtb8011+Qb3/gGP/nJT9q2j+4MVAsMSZIkSZLUBt/5znd49atfzSte8Qr22msvHn74YQD2339/Pvaxj/Ha176WF73oRfzoRz961mOvvPJKXvnKV3Lbbbd1ue11112XV7/61ay44optfQ5dMYEhSZIkSdIQsueee3LllVfypz/9iYkTJ3LqqacuXbZw4UJ+97vfcf7553PYYYc943G///3v+eAHP8isWbN48Ytf3N9hL1e/dSGRJEmSJEnt9+c//5nPfvazLFmyhAcffJCdd9556bI99tiDESNGsMUWW7Bo0aKl5TfddBPTp0/nl7/8Jeuvv/5AhL1ctsCQJEmSJGkI2X///TnhhBO4/vrrOfLII3nkkUeWLlt55ZWX3i6Tfhbjxo1j1KhRXHPNNf0aa2+YwJAkSZIkaQh54IEHGDduHI8//jhnnXVWjx6z+uqr87Of/YxPf/rTXHzxxe0N8DmyC4kkSZIkSUPIF77wBSZPnsw666zD5MmTeeCBB3r0uPXWW4/zzz+fXXfdldNOO43Jkyc/a50777yTrbfemvvvv58RI0Zw/PHHc+ONN7Laaqv19dN4lmhtMjKUbL311nnVVVcNdBiSJEmSJC3XTTfdxMSJEwc6jH7X1fOOiKszc+vO69qFRJIkSZIkNZ5dSCRJkiRJ0jOcfvrpfP3rX39G2XbbbceJJ544QBGZwJAkSZIkSZ0ccMABHHDAAQMdxjOYwJAkSZKk5+COo7ds+z42/Nz1bd+HNFg4BoYkSZIkSWo8ExiSJEmSJKnx7EIiSZIkSVLDvOrQmX26vav/e9py15k3bx7Tpk1j0aJFRATTp0/n4IMP5ogjjmDWrFmMGDGCddddlxkzZrD++uuTmRx88MHMnj2b0aNHM2PGDLbaaisAdtllF+bMmcP222/P+eef3yfPwRYYkiRJkiSJkSNHctxxx3HjjTcyZ84cTjzxRG688UYOPfRQrrvuOq699lp22203jj76aAAuuOAC5s6dy9y5cznllFM46KCDlm7r0EMP5cwzz+zT+ExgSJIkSZIkxo0bt7QFxZgxY5g4cSILFixgtdVWW7rOQw89REQAMGvWLKZNm0ZEsM0227BkyRIWLlwIwJve9CbGjBnTp/HZhUSSJEmSJD3D7bffzjXXXMPkyZMBOPzww5k5cyZjx47loosuAmDBggVssMEGSx8zYcIEFixYwLhx49oSky0wJEmSJEnSUg8++CB77bUXxx9//NLWF8cccwzz5s1j6tSpnHDCCQMSlwkMSZIkSZIEwOOPP85ee+3F1KlT2XPPPZ+1fOrUqZx77rkAjB8/nnnz5i1dNn/+fMaPH9+22ExgSJIkSZIkMpMDDzyQiRMn8olPfGJp+dy5c5fenjVrFptvvjkAb3/725k5cyaZyZw5cxg7dmzbuo+AY2BIkiRJktQ4PZn2tK9ddtllnHnmmWy55ZZMmjQJgGOPPZZTTz2VW265hREjRrDRRhtx8sknAzBlyhRmz57NpptuyujRozn99NOXbut1r3sdN998Mw8++CATJkzg1FNPZeedd35e8ZnAkCRJkiRJbL/99mTms8qnTJnS5foRwYknntjlst/+9rd9GhvYhUSSJEmSJA0CJjAkSZIkSVLjmcCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS4zmNqiRJkiRJDXPH0Vv26fY2/Nz1y11n3rx5TJs2jUWLFhERTJ8+nYMPPpgjjjiCWbNmMWLECNZdd11mzJjB+uuvT2Zy8MEHM3v2bEaPHs2MGTPYaqutuPbaaznooIO4//77WWGFFTj88MN597vf/byfgy0wJEmSJEkSI0eO5LjjjuPGG29kzpw5nHjiidx4440ceuihXHfddVx77bXstttuHH300QBccMEFzJ07l7lz53LKKadw0EEHATB69GhmzpzJDTfcwM9//nM+/vGPs2TJkucf3/PegiRJkiRJGvTGjRvHuHHjABgzZgwTJ05kwYIFbLHFFkvXeeihh4gIAGbNmsW0adOICLbZZhuWLFnCwoULeclLXrJ0/fXXX591112XxYsXs/rqqz+v+ExgSJIkSZKkZ7j99tu55pprmDx5MgCHH344M2fOZOzYsVx00UUALFiwgA022GDpYyZMmMCCBQuWJkEArrjiCh577DFe/OIXP++Y7EIiSZIkSZKWevDBB9lrr704/vjjWW211QA45phjmDdvHlOnTuWEE07o0XYWLlzIe9/7Xk4//XRGjHj+6QcTGJIkSZIkCYDHH3+cvfbai6lTp7Lnnns+a/nUqVM599xzARg/fjzz5s1bumz+/PmMHz8egPvvv5+3vvWtHHPMMWyzzTZ9EpsJDEmSJEmSRGZy4IEHMnHiRD7xiU8sLZ87d+7S27NmzWLzzTcH4O1vfzszZ84kM5kzZw5jx45l3LhxPPbYY7zjHe9g2rRpvPOd7+yz+BwDQ5IkSZKkhunJtKd97bLLLuPMM89kyy23ZNKkSQAce+yxnHrqqdxyyy2MGDGCjTbaiJNPPhmAKVOmMHv2bDbddFNGjx7N6aefDsA555zDpZdeyt13382MGTMAmDFjxtJtPlcmMCRJkiRJEttvvz2Z+azyKVOmdLl+RHDiiSc+q3zfffdl33337fP47EIiSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajynUZUkSZIkqWG2++Z2fbq9yz562XLXmTdvHtOmTWPRokVEBNOnT+fggw/miCOOYNasWYwYMYJ1112XGTNmsP7665OZHHzwwcyePZvRo0czY8YMttpqq6Xbu//++9liiy3YY489OOGEE573c7AFhiRJkiRJYuTIkRx33HHceOONzJkzhxNPPJEbb7yRQw89lOuuu45rr72W3XbbjaOPPhqACy64gLlz5zJ37lxOOeUUDjrooGds74gjjmCHHXbos/hMYEiSJEmSJMaNG7e0BcWYMWOYOHEiCxYsYLXVVlu6zkMPPUREADBr1iymTZtGRLDNNtuwZMkSFi5cCMDVV1/NokWL2GmnnfosPruQSJIkSZKkZ7j99tu55pprmDx5MgCHH344M2fOZOzYsVx00UUALFiwgA022GDpYyZMmMCCBQtYb731OOSQQ/jud7/Lr371qz6LyRYYkiRJkiRpqQcffJC99tqL448/fmnri2OOOYZ58+YxderU5Y5ncdJJJzFlyhQmTJjQp3HZAkOSJEmSJAHw+OOPs9deezF16lT23HPPZy2fOnUqU6ZM4fOf/zzjx49n3rx5S5fNnz+f8ePHc/nll/Pb3/6Wk046iQcffJDHHnuMVVddlS9/+cvPKzZbYEiSJEmSJDKTAw88kIkTJ/KJT3xiafncuXOX3p41axabb745AG9/+9uZOXMmmcmcOXMYO3Ys48aN46yzzuKOO+7g9ttv56tf/SrTpk173skLaHMLjIgYBVwKrFz39aPMPDIiZgA7AvfVVffPzGujjATydWAK8HAt/2Pd1n7AZ+v6X8zMM9oZuyRJkiRJA6Un0572+T4vu4wzzzyTLbfckkmTJgFw7LHHcuqpp3LLLbcwYsQINtpoI04++WQApkyZwuzZs9l0000ZPXo0p59+elvja3cXkkeBN2bmgxGxIvC7iLigLjs0M3/Uaf1dgc3q32TgW8DkiFgTOBLYGkjg6og4LzPvbXP8kiRJkiQNC9tvvz2Z+azyKVOmdLl+RHDiiScuc5v7778/+++/f1+E194uJFk8WO+uWP+e/Wo8bXdgZn3cHGD1iBgH7AxcmJn31KTFhcAu7YxdkiRJkiQ1R9vHwIiIFSLiWuAuShLiD3XRMRFxXUR8LSJWrmXjgXktD59fy7or77yv6RFxVURctXjx4r5+KpIkSZIkaYC0PYGRmU9m5iRgAvCaiPg34NPA5sCrgTWBT/XRvk7JzK0zc+t11lmnLzYpSZIkSZIaoN9mIcnMJcBFwC6ZubB2E3kUOB14TV1tAbBBy8Mm1LLuyiVJkiRJ0jDQ1gRGRKwTEavX26sAbwFuruNaUGcd2QP4c33IecC0KLYB7svMhcAvgJ0iYo2IWAPYqZZJkiRJkqRhoN2zkIwDzoiIFSjJknMy8/yI+E1ErAMEcC3wwbr+bMoUqrdSplE9ACAz74mILwBX1vWOzsx72hy7JEmSJElqiLYmMDLzOuCVXZS/sZv1E/hwN8tOA07r0wAlSZIkSWqgS3bYsU+3t+Ollyx3nXnz5jFt2jQWLVpERDB9+nQOPvhgjjjiCGbNmsWIESNYd911mTFjBuuvvz6ZycEHH8zs2bMZPXo0M2bMYKuttgJghRVWYMsttwRgww035Lzzznvez6HdLTAkSZIkSdIgMHLkSI477ji22morHnjgAV71qlfxlre8hUMPPZQvfOELAHzjG9/g6KOP5uSTT+aCCy5g7ty5zJ07lz/84Q8cdNBB/OEPZeLRVVZZhWuvvbZP4+u3QTwlSZIkSVJzjRs3bmkLijFjxjBx4kQWLFjAaquttnSdhx56iDKcJcyaNYtp06YREWyzzTYsWbKEhQsXti0+ExiSJEmSJOkZbr/9dq655homT54MwOGHH84GG2zAWWedxdFHHw3AggUL2GCDpycMnTBhAgsWlAlDH3nkEbbeemu22WYbfvKTn/RJTCYwJEmSJEnSUg8++CB77bUXxx9//NLWF8cccwzz5s1j6tSpnHDCCcvdxt///neuuuoqvve97/Hxj3+c22677XnHZQJDkiRJkiQB8Pjjj7PXXnsxdepU9txzz2ctnzp1Kueeey4A48ePZ968eUuXzZ8/n/Hjxy9dBvCiF72I17/+9VxzzTXPOzYTGJIkSZIkiczkwAMPZOLEiXziE59YWj537tylt2fNmsXmm28OwNvf/nZmzpxJZjJnzhzGjh3LuHHjuPfee3n00UcB+Oc//8lll13GFlts8bzjcxYSSZIkSZIapifTnva1yy67jDPPPJMtt9ySSZMmAXDsscdy6qmncssttzBixAg22mgjTj75ZACmTJnC7Nmz2XTTTRk9ejSnn346ADfddBMf+MAHGDFiBE899RSHHXaYCQxJkiRJktQ3tt9+ezLzWeVTpkzpcv2I4MQTT3xW+Wtf+1quv/76Po/PLiSSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSVIDdNV9Yyjr7fM1gSFJkiRJ0gAbNWoUd99997BJYmQmd999N6NGjerxYxzEU5IkSZKkATZhwgTmz5/P4sWLBzqUfjNq1CgmTJjQ4/VNYEiSJEmSNMBWXHFFNtlkk4EOo9HsQiJJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFGDnQAkiRJkqSubffN7dq+j8s+elnb9yH1BVtgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8dqawIiIURFxRUT8KSJuiIjP1/JNIuIPEXFrRPwgIlaq5SvX+7fW5Ru3bOvTtfyWiNi5nXFLkiRJkqRmaXcLjEeBN2bmK4BJwC4RsQ3wFeBrmbkpcC9wYF3/QODeWv61uh4RsQWwN/AyYBfgpIhYoc2xS5IkSZKkhmhrAiOLB+vdFetfAm8EflTLzwD2qLd3r/epy98UEVHLz87MRzPzb8CtwGvaGbskSZIkSWqOto+BERErRMS1wF3AhcBtwJLMfKKuMh8YX2+PB+YB1OX3AWu1lnfxmNZ9TY+IqyLiqsWLF7fh2UiSJEmSpIHQ9gRGZj6ZmZOACZRWE5u3cV+nZObWmbn1Ouus067dSJIkSZKkftZvs5Bk5hLgImBbYPWIGFkXTQAW1NsLgA0A6vKxwN2t5V08RpIkSZIkDXHtnoVknYhYvd5eBXgLcBMlkfHOutp+wKx6+7x6n7r8N5mZtXzvOkvJJsBmwBXtjF2SJEmSJDXHyOWv8ryMA86oM4aMAM7JzPMj4kbg7Ij4InANcGpd/1TgzIi4FbiHMvMImXlDRJwD3Ag8AXw4M59sc+ySJEmSJKkh2prAyMzrgFd2Uf5XuphFJDMfAf69m20dAxzT1zFKkiRJkqTm67cxMCRJkiRJkp4rExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGGznQAQw3dxy9Zb/sZ8PPXd8v+5EkSZIkqT+YwJCkNuqPpKUJS0mSJA0HdiGRJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNZ4JDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY3X1gRGRGwQERdFxI0RcUNEHFzLj4qIBRFxbf2b0vKYT0fErRFxS0Ts3FK+Sy27NSIOa2fckiRJkiSpWUa2eftPAIdk5h8jYgxwdURcWJd9LTO/2rpyRGwB7A28DFgf+FVEvKQuPhF4CzAfuDIizsvMG9scvyRJkiRJaoC2JjAycyGwsN5+ICJuAsYv4yG7A2dn5qPA3yLiVuA1ddmtmflXgIg4u65rAkOSJEmSpGGg38bAiIiNgVcCf6hFH4mI6yLitIhYo5aNB+a1PGx+LeuuvPM+pkfEVRFx1eLFi/v6KUiSJEmSpAHSLwmMiFgVOBf4eGbeD3wLeDEwidJC47i+2E9mnpKZW2fm1uuss05fbFKSJEmSJDVAu8fAICJWpCQvzsrM/wPIzEUty78DnF/vLgA2aHn4hFrGMsolSZIkSdIQ1+5ZSAI4FbgpM/+npXxcy2rvAP5cb58H7B0RK0fEJsBmwBXAlcBmEbFJRKxEGejzvHbGLkmSJEmSmqPdLTC2A94LXB8R19ayzwD7RMQkIIHbgQ8AZOYNEXEOZXDOJ4APZ+aTABHxEeAXwArAaZl5Q5tjlyRJkiRJDdHuWUh+B0QXi2Yv4zHHAMd0UT57WY+TJEmSJElDV7/NQiJJkiRJkvRcmcCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNV6PExgRsVY7A5EkSZIkSepOb1pgzImIH0bElIiItkUkSZIkSZLUSW8SGC8BTgHeC8yNiGMj4iXtCUuSJEmSJOlpPU5gZHFhZu4D/AewH3BFRFwSEdu2LUJJkiRJkjTsjezpinUMjH0pLTAWAR8FzgMmAT8ENmlDfJIkSZIkST1PYACXA2cCe2Tm/JbyqyLi5L4NS5IkSZIk6Wm9SWC8NDOzqwWZ+ZU+ikeSJEmSJOlZepPAWDsi/gt4GTCqozAz39jnUUmSJEmSJLXozSwkZwE3U8a6+DxwO3BlG2KSJEmSJEl6ht4kMNbKzFOBxzPzksx8H2DrC0mSJEmS1Ha96ULyeP2/MCLeCvwDWLPvQ5IkSZIkSXqm3iQwvhgRY4FDgG8CqwH/2ZaoJEmSJEmSWvQ4gZGZ59eb9wFvaE84kiRJkiRJz7bcBEZEfBPocvpUgMz8WJ9GJEmSJEmS1ElPWmBc1fYoJEmSJEmSlmG5CYzMPKP1fkSMzsyH2xeSJEmSJEnSM/V4GtWI2DYibgRurvdfEREntS0ySZIkSZKkqscJDOB4YGfgboDM/BOwQxtikiRJkiRJeobeJDDIzHmdip7sw1gkSZIkSZK61ONpVIF5EfFaICNiReBg4Kb2hCVJkiRJkvS03rTA+CDwYWA8sACYVO9LkiRJkiS1VY9bYGTmP4GpbYxFkiRJkiSpS8tNYETEN4HsbnlmfqxPI5IkSZIkSeqkJ11IrgKuBkYBWwFz698kYKW2RSZJkiRJklQttwVGZp4BEBEHAdtn5hP1/snAb9sbniRJkiRJUu8G8VwDWK3l/qq1TJIkSZIkqa16M43ql4FrIuIiIIAdgKPaEZQkSZIkSVKr3sxCcnpEXABMrkWfysw7O5ZHxMsy84a+DlCSJEmSpOFku29u1y/7ueyjl/XLfvpKb1pgUBMWs7pZfCZlkE9JkiRJkqQ+1ZsxMJYn+nBbkiRJkiRJS/VlAiP7cFuSJEmSJElL9WUCQ5IkSZIkqS36MoHxWB9uS5IkSZIkaakeJzAi4tfLKsvMbfoqKEmSJEmSpFbLnYUkIkYBo4G1I2INnh6sczVgfBtjkyRJkiRJAno2jeoHgI8D6wNX83QC437ghPaEJUmSJEmS9LTlJjAy8+sRcQLwmcz8Qj/EJEnqhe2+uV2/7Oeyj17WL/uRJEmSutKTFhhk5pMRsSdgAkOSpOW44+gt+2U/G37u+n7ZjyRJUhP0ZhaSX0fEXhERy19VkiRJkiSp7/QmgfEB4IfAoxFxf0Q8EBH3tykuSZIkSZKkpXrUhQQgM8e0MxBJkiRJkqTu9DiBAVCnUd0MGNVRlpmX9nVQkiRJkiRJrXqcwIiI9wMHAxOAa4FtgMuBN7YlMkmSJElS212yw479sp8dL72kX/ajoas3Y2AcDLwa+HtmvgF4JbBkWQ+IiA0i4qKIuDEiboiIg2v5mhFxYUTMrf/XqOUREd+IiFsj4rqI2KplW/vV9edGxH69faKSJEmSJGnw6k0C45HMfAQgIlbOzJuBly7nMU8Ah2TmFpQWGx+OiC2Aw4BfZ+ZmwK/rfYBdKV1UNgOmA9+q+1sTOBKYDLwGOLIj6SFJkiRJkoa+3iQw5kfE6sBPgAsjYhbw92U9IDMXZuYf6+0HgJuA8cDuwBl1tTOAPert3YGZWcwBVo+IccDOwIWZeU9m3gtcCOzSi9glSZIkSdIg1ptZSN5Rbx4VERcBY4ELevr4iNiY0u3kD8B6mbmwLroTWK/eHg/Ma3nY/FrWXXnnfUyntNxgww037GlokiRJkiSp4XoziOeZmflegMy8pKMMeG8PHrsqcC7w8cy8PyKWLsvMjIjsbeBdycxTgFMAtt566z7ZpiSp6I8BvhzcS5IkSd3pTReSl7XeiYgVgFct70ERsSIleXFWZv5fLV5Uu4ZQ/99VyxcAG7Q8fEIt665ckiRJkiQNA8tNYETEpyPiAeDlEXF//XuAknSYtZzHBnAqcFNm/k/LovOAjplE9mvZznnAtDobyTbAfbWryS+AnSJijTp45061TJIkSZIkDQPL7UKSmV8CvhQRX8rMT/dy+9tRuphcHxHX1rLPAF8GzomIAykDgb6rLpsNTAFuBR4GDqgx3BMRXwCurOsdnZn39DIWSXqGVx06s+37+PGYtu9CkiRJGhZ6PAYGcH5EvCAzH4qIfYGtgK9nZrczkWTm74DoZvGbulg/gQ93s63TgNN6Ea8kSZIkSRoiejMGxreAhyPiFcAhwG1A+y9fSpIkSZKkYa83LTCeqDOG7A6ckJmn1i4gkiRJkiQNC3ccvWX7d7LGau3fxyDUmwTGAxHxaWBfYIeIGAGs2J6wJEmSJElSO12yw45t38eOl17SZ9vqTReSdwOPAgdm5p2UqUz/u88ikSRJkiRJ6kaPW2DUpMX/tNy/g5YxMCLi8szctm/DkyRJkiRJ6l0LjOUZ1YfbkiRJkiRJWqovExjZh9uSJEmSJElaqi8TGJIkSZIkSW3RlwmM6MNtSZIkSZIkLdWrBEZEbBQRb663V4mIMS2L39unkUmSJEmSJFU9TmBExH8APwK+XYsmAD/pWJ6Zf+7TyCRJkiRJkqretMD4MLAdcD9AZs4F1m1HUJIkSZIkSa1G9mLdRzPzsYgy1EVEjMSZRyRJkjTM3XH0lv2ynw0/d32/7EcazF516My27+PHY5a/jtqjNy0wLomIzwCrRMRbgB8CP21PWJIkSZIkSU/rTQLjMGAxcD3wAWA28Nl2BCVJkiRJktSqx11IMvMp4DvAdyJiTWBCZtqFRJIkSZIktV1vZiG5OCJWq8mLqymJjK+1LzRJkiRJkqSiN11Ixmbm/cCewMzMnAy8qT1hSZIkSZIkPa03CYyRETEOeBdwfpvikSRJkiRJepbeJDCOBn4B3JqZV0bEi4C57QlLkiRJkiTpab0ZxPOHlKlTO+7/FdirHUFpcLhkhx3bvo8dL72k7fuQJEmSJDVfjxMYETEKOBB4GTCqozwz39eGuCRJkiRJkpbqTReSM4EXAjsDlwATgAfaEZQkSZIkSVKr3iQwNs3MI4CHMvMM4K3A5PaEJUmSJEmS9LTeJDAer/+XRMS/AWOBdfs+JEmSJEmSpGfq8RgYwCkRsQZwBHAesCrwubZEJUmSJEmS1KI3s5D8b715CfCi9oQjSZIkSZL0bL2ZhWRlyrSpG7c+LjOP7vuwJEmSJEmSntabLiSzgPuAq4FH2xOOJEmSJEnSs/UmgTEhM3dpWySSJEmSJEnd6M0sJL+PiC3bFokkSZIkSVI3ltsCIyKuB7Kue0BE/JXShSSAzMyXtzdESZIkSZI03PWkC8lubY9CkiRJkiRpGXqSwFgEfBDYFLgeODUzn2hrVJIkSZIkSS16MgbGGcDWlOTFrsBxbY1IkiRJkiSpk560wNgiM7cEiIhTgSvaG5IkSZIkSdIz9aQFxuMdN+w6IkmSJEmSBkJPWmC8IiLur7cDWKXe75iFZLW2RSdJkiRJkkQPEhiZuUJ/BCJJkiRJktSdnnQhkSRJkiRJGlAmMCRJkiRJUuP1ZAwMSZIkDSOX7LBjv+xnx0sv6Zf9SJKGBltgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnx2prAiIjTIuKuiPhzS9lREbEgIq6tf1Naln06Im6NiFsiYueW8l1q2a0RcVg7Y5YkSZIkSc3T7hYYM4Bduij/WmZOqn+zASJiC2Bv4GX1MSdFxAoRsQJwIrArsAWwT11XkiRJkiQNEyPbufHMvDQiNu7h6rsDZ2fmo8DfIuJW4DV12a2Z+VeAiDi7rntjX8crSZIkSZKaqa0JjGX4SERMA64CDsnMe4HxwJyWdebXMoB5ncond7XRiJgOTAfYcMMN+zpmScAlO+zYL/vZ8dJL+mU/kiRJkgaHgRjE81vAi4FJwELguL7acGaekplbZ+bW66yzTl9tVpIkSZIkDbB+b4GRmYs6bkfEd4Dz690FwAYtq06oZSyjXJIkSZIkDQP93gIjIsa13H0H0DFDyXnA3hGxckRsAmwGXAFcCWwWEZtExEqUgT7P68+YJUmSJEnSwGprC4yI+D7wemDtiJgPHAm8PiImAQncDnwAIDNviIhzKINzPgF8ODOfrNv5CPALYAXgtMy8oZ1xS5IkSZKkZmn3LCT7dFF86jLWPwY4povy2cDsPgxNkiRJkiQNIgMxiKckSZIkSVKvDNQ0qpIkDYhXHTqz7fv48Zi270KSJGnYsQWGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGm/kQAcgSZKkntvum9u1fR/H+hNRktRAtsCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNZ4JDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNZ4JDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDXeyIEOQFLf2e6b27V9H8d62JCkbt1x9Jbt38kaq7V/H5IkNZAtMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4jsYnSZK6dckOO7Z9Hzteeknb9yFJkgY/W2BIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqvLYmMCLitIi4KyL+3FK2ZkRcGBFz6/81anlExDci4taIuC4itmp5zH51/bkRsV87Y5YkSZIkSc3T7hYYM4BdOpUdBvw6MzcDfl3vA+wKbFb/pgPfgpLwAI4EJgOvAY7sSHpIkiRJkqThoa0JjMy8FLinU/HuwBn19hnAHi3lM7OYA6weEeOAnYELM/OezLwXuJBnJ0UkSZIkSdIQNhBjYKyXmQvr7TuB9ert8cC8lvXm17Luyp8lIqZHxFURcdXixYv7NmpJkiRJkjRgBnQQz8xMIPtwe6dk5taZufU666zTV5uVJEmSJEkDbCASGItq1xDq/7tq+QJgg5b1JtSy7solSZIkSdIwMRAJjPOAjplE9gNmtZRPq7ORbAPcV7ua/ALYKSLWqIN37lTLJEmSJEnSMDGynRuPiO8DrwfWjoj5lNlEvgycExEHAn8H3lVXnw1MAW4FHgYOAMjMeyLiC8CVdb2jM7PzwKCSJEmSJGkIa2sCIzP36WbRm7pYN4EPd7Od04DT+jA0SZIkSZI0iAzoIJ6SJEmSJEk9YQJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNV5bp1GV9LQ7jt6y/TtZY7X270OSJEmSBoAtMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNZ4JDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNZ4JDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJkiRJjWcCQ5IkSZIkNZ4JDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmNN3KgA5AkSZKkvvSqQ2f2y35+PKZfdiOpGrAWGBFxe0RcHxHXRsRVtWzNiLgwIubW/2vU8oiIb0TErRFxXURsNVBxS5IkSZKk/jfQXUjekJmTMnPrev8w4NeZuRnw63ofYFdgs/o3HfhWv0cqSZIkSZIGzEAnMDrbHTij3j4D2KOlfGYWc4DVI2LcAMQnSZIkSZIGwEAmMBL4ZURcHRHTa9l6mbmw3r4TWK/eHg/Ma3ns/Fr2DBExPSKuioirFi9e3K64JUmSJElSPxvIQTy3z8wFEbEucGFE3Ny6MDMzIrI3G8zMU4BTALbeeutePVaSJEmSJDXXgLXAyMwF9f9dwI+B1wCLOrqG1P931dUXABu0PHxCLZMkSZIkScPAgCQwIuIFETGm4zawE/Bn4Dxgv7rafsCsevs8YFqdjWQb4L6WriaSJEmSJGmIG6guJOsBP46Ijhi+l5k/j4grgXMi4kDg78C76vqzgSnArcDDwAH9H7IkSZIkSRooA5LAyMy/Aq/oovxu4E1dlCfw4X4ITZIkSZIkNVDTplGVJEmSJEl6FhMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8UxgSJIkSZKkxjOBIUmSJEmSGs8EhiRJkiRJajwTGJIkSZIkqfFMYEiSJEmSpMYzgSFJkiRJkhrPBIYkSZIkSWo8ExiSJEmSJKnxTGBIkiRJkqTGM4EhSZIkSZIazwSGJEmSJElqPBMYkiRJkiSp8QZVAiMidomIWyLi1og4bKDjkSRJkiRJ/WPQJDAiYgXgRGBXYAtgn4jYYmCjkiRJkiRJ/WHQJDCA1wC3ZuZfM/Mx4Gxg9wGOSZIkSZIk9YPIzIGOoUci4p3ALpn5/nr/vcDkzPxIyzrTgen17kuBW/o90OZYG/jnQAehfme9D0/W+/Bl3Q9P1vvwZd0PT9b78DTc632jzFync+HIgYikXTLzFOCUgY6jCSLiqszceqDjUP+y3ocn6334su6HJ+t9+LLuhyfrfXiy3rs2mLqQLAA2aLk/oZZJkiRJkqQhbjAlMK4ENouITSJiJWBv4LwBjkmSJEmSJPWDQdOFJDOfiIiPAL8AVgBOy8wbBjisJrMrzfBkvQ9P1vvwZd0PT9b78GXdD0/W+/BkvXdh0AziKUmSJEmShq/B1IVEkiRJkiQNUyYwJEmSJElS45nAkCRJkiRJjWcCQ5KGiYiI1v8aXqx3SRra/J4fnoZbfZvAGMYiYtDMQqO+FRH/FhFr1tseB4aP0QBZR28ebl94w1VErAOl3q3z4aUe69cb6DjUvyLilRHxinrb7/jhZWXwe34YWgOe/rwP9Xr3oDZMRcRbgGMi4nMRsclAx6P+ExE7A9cBRwBk5lMDG5H6Q0TsCpwWEcdExF4RsbIntENfROwAXBgR7waTGMNJROwC/B/1h20ts+6HuFrvVwOHgN/xw0lE7AScHBFfjog3R8SIdLrJIa/+rv9RRBwHfDQiVhjq9W4CYxiqJzInANcAWwMHD2xE6i8RMYWSuPgIsGlEbDXAIakfRMQk4HRgJnA/sD3wjYhYxRPaIW8N4Elgn4h4P3hlbjiIiDcCXwfen5k3R8RKYN0PdS3f8fsAL66/9zQM1MTVN4GfACsBbwNWG8iY1H71gvR/A18FbgZemplPtiwfksd6ExjDTESsTcnKH5qZZwP7Am+sX3oawiLi34AvAIdn5knAYmCLusxjwdAWwNmZ+TPgeODbwKPA/3S0xBjI4NRWc4FrKfW+W0TsERHrRMRK1vvQFBGjKN/tl2fmpRGxPvD/IuKLEXFYR+JygMNUH4uITSnf8Udk5g+AC4GX1WUrDGRsaq+IWA34EOX33U+AzwKvAt4+kHGpfaJYFXgn8InMnA1cDrw2Ij4ZEe8fysd6T1qGmcz8J/AZSpPiFTPzfuAyat94DWmPAftk5iX1/q+AoyNiQ5uYDnn/AnaPiJ0y81HgL8C3KEmMN8HQzdIPd5l5I+W7/m7gf4D/An4PjAfrfSjKzEcodf1IbVL8a2ARsIBS70dY70PSPcC/Z+Zv6v05wEci4hlXZDX01N/ynwIuiYiRmfkw8EtgzMBGpjZaMTMfBD6Zmb+q49qdBPwUuAvYkvIbf0ie6w/JJ6Vni4gXR8TGEbF6Zl4BPJKZj9fF/wTWruu9KSJePmCBqs9FxDYRsX5m/iUz/9JxJSYzv0dparhnXc/jwRDSMUgrQGbeDBwGHBYRr6sJq9so3UleVdcZkln64SYiJkfEf0TEK+v9oHQheYiSsHox5Zj/GrDeh5KImBQRO0XEhMz8M/Bl4IXAiZn5pcz8FiVxPdp6HzoiYmJEbAFEZv41IlYEyMyfA98FPhQRqwxokGqLWvdbRcS6mXkT8M/MfKIuvh/YsK731trVQENA7S50Qv2sPwiQmfcA/5WZR2TmTEoLrBWH6gVKT1iGgfpGnwUcBcyJiA1qv/eOWUhWAJ6KiLcD3wDuHZhI1dciYizwc+CLEfEigMx8suXq25+BN9TyIXmQG44iYjfg7Ih4V0vx+cD3Ke+FXTPzMWAhsElErOQV2cGv9nc/C5hEaWX30nqi+lPgOMqAjgdTWuHtERGrD1Co6mO17n8M7AycGhH/CdwHHEjpMtZhXWCDiBjlZ37wq4P3/R/wMeCGeiL7eEuXkYuBdQATGENM/W3/Y8ox/aaI2KzTb/vHgPvrseHLlO6EGuTqZ/4o4IeZ+XhrMjoz57Qc18cBG0bEKkPxWO80mkNcRGxDSUq8v/aF/QJwZERMb1ltLqVZ8ULg3Zk5bwBCVXs8BlwBbAYcGhH/nZl/7TjgZeZpEfHhiDgiM78woJGqT0TES4GTgZ8B20cEmXlOZj4UEd8FllAy978G3grsVJMZGsQiYl3gUODAzLwkIh4Etqz/FwAPA+/LzF9ExAuAqzLzgQEMWX2g/jAdQ0lU7Fe/599KGcxvXeD0zPxLXfcDwAeBqbWbiQaxiHgtpZ4/kJkX1XOU9SLivtpVkNq0/AjgGOCggYtWfSkitqaMa/QfmfnbiPgscFKU8ew6ugvdBswAbqF0H759AEJVH4qILYELgB0y83dRpshei/L9/vf6235ERHyQ8p2wb2b+a+Aibp+wFeHQVH/UBGUU4pUz85xavh3w0czcu2XdPYH/BV5bm5prEIuIaM3IRsR+lCTVvpSExiXAI8Cv6pWa7YA7TFwNDbVJ4ZuAGyhXYycDF3YcA+o6mwArAg9n5vwBCVR9ovXzHhHfBm4CzgP+RGl181LKD91LM/P2zscHDQ0R8b/ANZl5Yr3/fUpryjmZOTMiJlBaYvxXZt4wgKGqj0TEG4B/1auuG1GO+d+jDM79kcy8tq43HlgpM/82YMGqT9WLk+Mz89x6fwLwzcx8R8s621Na3722di/REBARv6K0rvsw8ANgPvAKyqxTM4H1gFOB/6xdCYckExhDVJQR5h+rTcnWAhZn5lNRZiE5F3h9bWq2Smb+qzY7vGtgo1ZfiDLv91Mt9z8FjMnMz0bEBZST2gMy84wBC1J9LiLeDGyamSd3vAciYh1KEnNbSsLqBxExPjMXDGy06itRBmN+vN5+D6VVzSbA7Mz8YkS8Dfg08MHMvM4ExtATZfyifSjJyieABNYHzgaOpHzf3x9lxqFHBy5S9YV6FfaxzLyl3l8J+E/gicw8rnYfOhR4WWbaJXgIiYgXUxKTDwGrZ+aiWr4S5eLUrpm5JCLWzsx/Rhn3bsnARay+EGVmqSdbvut/AbwF+HBmfqu2vDma0grvhogYNdRb2TkGxhBU+7udU5sNTs3MRfVkZkVgZUrWNiPi/cBZEbGCyYuhoQ7S9L8RMb02Iwb4DnBfRLyEcjX2QmC7esVGQ0BE7AScTplpZP2OBFZmLgZmU0ajf01EfA/4vyhTb2mQq/V+ZkQcEhH7ZOb3MnMqZdybRQCZ+VPKrDOb1vsmL4aAiNguInauFyGeojQrPo9ycrMEeG9mzqK0xFm5PsyuYoNcROwBnAmsE08PyP0YpavQcfX+14CLgNUGKk71vXqSehawWmY+2pK8WBEYBawJPBwR+wMz60nskoGKV32jfs//EDg+Ij4JkJk7A+/KMjAzWaZQ/TNl0GYoA3YPaSYwhpiIeDVlzIuzKU2JD46IrwHUzN1i4KraF/YA4Kh0eq0hoTYXPJVysroG8NGI+HSWkYnfB1xPuQq7M+Uq3ePdbkyDRh3Q6UuUed/vAzpmnxgBkJl3ZuaplCuy21P6Sz84QOGqj0TE6yjH+nOBKykzzBxbF/8B2DQi3lFbZWwLXD0wkaqv1a4DvwU+AOwYES/IzHsy81eZ+YX690REHEA9HoDJq8GuXnT4FOUY/jtKSxsAMvOujmN+REwFJlKmz9YQUE9i/4fSLeD2aJk1LstAjvdTxjs7BHg/cNhQvwI/HEQZqPV4SuLqZ8BO9SI1mfmjlvWmAq+mXKwYFsd6B/EcekYCl2Tm2QAR8RvKzCNPZeYhtVvJtpSpE99uv7ghZVXg+5l5Sm1u9jPgtIi4C9iN0vLm0rruh4fDAW6oi4gNKd0DPl4H8hoFHBMR12TmP+o6QZky823ANkO5T+Qw80Lg1Mz8IUBEnAl8PiIeAr4CbAfsQUlc7ZWZfx+oQNXnNqYkpUcD76R8zC/uGKytntxMAb4A7FxbYmnwexy4MzP/EBEbA0dExBJgSZZBuFeOiH2AT1CuztqydgiIMlvUNMp4NpdHxBrAxyPifuCezDy9rvpyyqxyb3Y8u8EvIlajdAk9JDMvqEMC7ACs3rLOSnWdI4E9htNYdrbAGCIiYsMo83w/BLwwysi0HfMCbwPsEGUwRyitM6aYvBhyHqVcjVspMx+pJ6oHUn7gTsgyOn3YB37oyMw7KKOL/7aetHwPuAzYCpaOh5KZ+QdgosmLIWUlYL+IGF3vr0jp974LZUCvozNzP0rywnofAiLiJVFmkDkX+G5mngTcDOwJvLH+BiAzn8rM8ykJSwfsHDoeokyLORE4HLiVMkjjtIj4Yk1grQC8IzNvHMA41YdqN5BvAwsj4ivA5ZTj/5PA9Ij4eF3125TxbkxeDAG1Vc3pwNX1d/sTwD8oSaqOdR6jfAfsNNw+87bAGAJqE/IvAnvXQdr+BvwiIl5dm5bdExEnUAbzBDi8fhA0yNXWNFsAN2SZRu1PwC8jYpfafPA2SrPCDWB4NCsbDiJi1ZZuIHdCOWkBHoiIfwIfA87vGPumHgeGTWZ+qIqIrYANgSsz86yIeCXw+4i4EVg/M18fZTrVjTPzalj6I0iDXG1C/nXK1bjZtd87mfnViDiU0trmzihTaz6Rmd9KZxga9Op3/ETg5sz8fUTcQRnX6CeZ+aW6ztsoXUugtMp6quutaTCJiB0pA/PeRklUBfAh4ITMPKGus4Cnu4l92y7hg1/9PG+bmZ/JzD92Wnwv8IK63j7AI5n54/6OsQlsgTHI1R81X6Y0KToMIDM/ClwDXBERG9RV1wVeVQd98gA3BETE2ykZ9+2Az0TEJpn5AcrYJ7+OiNGZ+TCln+xrOlpfDGDI6gP1y+3yOgZCa3kAZOaR9f5B9b5jnQwB9fN+NvAe4CsR8d/AZ4B3AP8PeHNddRQ1YamhoX7Pf4WSrHwXlM91bVJMZv438HvK98FhlCu0GuRavuO3Bz4VES/KzCOAn1BaX21eV90WWDciVqZlXAwNXvV7/uvAOpRWtNvVLsCHUd4THTYB1qu/7U1cDXL1gvTRwG+6WWUucEsdG+MQSuuLYckWGINYRLwJ+Bawe2b+OSJ+HhE7ZeYvM/OAiPgq8I2IeIzSN+7fzc4ODRGxJnAQsG9tdXMKZWaRByhX378EXFivzL4JeKutLwa/iHgZ5WT1UuDrEfHxjq5BmZlRZhR6EvgVsH60TLGpQW9X4JOZeV5tifFO4AzgE5n5N4CIOJAyneabu9+MBpOIeCPlhGWPzPxTRFwZEftm5nfrQJ0d02Y/RZlp5rXDrSnxUNTNd/z2EXFvZv5nbWl3VETcQ7lKv186Re6QULsFTgP+IzOvjIhjgEm1tcXifHoqzfdSjvfv8bf94BcRrwBOAQ7OzF/VsU42Bu4B/pmZD1EaHhwFXEuZaWrYDgVgAmNwS8qX258jYiwlE7cF8EuAzPxklKkzRwH3OYjbkPI4sArwyoiYR5kP+oWUgRpvrnX/Gsr0eV/OzNsGLlT1obuAL9buAwcAJ0TERzPzkprE6PgR83+UpoUmL4aAOr7JCpTj+3mZ+ceIWAz8B/DJiDgcWA/YnJKsnDtw0aqPLaKMc/On2srqu8BmUFpd1W5iHf3hdzB5MWQ8wbO/49cD3lYvTBxFufq+CvAVf98NKUnp8r1jRMwH3k2ZRe4VwCoR8dG6/D2Uc4BhexI7xNxF6S60dkRMAk4A7qb83v9LHf/kPkry4t3D/Xs+vCg7+HVcgan95c6h/IC9aqDjUnt0XGWPiN2BIyiDd/4yMz8fETtQTmqOy8xrBzJO9Z3aVPjezFzU0sqCKPO9HwJ8pCYxNgPm18HcNMjVLgIrZOajtdXF6ZQE1g/ryexk4MOUcRHuiohVrPuhISLeTJlh4I/1fsf3/FaUBOUBmXlRy/oOzjwERMQE4MHMXFK7EXwOeIxnfse/H/haZl4zkLGqb9VxbSLLbIGvBk6knLBekZmHR5l55jBKEnt2RKxeB/jUIFa7CG6QmadGxIuBkyit6b6cmd+pn/npwJcy84aIWDsz/zmQMTeBY2AMMhHx1og4OSJOiDJYF/VHTWTmJZSM3a4RMSJa5onW4BcRO0fEt4CTI2JyZs6iXJX5LXADQO0jOYpy8NMQEGXO75Mo0+TSkryIzJxBmRv+/0UZqPc4SqsbDXIRMQWYAZwXEW+qJ7KfBw6IiHdlMYcy/tErAUxeDA217v8XmNCpPOr74Dhg/yjT7AEO0DwU1OTU1ZTP+DqZ+VOe/o6/EZZ+x68CvHjAAlWfqxekZgDfi4gpmXkl8Frg58DfADLzdspsUxvW+0sGIlb1nZqo/j6lu/9La2vp9wNHZuZ34Bm/6zvGtrp7QIJtGLuQDCIRsR1wDGWO73UoB7pjgTNbfrj+iTK91n9nmYVCQ0D9QftlyvgH61HqftfM/EtE/JIyjVpHd4EXU34EaZCLiLcCx1L6wnbuBhSU85bTawb/3ZT535f0c5jqYzVp9WXKtKgbAWdFxFsy8/8i4gngmNo98EFKstJuA0NERKwK/BdwYGb+Op6eGrU1OfV7yuCtawDOMjN0zANuB9YE9omIczLzzvodv2+U8czA7/ghpba2+DzwPmB94LCI2IZyceJXwFdri7v7gUmUMc40yNXfd8cAb6UM1LtLRNyWZca477astxflM99xodJkNSYwBpvNgQsz8zcAEbEF8ElKH9lZAHWAt38HxlGzthrc6mBee1OaiV9Yy8ZTvuj+QhmVeA5wMPAIsH/HoH4avOpAXu+ldB25ol5t/RDlx+2szLysrvdGYEvgjZl5/YAFrD4RES8ApgCfzcxf1LLxlIGYr6/H+Nso7401KNNnO0Xu0JGULgS/rsf+U4CVI+Jy4OLM/H1mXh0R12Mr2iGjtph9AlgI/IuSmHxLRNwCrAT8Afh4XeZ3/NCyMXBtbV31x9qN6IPAfMqJ7ImU7/57KV3Hbh2oQNU3ImJtygCsH8/MORGxJWWGqW/W5R0Dsx9AmSJ5L7/nn8kxMAaRKFNq7QZ8tV55/zRlMK8dgXdk5nUDGqDaovaL3J6SpHi0dhn6FnB3Zn62Zb0xAJn5wMBEqr5Ur7hsAexP+YGzMTCbMtvAfsD7MvPiiFgHWCUz7xiYSNVXOsawiIhXUpKT/6qf96OBtTPzQwMcotqkdfySiPgm8ADlJPZ8ysBuO1GSG1+2deXQEREvzMw7W+5/gjJN6uqUMa62ocwg97ua3Bzhd/zQEBHjMnNhbYExHfhhZv4yIj5DueL+UuBTmXlZlClySWeaGfQi4sWZeVtEjGn9LEfEz4HrMvO/Wso2AxjuA3Z2xex9w0XEthGxS0S8DvgZpdn45yPiPMqI4++jXKHZaiDjVN+LiF0jYr86k8Sl9cdtR8bxz5QfuETEuyJiYmY+4A+bwa+l3hO4iTJwI5QfN0dm5ucpTUsPjIiRmbnY5MXgF2X+949GxAqUq3EPZZkeE8oI9PfV9fap3Qk1RNS6/0g9QYUyGPfKwLrAObW11bnAtpTxDzQE1K5i36gD93VYhTI47wvq/6uBLSJi3XpM8Dt+CKh1//WI2Ijye24+ZeyT2cB2mXkgcCYlcUlmPmryYvCLiLcAV0TEAR2f5SiDdQN8BVgtyvSpHQP2zzV50TW7kDRYHffgS8AvKM2Hv0hpQrghZQqlK+qqawEPDUCIapOabf8gsFNELKkDdkId94AyiM+TEbEH8AVg9wEJVH2qU73fl5k/iYibKPOC/6OjWWFd/d7MfGLgolVfaRnz4uB8eircVvcBD9bugUcBe/RfdGqnTnXf8T1+JaWL4Gsps1B8hvK970WnISLKNOcnU7oEtI5vdAHwacpFqQ9QZiB5A6V7iYaATnX/91r2JUrSaiPqWAeUVjjW+xAREbtQjvU/A15Yy6Lld9wtlM/93sC3uvktoMoERkPV0aiPBj6YmZdHxBcpA3eOypY5nyPiIEq3kj0GJFC1RZZpE8+n9Hc9Psp0WWdQEhhQRqL+GiVzv0dm3jxAoaoPdar3r0XEGnWQzkV1eUbEeyndSvYbwFDVR+pYRidRpki7OCLWAtYGVmoZ02Q0JXFxDeXzflOXG9Og0k3drws8kZk/iIg7gPdGxE8pgzf/R2beO4Ahq++8BPhuZv4mItanzCQ0htLS5kHgP+ssJETE5ZnpYK1DR+e6fxUwNjO/Sxnngoj4GGWco38fuDDVVyLi9ZQL0gcCdwDXR8RVLePaRb1I9RVgekScQelC6jgP3TCB0VwjgY/UwV3WpIxO/Apgz3pF/qO17/tmwD6Z+ZeBDFZ9JyJWrN1G7qL8mPlv4Oz6Y3cV4GOUkcpvAPbNzFsGKlb1nWXU++bAqIg4hJKd341y5eaG7remQWQVylXXp+oVmk9SWlitGRE3Z+ZHgeuA3wEfMnkxpHRX92tHxLWZeQhweR3U78F0hqGhZD6wbURsQBmE/ZfALsCOmXkAlKblmfmEyYshp6u6f3NE7JaZe9duhGsBUz3eDxmjKRekrwaoF6X3iYgrMvO+lkTFr4GLMvPhgQp0sLA5YsNEmRqPzLwCuLKOTL0P8OnMfBtwGPBvEbFDZi4GDsvMPw1cxOorLXXfMR3qdcCe9YD3beA/gRXqsquBt5m8GPx6WO8jazPDa4Hp6Wwjg15LvV8NnAW8jDLa/I8oTUjfB0ys410sAN7pj9mhoQd1vz/winrVjsycb/Ji8Ouo9+peYANgGuVq/GGZOQl4ZUR8HMAugkNHD+p+a2CjiPhY7TpwlL/tB7+IeClAZs7OzD/UczooQwCsTekmRE1akZlLMvOegYh1sDGB0SARsRtwbUR8HyAzn6yDuP1v7T5AZi4A/go8We8/1t32NHi01P33WoqXAIsj4l2Uk5mjgb0j4j2Z+XBmLhyAUNWHelnv+2TmY5l53wCEqj7UUu9nA9RBGr8PfDIzT85iHuVKXccAbncPXMTqK72se2cbGSK6+H33J8qsUgcCL4qI1euq/0cdsFdDQy/q/seU7kPYdWDwq/V+TUe9VyNg6UXqxcAJ9b7jXfSSCYyGqKOPf4QySOejEfHdlsVPtqy3J2VAz/n9GqDaplPdP9ZR97Wv88OUkaiPyMwvAnvy9OCtGsSeQ71fOUChqg91qvdHOpJX9QfNz1vW24tyZd5j/RDxHOreJPUQ0MXvu456P5nSL34zYP+I+DxwAHD5AIWqPvYc6v73AxSq+lB353SZ+UQdrB3gU8DjEbH9wEQ5uIVJvuaog/ncD4yijFD8SGbuW5etSJkn+n3Afpn55wELVH2ui7p/LDPfU5ubbZqZf+k0A4WGAOt9eOqi3h/NzKkty/ej/Pg5wGP90GLdD09d1PvjmblPXbY9sAZl2tQz7Ro6tFj3w9Oyzunq8tHAkcDXMvPOgYly8DKB0VB1NPJTKKPQ7lsH8tsZ+Flm3jqw0amduqj7SZQfufZ/H8Ks9+Gpi3qfSJk28eeZ+deBjU7tZN0PTy31/lhm7hMRLwfurl2ENYRZ98NTF8f6rSmtK++qQwWol0xgNFhErE2ZieC1lOkzdzBLNzy01P22lIE735CZNiUf4qz34amLY/2OjnEzPFj3w1Onel8BeL3H+uHBuh+eOv2+G4n1/rw4BkaDZeY/KTMSjAX2MnkxfLTU/eqUGSk8yA0D1vvw1MWx3hPYYcK6H5461fs7PNYPH9b98NTp9531/jyZwGiwiFgDmALs5LSJw4t1PzxZ78OT9T58WffDk/U+fFn3w5P13rfsQtJwETEqM51KbRiy7ocn6314st6HL+t+eLLehy/rfniy3vuOCQxJkiRJktR4diGRJEmSJEmNZwJDkiRJkiQ1ngkMSZIkSZLUeCYwJEmSJElS45nAkCRJ/SIiMiK+23J/ZEQsjojzl/O4SREx5Tnsb/2I+NFy1tk4Iv7c221LkqT+ZwJDkiT1l4eAf4uIVer9twALevC4SUCvEhgRMTIz/5GZ7+xdiJIkqalMYEiSpP40G3hrvb0P8P2OBRHxmoi4PCKuiYjfR8RLI2Il4Gjg3RFxbUS8OyJeEBGnRcQVdd3d6+P3j4jzIuI3wK9bW1fU27+NiD/Wv9f279OWJEnPlwkMSZLUn84G9o6IUcDLgT+0LLsZeF1mvhL4HHBsZj5Wb/8gMydl5g+Aw4HfZOZrgDcA/x0RL6jb2Ap4Z2bu2Gm/dwFvycytgHcD32jT85MkSW0ycqADkCRJw0dmXhcRG1NaX8zutHgscEZEbAYksGI3m9kJeHtEfLLeHwVsWG9fmJn3dPGYFYETImIS8CTwkuf8JCRJ0oAwgSFJkvrbecBXgdcDa7WUfwG4KDPfUZMcF3fz+AD2ysxbnlEYMZkyzkZX/hNYBLyC0gL1kecYuyRJGiB2IZEkSf3tNODzmXl9p/KxPD2o5/4t5Q8AY1ru/wL4aEQEQES8sgf7HAsszMyngPcCKzyHuCVJ0gAygSFJkvpVZs7PzK7GoPh/wJci4hqe2Ur0ImCLjkE8KS01VgSui4gb6v3lOQnYLyL+BGxO9y01JElSQ0VmDnQMkiRJkiRJy2QLDEmSJEmS1HgmMCRJkiRJUuOZwJAkSZIkSY1nAkOSJEmSJDWeCQxJkiRJktR4JjAkSZIkSVLjmcCQJEmSJEmN9/8BtfonAOMg/eEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=filtered_data, x='Material', y='Phase_start_delay', hue='Tank_1', ci=None)\n",
    "\n",
    "plt.title('Phase_start_delay for ALL Materials during Deaeration Phase Across 23MT Tanks')\n",
    "plt.ylabel('Phase_start_delay')\n",
    "plt.xlabel('Material')\n",
    "plt.legend(title='Tank_1', loc='upper right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f8229b-87ff-4d87-8131-2d4512ac1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=filtered_data1, x='Material', y='Phase_start_delay', hue='Tank_1', ci=None)\n",
    "\n",
    "plt.title('Phase_start_delay for Common Materials during Deaeration Phase Across 23MT Tanks')\n",
    "plt.ylabel('Phase_start_delay')\n",
    "plt.xlabel('Material')\n",
    "plt.legend(title='Tank_1', loc='upper right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f53f8-38a7-40f4-b42a-7607205f32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33d6366-beb5-41e8-ac7f-639bc9e1bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredient_of_interest = ['1461896', '1254972','1031006','1243269','1196706','1815609']\n",
    "#ingredient_data = data[data['INGRED_ID'] == ingredient_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00cc340d-2365-4260-ad2b-13912e94dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID       Instruction_Step  Phase_start_delay\n",
      "0     2301  107659908  STEP2_CONS-Deaeration               2867\n",
      "1     2301  107689605  STEP2_CONS-Deaeration               2340\n",
      "2     2301  107700709  STEP2_CONS-Deaeration               1233\n",
      "3     2301  107710853  STEP2_CONS-Deaeration               3458\n",
      "4     2301  107734582  STEP2_CONS-Deaeration               3171\n",
      "..     ...        ...                    ...                ...\n",
      "78    2305  107899895  STEP2_CONS-Deaeration               5344\n",
      "79    2305  107915804  STEP2_CONS-Deaeration               3918\n",
      "80    2305  107934335  STEP2_CONS-Deaeration               4984\n",
      "81    2305  108067816  STEP2_CONS-Deaeration               3935\n",
      "82    2305  108084747  STEP2_CONS-Deaeration               4425\n",
      "\n",
      "[83 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = [2301,2302,2304,2305]\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP2_CONS-Deaeration']\n",
    "filtered_data = Data[(Data['Instruction_Step'].isin(desired_steps)) & (Data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_Phase_start_delay = filtered_data.groupby(['Tank_1','BATCHID','Instruction_Step'])['Phase_start_delay'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID','Material']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "#print(aggregated_total_durations_df2)\n",
    "print(total_Phase_start_delay)\n",
    "\n",
    "\n",
    "aggregated_total_durations_df2.to_csv('DeaerationPhase23MT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea720dac-c31d-41ba-8be7-c425a58ae6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2301  107659908   1775253             175          155.0   \n",
      "1     2301  107689605   1451710              76           56.0   \n",
      "2     2301  107700709   1520984             111           99.0   \n",
      "3     2301  107710853   1775253              11            0.0   \n",
      "4     2301  107734582   1775253              57           37.0   \n",
      "..     ...        ...       ...             ...            ...   \n",
      "78    2305  107899895   1397022             179          150.0   \n",
      "79    2305  107915804   1775253              12            0.0   \n",
      "80    2305  107934335   1451710              25            5.0   \n",
      "81    2305  108067816   1775253              64           44.0   \n",
      "82    2305  108084747   1775253              35           15.0   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0                2867  1631.500         86.5330                   10.0   \n",
      "1                2340  1528.100         57.9004                   10.0   \n",
      "2                1233   909.100          8.1901                   12.0   \n",
      "3                3458  1631.900        148.3545                   21.0   \n",
      "4                3171  1630.000         58.6553                   10.0   \n",
      "..                ...       ...             ...                    ...   \n",
      "78               5344  2052.498         98.3854                   10.0   \n",
      "79               3918  1631.400        135.9500                   21.0   \n",
      "80               4984  1526.498        123.9041                   10.0   \n",
      "81               3935  1630.900         71.0260                   10.0   \n",
      "82               4425  1630.100         93.2281                   10.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0           79.0160  \n",
      "1           79.0160  \n",
      "2           79.0160  \n",
      "3           79.0160  \n",
      "4           79.0160  \n",
      "..              ...  \n",
      "78          65.4124  \n",
      "79          79.0160  \n",
      "80          79.0160  \n",
      "81          79.0160  \n",
      "82          79.0160  \n",
      "\n",
      "[83 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = [2301,2302,2304,2305]\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP2_CONS-Deaeration']\n",
    "filtered_data = Data[(Data['Instruction_Step'].isin(desired_steps)) & (Data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_Phase_start_delay = filtered_data.groupby(['Tank_1','Material','Instruction_Step'])['Phase_start_delay'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID','Material']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "print(aggregated_total_durations_df2)\n",
    "aggregated_total_durations_df2.to_csv('DeaerationPhase23MT1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c827824-d055-4ce5-a232-697b9b4bddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "#aggregated_total_durations_df2.dropna(inplace=True)  # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1dd2246-274f-43c0-8e34-ce1380e376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling du# Handling duplicates\n",
    "#aggregated_total_durations_df2.drop_duplicates(inplace=True)  # Remove duplicate rowsplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff37f00e-5bfc-4898-9d25-43652b4b4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "1     2301  107689605   1451710              76           56.0   \n",
      "3     2301  107710853   1775253              11            0.0   \n",
      "4     2301  107734582   1775253              57           37.0   \n",
      "5     2301  107755257   1775253              69           48.0   \n",
      "6     2301  107765823   1520984              31           19.0   \n",
      "..     ...        ...       ...             ...            ...   \n",
      "77    2305  107856518   1451710              28           10.0   \n",
      "79    2305  107915804   1775253              12            0.0   \n",
      "80    2305  107934335   1451710              25            5.0   \n",
      "81    2305  108067816   1775253              64           44.0   \n",
      "82    2305  108084747   1775253              35           15.0   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "1                2340  1528.100         57.9004                   10.0   \n",
      "3                3458  1631.900        148.3545                   21.0   \n",
      "4                3171  1630.000         58.6553                   10.0   \n",
      "5                3703  1631.300         23.6420                   21.0   \n",
      "6                1969   909.847         29.3499                   12.0   \n",
      "..                ...       ...             ...                    ...   \n",
      "77               5436  1526.400        133.5525                   10.0   \n",
      "79               3918  1631.400        135.9500                   21.0   \n",
      "80               4984  1526.498        123.9041                   10.0   \n",
      "81               3935  1630.900         71.0260                   10.0   \n",
      "82               4425  1630.100         93.2281                   10.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "1            79.016  \n",
      "3            79.016  \n",
      "4            79.016  \n",
      "5            79.016  \n",
      "6            79.016  \n",
      "..              ...  \n",
      "77           79.016  \n",
      "79           79.016  \n",
      "80           79.016  \n",
      "81           79.016  \n",
      "82           79.016  \n",
      "\n",
      "[67 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank23_df = pd.DataFrame(aggregated_total_durations_df2)\n",
    "ProductionTank23_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "  ProductionTank23_df = remove_outliers_iqr(ProductionTank23_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank23_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea6a804-d22e-41f5-9e07-92934bbc8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "1     2301  107689605   1451710        1.708235       1.852998   \n",
      "3     2301  107710853   1775253       -1.058356      -0.890667   \n",
      "4     2301  107734582   1775253        0.899539       0.922111   \n",
      "5     2301  107755257   1775253        1.410295       1.461046   \n",
      "6     2301  107765823   1520984       -0.207097       0.040219   \n",
      "..     ...        ...       ...             ...            ...   \n",
      "77    2305  107856518   1451710       -0.334786      -0.400727   \n",
      "79    2305  107915804   1775253       -1.015793      -0.890667   \n",
      "80    2305  107934335   1451710       -0.462475      -0.645697   \n",
      "81    2305  108067816   1775253        1.197480       1.265069   \n",
      "82    2305  108084747   1775253       -0.036846      -0.155757   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "1           -0.520010  1528.100       -0.982473                   10.0   \n",
      "3            0.297688  1631.900        0.939759                   21.0   \n",
      "4            0.087778  1630.000       -0.966431                   10.0   \n",
      "5            0.476879  1631.300       -1.710496                   21.0   \n",
      "6           -0.791357   909.847       -1.589198                   12.0   \n",
      "..                ...       ...             ...                    ...   \n",
      "77           1.744384  1526.400        0.625203                   10.0   \n",
      "79           0.634129  1631.400        0.676152                   21.0   \n",
      "80           1.413794  1526.498        0.420166                   10.0   \n",
      "81           0.646563  1630.900       -0.703542                   10.0   \n",
      "82           1.004945  1630.100       -0.231727                   10.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "1            79.016  \n",
      "3            79.016  \n",
      "4            79.016  \n",
      "5            79.016  \n",
      "6            79.016  \n",
      "..              ...  \n",
      "77           79.016  \n",
      "79           79.016  \n",
      "80           79.016  \n",
      "81           79.016  \n",
      "82           79.016  \n",
      "\n",
      "[67 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "ProductionTank23_df[numerical_cols] = scaler.fit_transform(ProductionTank23_df[numerical_cols])\n",
    "print(ProductionTank23_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58871e9d-b507-493d-8245-6443bda1dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Summary Statistics:\n",
      "            Tank_1       BATCHID      Material  Phase_duration  Phase_overrun  \\\n",
      "count    83.000000  8.300000e+01  8.300000e+01       83.000000      83.000000   \n",
      "mean   2303.216867  1.077971e+08  1.630871e+06       57.650602      39.433735   \n",
      "std       1.498358  1.264593e+05  1.490411e+05       66.279238      64.103231   \n",
      "min    2301.000000  1.075483e+08  1.397022e+06        5.000000       0.000000   \n",
      "25%    2302.000000  1.077034e+08  1.451710e+06       17.000000       0.000000   \n",
      "50%    2304.000000  1.077906e+08  1.698522e+06       35.000000      13.000000   \n",
      "75%    2305.000000  1.078705e+08  1.775253e+06       65.500000      45.000000   \n",
      "max    2305.000000  1.080847e+08  1.775253e+06      373.000000     352.000000   \n",
      "\n",
      "       Phase_start_delay     Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count          83.000000    83.000000       83.000000              83.000000   \n",
      "mean         3054.759036  1632.983361      111.188980              13.656627   \n",
      "std          1329.305757   413.375362       73.279449               5.365272   \n",
      "min            28.000000   789.200000        4.373700              10.000000   \n",
      "25%          2020.500000  1526.500000       65.517250              10.000000   \n",
      "50%          3195.000000  1631.200000       98.385400              10.000000   \n",
      "75%          3889.500000  1632.600000      135.950000              19.000000   \n",
      "max          5526.000000  2448.000000      416.985100              31.000000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count        83.000000  \n",
      "mean         78.278455  \n",
      "std           3.006794  \n",
      "min          65.412400  \n",
      "25%          79.016000  \n",
      "50%          79.016000  \n",
      "75%          79.016000  \n",
      "max          79.016000  \n",
      "\n",
      "Cleaned DataFrame Summary Statistics:\n",
      "            Tank_1       BATCHID      Material  Phase_duration  Phase_overrun  \\\n",
      "count    67.000000  6.700000e+01  6.700000e+01    6.700000e+01   6.700000e+01   \n",
      "mean   2303.208955  1.078047e+08  1.629666e+06   -4.277258e-17   4.142623e-18   \n",
      "std       1.482599  1.249202e+05  1.455610e+05    1.007547e+00   1.007547e+00   \n",
      "min    2301.000000  1.075483e+08  1.397022e+06   -1.186045e+00  -8.906674e-01   \n",
      "25%    2302.000000  1.077346e+08  1.451710e+06   -8.668230e-01  -8.906674e-01   \n",
      "50%    2304.000000  1.077906e+08  1.698522e+06   -2.496603e-01  -4.007272e-01   \n",
      "75%    2304.500000  1.078884e+08  1.775253e+06    6.867246e-01   6.526442e-01   \n",
      "max    2305.000000  1.080847e+08  1.775253e+06    2.857435e+00   3.224830e+00   \n",
      "\n",
      "       Phase_start_delay     Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count       6.700000e+01    67.000000    6.700000e+01              67.000000   \n",
      "mean       -2.319869e-17  1580.513746    2.232874e-16              14.097015   \n",
      "std         1.007547e+00   392.748729    1.007547e+00               5.606570   \n",
      "min        -2.210991e+00   789.200000   -1.763181e+00              10.000000   \n",
      "25%        -7.950136e-01  1526.300000   -7.152612e-01              10.000000   \n",
      "50%         1.228850e-01  1631.200000    9.805724e-02              12.000000   \n",
      "75%         6.403457e-01  1631.950000    6.570765e-01              20.000000   \n",
      "max         1.810209e+00  2448.000000    2.488144e+00              31.000000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count        67.000000  \n",
      "mean         78.305364  \n",
      "std           2.932584  \n",
      "min          65.412400  \n",
      "25%          79.016000  \n",
      "50%          79.016000  \n",
      "75%          79.016000  \n",
      "max          79.016000  \n"
     ]
    }
   ],
   "source": [
    "# For the original DataFrame\n",
    "print(\"Original DataFrame Summary Statistics:\")\n",
    "print(aggregated_total_durations_df2.describe())\n",
    "\n",
    "# After removing outliers\n",
    "print(\"\\nCleaned DataFrame Summary Statistics:\")\n",
    "print(ProductionTank23_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32eccb79-e88b-4cd5-baa7-968f0f166525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.0214166   | 0.0199991  |  0.979592  |  0.970223 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.0221105   | 0.0191341  |  0.978931  |  0.971511 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.988926    | 0.78184    |  0.0576573 | -0.164079 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0420116   | 0.0341747  |  0.959967  |  0.949117 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 0.00716078  | 0.0320946  |  0.993177  |  0.952214 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0.0523743   | 0.0373796  |  0.950093  |  0.944346 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0080847   | 0.0283886  |  0.992296  |  0.957732 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.00800853  | 0.0246524  |  0.992369  |  0.963295 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 1.50088e-30 | 0.00249046 |  1         |  0.996292 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank2203_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_start_delay'], axis=1)\n",
    "\n",
    "#y = df['Phase_start_delay']\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Tank_1','BATCHID','Material','Target_Phase_duration','Target_Flowrate','Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "#gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=5, subsample=0.8, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "#dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('23DEresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f92c41cc-63b5-4881-9886-35d8d3f00469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.028346\n",
      "  Std MSE: 0.016381\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.029939\n",
      "  Std MSE: 0.016845\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 0.961107\n",
      "  Std MSE: 0.218244\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.052480\n",
      "  Std MSE: 0.041373\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.041611\n",
      "  Std MSE: 0.034612\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.088262\n",
      "  Std MSE: 0.202847\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 308.946481\n",
      "  Std MSE: 594.716188\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.072463\n",
      "  Std MSE: 0.063194\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.072879\n",
      "  Std MSE: 0.052874\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.052770\n",
      "  Std MSE: 0.043338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "    \n",
    "      # Save the results to an Excel file\n",
    "df.to_excel(\"23DEmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model. You can then open this file with Excel to view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "245d25b8-fb9d-46b2-8aef-b2c04bdf2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge Regression: {'alpha': 0.01}\n",
      "Best parameters for Lasso Regression: {'alpha': 0.01}\n",
      "Best parameters for Random Forest Regressor: {'max_depth': 20, 'n_estimators': 300}\n",
      "Best parameters for Gradient Boosting Regressor: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Best parameters for Decision Tree Regressor: {'max_depth': 10}\n",
      "Best parameters for Bagging Regressor: {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 50}\n",
      "                         Model     Train MSE  Test MSE  Train R2   Test R2\n",
      "0            Linear Regression  2.144703e-02  0.020615  0.979563  0.969307\n",
      "1             Ridge Regression  2.144710e-02  0.020603  0.979563  0.969325\n",
      "2             Lasso Regression  2.200827e-02  0.019079  0.979028  0.971593\n",
      "3      Random Forest Regressor  7.333355e-03  0.022764  0.993012  0.966106\n",
      "4  Gradient Boosting Regressor  5.504670e-07  0.008354  0.999999  0.987562\n",
      "5      Decision Tree Regressor  3.348938e-32  0.027433  1.000000  0.959155\n",
      "6            Bagging Regressor  9.191484e-03  0.025474  0.991241  0.962072\n",
      "7           AdaBoost Regressor  7.630399e-03  0.022065  0.992729  0.967147\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.021447    | 0.0206147  |   0.979563 |  0.969307 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.0214471   | 0.0206027  |   0.979563 |  0.969325 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.0220083   | 0.0190793  |   0.979028 |  0.971593 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.00733335  | 0.0227644  |   0.993012 |  0.966106 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 5.50467e-07 | 0.00835356 |   0.999999 |  0.987562 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 3.34894e-32 | 0.0274333  |   1        |  0.959155 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.00919148  | 0.0254737  |   0.991241 |  0.962072 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.0076304   | 0.0220652  |   0.992729 |  0.967147 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Tank_1','BATCHID','Material','Phase_start_delay','Target_Phase_duration','Target_Flowrate','Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Ridge Regression: {ridge_grid.best_params_}\")\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Lasso Regression: {lasso_grid.best_params_}\")\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Random Forest Regressor: {rf_grid.best_params_}\")\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Gradient Boosting Regressor: {gb_grid.best_params_}\")\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Decision Tree Regressor: {dt_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Bagging Regressor: {bag_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('23DEresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd1f922b-5884-4c2d-9c02-421aff9d9dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|    | Model                     |   Train MSE |    Test MSE |     Train R2 |      Test R2 |\n",
      "+====+===========================+=============+=============+==============+==============+\n",
      "|  0 | LinearRegression          | 0.0184789   | 0.0287615   |  0.981514    |  0.970819    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  1 | Ridge                     | 0.0192559   | 0.0297736   |  0.980725    |  0.969598    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  2 | Lasso                     | 0.902629    | 1.06504     |  0.0959689   | -0.120407    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  3 | RandomForestRegressor     | 0.00988457  | 0.0854889   |  0.990124    |  0.911468    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  4 | GradientBoostingRegressor | 8.79162e-06 | 0.0743214   |  0.999991    |  0.925635    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  5 | SVR                       | 1.13969     | 1.17656     | -0.14244     | -0.204684    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  6 | MLPRegressor              | 5.11228e+12 | 5.12083e+12 | -5.56744e+12 | -4.00616e+12 |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  7 | DecisionTreeRegressor     | 2.35502e-32 | 0.0772406   |  1           |  0.914804    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  8 | BaggingRegressor          | 0.00931922  | 0.0887159   |  0.990673    |  0.906369    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  9 | AdaBoostRegressor         | 0.00783577  | 0.0976631   |  0.992139    |  0.900103    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Initialize k-fold cross-validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Iterate through each model and perform k-fold cross-validation\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    train_mse_list = []\n",
    "    test_mse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_mse_list.append(train_mse)\n",
    "        test_mse_list.append(test_mse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "    \n",
    "    mean_train_mse = sum(train_mse_list) / num_folds\n",
    "    mean_test_mse = sum(test_mse_list) / num_folds\n",
    "    mean_train_r2 = sum(train_r2_list) / num_folds\n",
    "    mean_test_r2 = sum(test_r2_list) / num_folds\n",
    "    \n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': mean_train_mse, 'Test MSE': mean_test_mse,\n",
    "                                    'Train R2': mean_train_r2, 'Test R2': mean_test_r2}, ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('23MT DEAkfold_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f5e2c3f-0d5e-4062-9071-6f04814c8c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |   0.269522  |  0.327828  |   0.743174 |  0.511898 |      0.391823 |     0.212747 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |   0.0560309 |  0.0895985 |   0.946608 |  0.866597 |      0.27181  |     0.196097 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters for K-Nearest Neighbors: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for Support Vector Machine: {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |  0          | 0.385077   |    1       |  0.426661 |     0.328658  |    0.148207  |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |  0.00804926 | 0.00593723 |    0.99233 |  0.99116  |     0.0141653 |    0.0061096 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('23MT DEAknn_svm_results_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "976f7010-39dc-43d3-8256-9eed1da8d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |   0.0214876 |  0.0920319 |   0.979525 |  0.862974 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |   0.0214876 |  0.0920319 |   0.979525 |  0.862974 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|  1 | LSTM Neural Network   |   0.263308  |  0.309494  |   0.749095 |  0.539195 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('23MTDEALSTMSNN Neural Network.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d847f78-a382-4184-81be-9a6e687d7282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0B10C9D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0B10C9A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best Simple NN Params: {'batch_size': 32, 'dense1_neurons': 128, 'dense2_neurons': 64, 'epochs': 50}\n",
      "Training MSE: 0.0014226079174631087\n",
      "Training R^2: 0.9986444033126834\n",
      "Test MSE: 0.05681178562807777\n",
      "Test R^2: 0.915413125681471\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be5d67dd-0a4a-4d3d-bd58-d7a2e64cc163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best LSTM Params: {'batch_size': 16, 'epochs': 100, 'lstm_neurons': 70}\n",
      "Training MSE for LSTM: 0.011386580999302261\n",
      "Training R^2 for LSTM: 0.9891497781693485\n",
      "Test MSE for LSTM: 0.08852956287704815\n",
      "Test R^2 for LSTM: 0.868188635055783\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6749532-9a07-435f-989c-0d5b2acd38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|    |   param_neurons_layer1 |   param_neurons_layer2 |   param_batch_size |   param_epochs |   mean_test_score |   std_test_score |   rank_test_score |\n",
      "+====+========================+========================+====================+================+===================+==================+===================+\n",
      "|  0 |                     32 |                     16 |                 32 |             50 |        -0.330759  |        0.124844  |                 5 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  1 |                    128 |                     64 |                 32 |             50 |        -0.114894  |        0.0467523 |                 3 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  2 |                     64 |                     16 |                 16 |            100 |        -0.16401   |        0.0330945 |                 4 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  3 |                     64 |                     32 |                 16 |             50 |        -0.093884  |        0.0492752 |                 2 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  4 |                    128 |                     16 |                 64 |            100 |        -0.0911938 |        0.0313293 |                 1 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "Best Simple NN Params: {'neurons_layer2': 16, 'neurons_layer1': 128, 'epochs': 100, 'batch_size': 64}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|    |   param_lstm_neurons |   param_batch_size |   param_epochs |   mean_test_score |   std_test_score |   rank_test_score |\n",
      "+====+======================+====================+================+===================+==================+===================+\n",
      "|  0 |                   30 |                 64 |             30 |         -0.978917 |        0.123891  |                 5 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  1 |                   70 |                 32 |             50 |         -0.54907  |        0.138927  |                 3 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  2 |                   50 |                 16 |             50 |         -0.400518 |        0.111913  |                 2 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  3 |                   70 |                 32 |             30 |         -0.78262  |        0.16505   |                 4 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  4 |                   70 |                 32 |            100 |         -0.230393 |        0.0545701 |                 1 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "Best LSTM Params: {'lstm_neurons': 70, 'epochs': 100, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('simple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('23MTDEALSTM_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9064ded4-a829-4fd6-a9a8-c972fa1150e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+======================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network | 0.000558408 |  0.0656179 |   0.999468 |  0.902302 |\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "Best Score:  -0.08296381185452144\n",
      "Best Params:  {'neurons_layer3': 64, 'neurons_layer2': 128, 'neurons_layer1': 256, 'epochs': 100, 'batch_size': 32}\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                            |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+==================================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network             | 0.000558408 |  0.0656179 |   0.999468 |  0.902302 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Dense Neural Network (Optimized) | 2.10418e-05 |  0.0482406 |   0.99998  |  0.928175 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Dense Neural Network (Optimized) | 2.10418e-05 |  0.0482406 |   0.99998  |  0.928175 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('neural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results_df.to_excel('23MTDEAdenseNN_results.xlsx', index=False)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd3146-70f7-4151-93ae-462b2ff85d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

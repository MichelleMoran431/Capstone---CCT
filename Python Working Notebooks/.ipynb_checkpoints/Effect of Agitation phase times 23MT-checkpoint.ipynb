{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8647a856-714f-4998-a553-b00d33956887",
   "metadata": {},
   "source": [
    "### Agitation on Production tanks - 23MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351e04f5-c156-43f5-b04f-7aa88e1e6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac75ad5-8489-43d2-a1c5-a7912cb763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a42ef6-82d3-4d16-a479-1f451969c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Material    BATCHID Tank_1             Instruction_Step  \\\n",
       "0           0   1002150  107643491   2503         S3_BATCH_IN_PROGRESS   \n",
       "1           1   1002150  107643491   2503                   STEP1_CONS   \n",
       "2           2   1002150  107643491   2503  PLEASE VERIFY BULK ADDITION   \n",
       "3           3   1002150  107643491   2503                   STEP1_CONS   \n",
       "4           4   1002150  107643491   2503                   STEP1_CONS   \n",
       "\n",
       "  INGRED_ID                           INGRED_Name  Quantity       Phase_start  \\\n",
       "0       NaN                                   NaN     0.000  09/03/2022 10:42   \n",
       "1   1002565                         WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2       NaN                                   NaN     0.000  09/03/2022 11:16   \n",
       "3   1037802  S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4   1002818  S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "\n",
       "          Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0  09/03/2022 10:42               0                  0             1   \n",
       "1  09/03/2022 11:16              34                  0             2   \n",
       "2  09/03/2022 11:17               1                  0             3   \n",
       "3  09/03/2022 11:27              10                  0             4   \n",
       "4  09/03/2022 11:38              11                  0             5   \n",
       "\n",
       "   Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0          0.0000              NaN                      0            NaN   \n",
       "1        169.4118         733.5050                      8           26.0   \n",
       "2          0.0000              NaN                      3            0.0   \n",
       "3          0.5629           6.3182                      1            9.0   \n",
       "4          7.1605           6.3182                     12            0.0   \n",
       "\n",
       "   Deaeration Phase  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ProductionTank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf73d0c-7499-465d-8d22-5701d012c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d952e0-5808-4a32-bbe3-848e6474712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.DataFrame(ProductionTank) \n",
    "# Count the unique materialsProductionTank produced by each tank\n",
    "Batch_counts =ProductionTank.groupby('Tank_1')['BATCHID'].nunique().reset_index()\n",
    "#print(Batch_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66ed9fe5-3991-4a56-8002-6e20104f27c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "0    2302  107553571              51            1.0               4222   \n",
      "1    2302  107569832              91            1.0               2731   \n",
      "2    2302  107593359              61            1.0                  1   \n",
      "3    2302  107609177              90            0.0                  0   \n",
      "4    2302  107622258             135            0.0                  1   \n",
      "..    ...        ...             ...            ...                ...   \n",
      "77   2305  107899895              50            0.0                  2   \n",
      "78   2305  107915804              90            0.0                  2   \n",
      "79   2305  107934335              95            0.0                  2   \n",
      "80   2305  108067816              90            0.0                  1   \n",
      "81   2305  108084747              90            0.0                  2   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "0        0.0             0.0              16.666667              NaN  \n",
      "1        0.0             0.0              30.000000              NaN  \n",
      "2        0.0             0.0              20.000000              NaN  \n",
      "3        0.0             0.0              30.000000              NaN  \n",
      "4        0.0             0.0              33.750000              NaN  \n",
      "..       ...             ...                    ...              ...  \n",
      "77       0.0             0.0              16.666667              NaN  \n",
      "78       0.0             0.0              30.000000              NaN  \n",
      "79       0.0             0.0              31.666667              NaN  \n",
      "80       0.0             0.0              30.000000              NaN  \n",
      "81       0.0             0.0              30.000000              NaN  \n",
      "\n",
      "[82 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = ['2301','2302','2304','2305']\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP1_AGITATION', 'STEP2_AGITATION','STEP3_AGITATION']\n",
    "filtered_data = data[(data['Instruction_Step'].isin(desired_steps)) & (data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'Material'])['Phase_duration'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Visualization using bar plots\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=total_durations, x='Tank_1', y='Phase_duration',ci=None)\n",
    "plt.title('Phase_duration for Each Tank by Phase')\n",
    "plt.ylabel('Phase_duration')\n",
    "plt.xlabel('Tank')\n",
    "plt.legend(title='Phase_duration')\n",
    "plt.show()\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df3 = filtered_data.groupby(['Tank_1','BATCHID']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    " #Print the aggregated DataFrame\n",
    "print(aggregated_total_durations_df3)\n",
    "\n",
    "aggregated_total_durations_df3.to_csv('Agitation23MT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a96ae54-4318-49bd-9508-ec5baf5f42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "#aggregated_total_durations_df3.dropna(inplace=True)  # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a432170-b7e7-4193-ab58-f066eb7ca0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling du# Handling duplicates\n",
    "#aggregated_total_durations_df3.drop_duplicates(inplace=True)  # Remove duplicate rowsplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e85f8ce-adf8-4eaf-a000-2d08075992b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "3    2302  107609177              90            0.0                  0   \n",
      "5    2302  107641913              90            0.0                  2   \n",
      "6    2302  107650387              90            0.0                  2   \n",
      "7    2302  107659927              91            1.0                  0   \n",
      "8    2302  107671476              90            0.0                  1   \n",
      "12   2302  107734577              92            2.0                  0   \n",
      "14   2302  107749891              91            1.0                 11   \n",
      "15   2302  107790571              90            0.0                  2   \n",
      "17   2302  107818428              90            0.0                  1   \n",
      "20   2302  107884494              90            0.0                  1   \n",
      "24   2302  107926370              91            1.0                  0   \n",
      "26   2302  108067815              91            1.0                 21   \n",
      "27   2302  108084745              91            1.0                  0   \n",
      "28   2304  107548331              91            1.0                  1   \n",
      "32   2304  107618350              90            0.0                  1   \n",
      "36   2304  107734590              91            1.0                  1   \n",
      "37   2304  107749892              92            2.0                  0   \n",
      "39   2304  107781794              92            2.0                 10   \n",
      "44   2304  107833744              91            1.0                  4   \n",
      "45   2304  107845579              90            0.0                  3   \n",
      "46   2304  107848869              92            2.0                  0   \n",
      "48   2304  107887070              90            0.0                  1   \n",
      "49   2304  107915805              90            0.0                  2   \n",
      "50   2304  107926371              90            0.0                 16   \n",
      "55   2304  108084746              90            0.0                  1   \n",
      "58   2305  107591051              91            1.0                  2   \n",
      "61   2305  107650388              91            1.0                  1   \n",
      "62   2305  107659907              90            0.0                  2   \n",
      "63   2305  107689631              90            0.0                  1   \n",
      "68   2305  107771598              91            1.0                  2   \n",
      "69   2305  107781795              90            0.0                  3   \n",
      "70   2305  107790572              90            0.0                  2   \n",
      "72   2305  107802618              91            1.0                  1   \n",
      "73   2305  107818427              90            0.0                  3   \n",
      "74   2305  107845580              91            1.0                  0   \n",
      "75   2305  107848870              90            0.0                  2   \n",
      "78   2305  107915804              90            0.0                  2   \n",
      "80   2305  108067816              90            0.0                  1   \n",
      "81   2305  108084747              90            0.0                  2   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "3        0.0             0.0                   30.0              NaN  \n",
      "5        0.0             0.0                   30.0              NaN  \n",
      "6        0.0             0.0                   30.0              NaN  \n",
      "7        0.0             0.0                   30.0              NaN  \n",
      "8        0.0             0.0                   30.0              NaN  \n",
      "12       0.0             0.0                   30.0              NaN  \n",
      "14       0.0             0.0                   30.0              NaN  \n",
      "15       0.0             0.0                   30.0              NaN  \n",
      "17       0.0             0.0                   30.0              NaN  \n",
      "20       0.0             0.0                   30.0              NaN  \n",
      "24       0.0             0.0                   30.0              NaN  \n",
      "26       0.0             0.0                   30.0              NaN  \n",
      "27       0.0             0.0                   30.0              NaN  \n",
      "28       0.0             0.0                   30.0              NaN  \n",
      "32       0.0             0.0                   30.0              NaN  \n",
      "36       0.0             0.0                   30.0              NaN  \n",
      "37       0.0             0.0                   30.0              NaN  \n",
      "39       0.0             0.0                   30.0              NaN  \n",
      "44       0.0             0.0                   30.0              NaN  \n",
      "45       0.0             0.0                   30.0              NaN  \n",
      "46       0.0             0.0                   30.0              NaN  \n",
      "48       0.0             0.0                   30.0              NaN  \n",
      "49       0.0             0.0                   30.0              NaN  \n",
      "50       0.0             0.0                   30.0              NaN  \n",
      "55       0.0             0.0                   30.0              NaN  \n",
      "58       0.0             0.0                   30.0              NaN  \n",
      "61       0.0             0.0                   30.0              NaN  \n",
      "62       0.0             0.0                   30.0              NaN  \n",
      "63       0.0             0.0                   30.0              NaN  \n",
      "68       0.0             0.0                   30.0              NaN  \n",
      "69       0.0             0.0                   30.0              NaN  \n",
      "70       0.0             0.0                   30.0              NaN  \n",
      "72       0.0             0.0                   30.0              NaN  \n",
      "73       0.0             0.0                   30.0              NaN  \n",
      "74       0.0             0.0                   30.0              NaN  \n",
      "75       0.0             0.0                   30.0              NaN  \n",
      "78       0.0             0.0                   30.0              NaN  \n",
      "80       0.0             0.0                   30.0              NaN  \n",
      "81       0.0             0.0                   30.0              NaN  \n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank23_df = pd.DataFrame(aggregated_total_durations_df3)\n",
    "#ProductionTank23_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank23_df = remove_outliers_iqr(ProductionTank23_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank23_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ea6a804-d22e-41f5-9e07-92934bbc8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "3    2302  107609177       -0.799456      -0.799456          -0.620466   \n",
      "5    2302  107641913       -0.799456      -0.799456          -0.159548   \n",
      "6    2302  107650387       -0.799456      -0.799456          -0.159548   \n",
      "7    2302  107659927        0.685248       0.685248          -0.620466   \n",
      "8    2302  107671476       -0.799456      -0.799456          -0.390007   \n",
      "12   2302  107734577        2.169953       2.169953          -0.620466   \n",
      "14   2302  107749891        0.685248       0.685248           1.914581   \n",
      "15   2302  107790571       -0.799456      -0.799456          -0.159548   \n",
      "17   2302  107818428       -0.799456      -0.799456          -0.390007   \n",
      "20   2302  107884494       -0.799456      -0.799456          -0.390007   \n",
      "24   2302  107926370        0.685248       0.685248          -0.620466   \n",
      "26   2302  108067815        0.685248       0.685248           4.219168   \n",
      "27   2302  108084745        0.685248       0.685248          -0.620466   \n",
      "28   2304  107548331        0.685248       0.685248          -0.390007   \n",
      "32   2304  107618350       -0.799456      -0.799456          -0.390007   \n",
      "36   2304  107734590        0.685248       0.685248          -0.390007   \n",
      "37   2304  107749892        2.169953       2.169953          -0.620466   \n",
      "39   2304  107781794        2.169953       2.169953           1.684122   \n",
      "44   2304  107833744        0.685248       0.685248           0.301369   \n",
      "45   2304  107845579       -0.799456      -0.799456           0.070910   \n",
      "46   2304  107848869        2.169953       2.169953          -0.620466   \n",
      "48   2304  107887070       -0.799456      -0.799456          -0.390007   \n",
      "49   2304  107915805       -0.799456      -0.799456          -0.159548   \n",
      "50   2304  107926371       -0.799456      -0.799456           3.066875   \n",
      "55   2304  108084746       -0.799456      -0.799456          -0.390007   \n",
      "58   2305  107591051        0.685248       0.685248          -0.159548   \n",
      "61   2305  107650388        0.685248       0.685248          -0.390007   \n",
      "62   2305  107659907       -0.799456      -0.799456          -0.159548   \n",
      "63   2305  107689631       -0.799456      -0.799456          -0.390007   \n",
      "68   2305  107771598        0.685248       0.685248          -0.159548   \n",
      "69   2305  107781795       -0.799456      -0.799456           0.070910   \n",
      "70   2305  107790572       -0.799456      -0.799456          -0.159548   \n",
      "72   2305  107802618        0.685248       0.685248          -0.390007   \n",
      "73   2305  107818427       -0.799456      -0.799456           0.070910   \n",
      "74   2305  107845580        0.685248       0.685248          -0.620466   \n",
      "75   2305  107848870       -0.799456      -0.799456          -0.159548   \n",
      "78   2305  107915804       -0.799456      -0.799456          -0.159548   \n",
      "80   2305  108067816       -0.799456      -0.799456          -0.390007   \n",
      "81   2305  108084747       -0.799456      -0.799456          -0.159548   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "3        0.0             0.0                   30.0              NaN  \n",
      "5        0.0             0.0                   30.0              NaN  \n",
      "6        0.0             0.0                   30.0              NaN  \n",
      "7        0.0             0.0                   30.0              NaN  \n",
      "8        0.0             0.0                   30.0              NaN  \n",
      "12       0.0             0.0                   30.0              NaN  \n",
      "14       0.0             0.0                   30.0              NaN  \n",
      "15       0.0             0.0                   30.0              NaN  \n",
      "17       0.0             0.0                   30.0              NaN  \n",
      "20       0.0             0.0                   30.0              NaN  \n",
      "24       0.0             0.0                   30.0              NaN  \n",
      "26       0.0             0.0                   30.0              NaN  \n",
      "27       0.0             0.0                   30.0              NaN  \n",
      "28       0.0             0.0                   30.0              NaN  \n",
      "32       0.0             0.0                   30.0              NaN  \n",
      "36       0.0             0.0                   30.0              NaN  \n",
      "37       0.0             0.0                   30.0              NaN  \n",
      "39       0.0             0.0                   30.0              NaN  \n",
      "44       0.0             0.0                   30.0              NaN  \n",
      "45       0.0             0.0                   30.0              NaN  \n",
      "46       0.0             0.0                   30.0              NaN  \n",
      "48       0.0             0.0                   30.0              NaN  \n",
      "49       0.0             0.0                   30.0              NaN  \n",
      "50       0.0             0.0                   30.0              NaN  \n",
      "55       0.0             0.0                   30.0              NaN  \n",
      "58       0.0             0.0                   30.0              NaN  \n",
      "61       0.0             0.0                   30.0              NaN  \n",
      "62       0.0             0.0                   30.0              NaN  \n",
      "63       0.0             0.0                   30.0              NaN  \n",
      "68       0.0             0.0                   30.0              NaN  \n",
      "69       0.0             0.0                   30.0              NaN  \n",
      "70       0.0             0.0                   30.0              NaN  \n",
      "72       0.0             0.0                   30.0              NaN  \n",
      "73       0.0             0.0                   30.0              NaN  \n",
      "74       0.0             0.0                   30.0              NaN  \n",
      "75       0.0             0.0                   30.0              NaN  \n",
      "78       0.0             0.0                   30.0              NaN  \n",
      "80       0.0             0.0                   30.0              NaN  \n",
      "81       0.0             0.0                   30.0              NaN  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "ProductionTank23_df[numerical_cols] = scaler.fit_transform(ProductionTank23_df[numerical_cols])\n",
    "print(ProductionTank23_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58871e9d-b507-493d-8245-6443bda1dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Summary Statistics:\n",
      "            BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "count  8.200000e+01       82.000000       82.00000          82.000000   \n",
      "mean   1.077787e+08       87.256098        0.50000         391.987805   \n",
      "std    1.399699e+05       22.020087        0.67128        1045.916144   \n",
      "min    1.075483e+08       31.000000        0.00000           0.000000   \n",
      "25%    1.076628e+08       90.000000        0.00000           1.000000   \n",
      "50%    1.077862e+08       90.000000        0.00000           2.000000   \n",
      "75%    1.078775e+08       91.750000        1.00000           8.500000   \n",
      "max    1.080847e+08      165.000000        3.00000        4719.000000   \n",
      "\n",
      "       Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "count      82.0            82.0              82.000000              0.0  \n",
      "mean        0.0             0.0              28.585366              NaN  \n",
      "std         0.0             0.0               5.815920              NaN  \n",
      "min         0.0             0.0              15.000000              NaN  \n",
      "25%         0.0             0.0              30.000000              NaN  \n",
      "50%         0.0             0.0              30.000000              NaN  \n",
      "75%         0.0             0.0              30.000000              NaN  \n",
      "max         0.0             0.0              55.000000              NaN  \n",
      "\n",
      "Cleaned DataFrame Summary Statistics:\n",
      "            BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "count  3.900000e+01    3.900000e+01   3.900000e+01       3.900000e+01   \n",
      "mean   1.078047e+08    8.033460e-15   1.708035e-17      -8.469009e-17   \n",
      "std    1.450411e+05    1.013072e+00   1.013072e+00       1.013072e+00   \n",
      "min    1.075483e+08   -7.994563e-01  -7.994563e-01      -6.204660e-01   \n",
      "25%    1.076806e+08   -7.994563e-01  -7.994563e-01      -3.900072e-01   \n",
      "50%    1.077906e+08   -7.994563e-01  -7.994563e-01      -3.900072e-01   \n",
      "75%    1.078858e+08    6.852483e-01   6.852483e-01      -1.595484e-01   \n",
      "max    1.080847e+08    2.169953e+00   2.169953e+00       4.219168e+00   \n",
      "\n",
      "       Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "count      39.0            39.0                   39.0              0.0  \n",
      "mean        0.0             0.0                   30.0              NaN  \n",
      "std         0.0             0.0                    0.0              NaN  \n",
      "min         0.0             0.0                   30.0              NaN  \n",
      "25%         0.0             0.0                   30.0              NaN  \n",
      "50%         0.0             0.0                   30.0              NaN  \n",
      "75%         0.0             0.0                   30.0              NaN  \n",
      "max         0.0             0.0                   30.0              NaN  \n"
     ]
    }
   ],
   "source": [
    "# For the original DataFrame\n",
    "print(\"Original DataFrame Summary Statistics:\")\n",
    "print(aggregated_total_durations_df3.describe())\n",
    "\n",
    "# After removing outliers\n",
    "print(\"\\nCleaned DataFrame Summary Statistics:\")\n",
    "print(ProductionTank23_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32eccb79-e88b-4cd5-baa7-968f0f166525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |    Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+=============+============+===========+\n",
      "|  0 | Linear Regression           | 2.52761e-22 | 2.66024e-22 |   1        | 1         |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.00090062  | 0.000485243 |   0.999185 | 0.999061  |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.913215    | 0.504861    |   0.17402  | 0.0228065 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0781123   | 0.0248004   |   0.929349 | 0.951997  |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 0.00654582  | 0.00361073  |   0.994079 | 0.993011  |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 1.07355e-32 | 1.2326e-32  |   1        | 1         |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 2.84432e-05 | 9.36772e-31 |   0.999974 | 1         |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 1.07355e-32 | 1.2326e-32  |   1        | 1         |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 3.36379e-30 | 9.36772e-31 |   1        | 1         |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank2203_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun','Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate','Phase_start_delay'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "#gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=5, subsample=0.8, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "#dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('23AGresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f92c41cc-63b5-4881-9886-35d8d3f00469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.000000\n",
      "  Std MSE: 0.000000\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.001795\n",
      "  Std MSE: 0.001753\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.050411\n",
      "  Std MSE: 0.662985\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.030897\n",
      "  Std MSE: 0.060974\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.000000\n",
      "  Std MSE: 0.000000\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.465875\n",
      "  Std MSE: 0.993326\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 2584438687120.838867\n",
      "  Std MSE: 3144596581859.747070\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.000000\n",
      "  Std MSE: 0.000000\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.000000\n",
      "  Std MSE: 0.000000\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.020140\n",
      "  Std MSE: 0.038664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245d25b8-fb9d-46b2-8aef-b2c04bdf2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Model     Train MSE      Test MSE  Train R2   Test R2\n",
      "0            Linear Regression  2.527614e-22  2.660242e-22  1.000000  1.000000\n",
      "1             Ridge Regression  9.544423e-08  5.139569e-08  1.000000  1.000000\n",
      "2             Lasso Regression  9.132151e-05  5.048613e-05  0.999917  0.999902\n",
      "3      Random Forest Regressor  3.413184e-04  2.204348e-04  0.999691  0.999573\n",
      "4  Gradient Boosting Regressor  2.134876e-16  9.089359e-17  1.000000  1.000000\n",
      "5      Decision Tree Regressor  1.073551e-32  1.232595e-32  1.000000  1.000000\n",
      "6            Bagging Regressor  6.775297e-31  6.594384e-31  1.000000  1.000000\n",
      "7           AdaBoost Regressor  1.073551e-32  1.232595e-32  1.000000  1.000000\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |    Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+=============+============+===========+\n",
      "|  0 | Linear Regression           | 2.52761e-22 | 2.66024e-22 |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 9.54442e-08 | 5.13957e-08 |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 9.13215e-05 | 5.04861e-05 |   0.999917 |  0.999902 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.000341318 | 0.000220435 |   0.999691 |  0.999573 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 2.13488e-16 | 9.08936e-17 |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 1.07355e-32 | 1.2326e-32  |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 6.7753e-31  | 6.59438e-31 |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 1.07355e-32 | 1.2326e-32  |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank23_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('23AGresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f084a9-4d0e-4bde-a378-b69ef1f12cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c6928-13e4-446d-ba80-e12659b793d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745bb23-cb1e-4ec8-ab3f-c84d30dad6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af26fe-52b6-4a48-bc04-118a18961a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1228d9c-d0a3-44e8-b6f2-1299dc072911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2c3d2b-e866-4a84-91fb-8c3da5aedc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19268a8f-87e5-41cf-9209-ef912a4ead27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Material    BATCHID  Tank_1             Instruction_Step  \\\n",
       "0           0   1002150  107643491    2503         S3_BATCH_IN_PROGRESS   \n",
       "1           1   1002150  107643491    2503                   STEP1_CONS   \n",
       "2           2   1002150  107643491    2503  PLEASE VERIFY BULK ADDITION   \n",
       "3           3   1002150  107643491    2503                   STEP1_CONS   \n",
       "4           4   1002150  107643491    2503                   STEP1_CONS   \n",
       "\n",
       "  INGRED_ID                           INGRED_Name  Quantity       Phase_start  \\\n",
       "0       NaN                                   NaN     0.000  09/03/2022 10:42   \n",
       "1   1002565                         WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2       NaN                                   NaN     0.000  09/03/2022 11:16   \n",
       "3   1037802  S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4   1002818  S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "\n",
       "          Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0  09/03/2022 10:42               0                  0             1   \n",
       "1  09/03/2022 11:16              34                  0             2   \n",
       "2  09/03/2022 11:17               1                  0             3   \n",
       "3  09/03/2022 11:27              10                  0             4   \n",
       "4  09/03/2022 11:38              11                  0             5   \n",
       "\n",
       "   Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0          0.0000              NaN                      0            NaN   \n",
       "1        169.4118         733.5050                      8           26.0   \n",
       "2          0.0000              NaN                      3            0.0   \n",
       "3          0.5629           6.3182                      1            9.0   \n",
       "4          7.1605           6.3182                     12            0.0   \n",
       "\n",
       "   Deaeration Phase  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd80668-682b-40be-b18d-f1608e4f7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84fea0-9933-4710-afe2-74215bad517d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98f916a3-039c-4ba1-ad64-1194e757e8d3",
   "metadata": {},
   "source": [
    "## Examining the Phase Overrun duration times for the GUM ingredient addition - Addition of GUM ingredients to the specific production tanks based on their capacity\n",
    " This is completed manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38655ba8-6a76-44c3-b143-260d3ab5f1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "0     2501  107548283             307          276.0                  0   \n",
      "1     2501  107599589              20            8.0                  0   \n",
      "2     2501  107619398              55           32.0                  1   \n",
      "3     2501  107654587              10            8.0                  0   \n",
      "4     2501  107673784             140          120.0                  0   \n",
      "5     2501  107692170             140          123.0                  1   \n",
      "6     2501  107721584               9            7.0                  0   \n",
      "7     2501  107781849              14           12.0                  0   \n",
      "8     2501  107799508              60           42.0                  1   \n",
      "9     2501  107820047              64           50.0                  0   \n",
      "10    2501  107829242              63           61.0                  0   \n",
      "11    2501  107837364              14           12.0                  0   \n",
      "12    2501  107858284              82           65.0                  0   \n",
      "13    2501  107884951              27           15.0                  0   \n",
      "14    2501  107894171              16            4.0                  0   \n",
      "15    2501  107907568               2            0.0                  0   \n",
      "16    2501  107926373             408          393.0                  0   \n",
      "17    2501  107949933              10            8.0                  0   \n",
      "18    2501  107963440             225          211.0                  0   \n",
      "19    2501  107975586               6            4.0                  0   \n",
      "20    2501  108033842              57           43.0                  0   \n",
      "21    2501  108049009             193          173.0                  1   \n",
      "22    2501  108051967              60           44.0                  0   \n",
      "23    2501  108058736              19           17.0                  0   \n",
      "24    2501  108058739              56           41.0                  0   \n",
      "25    2501  108068562              30           13.0                  0   \n",
      "26    2502  107573888             326          305.0                  0   \n",
      "27    2502  107630217             328          310.0                  1   \n",
      "28    2502  107643502              27            6.0                  0   \n",
      "29    2502  107673347               8            6.0                  0   \n",
      "30    2502  107673776              91           79.0                  0   \n",
      "31    2502  107700722             165          145.0                  0   \n",
      "32    2502  107711607              14            2.0                  0   \n",
      "33    2502  107737576              20            8.0                  0   \n",
      "34    2502  107741788              20            0.0                  0   \n",
      "35    2502  107790594              42           30.0                  0   \n",
      "36    2502  107815341              83           66.0                  0   \n",
      "37    2502  107829240              12            0.0                  0   \n",
      "38    2502  107831024              18            3.0                  0   \n",
      "39    2502  107831025              84           68.0                  0   \n",
      "40    2502  107872046             204          168.0                  0   \n",
      "41    2502  107874920              33           19.0                  0   \n",
      "42    2502  107896329             127          111.0                  0   \n",
      "43    2502  107907571              24            4.0                  0   \n",
      "44    2502  107916897              13            0.0                  9   \n",
      "45    2502  107949935              96           75.0                  0   \n",
      "46    2502  107971789              80           65.0                  0   \n",
      "47    2502  108033836             134          119.0                  0   \n",
      "48    2502  108045551             117          103.0                  1   \n",
      "49    2502  108084758              83           63.0                  1   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "0    652.000         11.8456                   15.5         19.17085  \n",
      "1    172.600          8.6300                   12.0         14.87500  \n",
      "2    653.000         22.0803                   11.5         26.66825  \n",
      "3     15.077          1.5077                    2.0          6.31820  \n",
      "4    758.000          5.4143                   20.0         38.46150  \n",
      "5    640.000          4.5714                   17.0         38.46150  \n",
      "6     15.015          1.6683                    2.0          6.31820  \n",
      "7     15.035          1.0739                    2.0          6.31820  \n",
      "8    699.300         11.6550                   18.0         38.46150  \n",
      "9    530.400          8.2875                   14.0         38.46150  \n",
      "10    15.000          0.2381                    2.0          6.31820  \n",
      "11    15.046          1.0747                    2.0          6.31820  \n",
      "12   401.700          4.8988                   17.0         23.46670  \n",
      "13   172.083          6.3734                   12.0         14.87500  \n",
      "14   172.700         10.7937                   12.0         14.87500  \n",
      "15    15.033          7.5165                    2.0          6.31820  \n",
      "16   569.900          1.3968                   15.0         38.46150  \n",
      "17    14.017          1.4017                    2.0          6.31820  \n",
      "18   530.000          2.3556                   14.0         38.46150  \n",
      "19    14.600          2.4333                    2.0          6.31820  \n",
      "20   334.500          5.8684                   14.0         23.46670  \n",
      "21   758.000          3.9275                   20.0         38.46150  \n",
      "22   382.600          6.3767                   16.0         23.46670  \n",
      "23    14.531          0.7648                    2.0          6.31820  \n",
      "24   340.600          6.0821                   15.0         23.46670  \n",
      "25   397.800         13.2600                   17.0         23.46670  \n",
      "26   486.000          1.4908                   21.0         23.46670  \n",
      "27   676.000          2.0610                   18.0         38.46150  \n",
      "28   486.600         18.0222                   21.0         23.46670  \n",
      "29    15.042          1.8803                    2.0          6.31820  \n",
      "30   171.900          1.8890                   12.0         14.87500  \n",
      "31   757.605          4.5915                   20.0         38.46150  \n",
      "32   172.100         12.2929                   12.0         14.87500  \n",
      "33   204.245         10.2123                   12.0         17.00000  \n",
      "34   485.945         24.2972                   21.0         23.46670  \n",
      "35   173.000          4.1190                   12.0         14.87500  \n",
      "36   400.000          4.8193                   17.0         23.46670  \n",
      "37   172.300         14.3583                   12.0         14.87500  \n",
      "38   259.000         14.3889                   15.0         17.00000  \n",
      "39   367.200          4.3714                   16.0         23.46670  \n",
      "40   593.000          5.3187                   18.0         14.89245  \n",
      "41   530.200         16.0667                   14.0         38.46150  \n",
      "42   381.600          3.0047                   16.0         23.46670  \n",
      "43   758.400         31.6000                   20.0         38.46150  \n",
      "44   487.100         37.4692                   21.0         23.46670  \n",
      "45   486.014          5.0626                   21.0         23.46670  \n",
      "46   568.600          7.1075                   15.0         38.46150  \n",
      "47   569.100          4.2470                   15.0         38.46150  \n",
      "48   530.200          4.5316                   14.0         38.46150  \n",
      "49   756.600          9.1157                   20.0         38.46150  \n"
     ]
    }
   ],
   "source": [
    "specific_tanks = [2501, 2502]\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['1461896', '1254972', '1031006','1243269','1196706','1815609']\n",
    "filtered_data = data[(data['INGRED_ID'].isin(desired_steps)) & (data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'Material','INGRED_ID'])['Phase_overrun'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Visualization using bar plots\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=total_durations, x='Tank_1', y='Phase_overrun', hue='INGRED_ID', ci=None)\n",
    "plt.title('Total Phase_overrun for Each Tank by Phase')\n",
    "plt.ylabel('Phase_overrun')\n",
    "plt.xlabel('Tank')\n",
    "plt.legend(title='Phase_overrun')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df4 = filtered_data.groupby(['Tank_1','BATCHID']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    " #Print the aggregated DataFrame\n",
    "print(aggregated_total_durations_df4)\n",
    "aggregated_total_durations_df4.to_csv('GUMADD25MT4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bceae0bd-2524-4256-944d-4e627edeef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "1     2501  107599589              20            8.0                  0   \n",
      "3     2501  107654587              10            8.0                  0   \n",
      "4     2501  107673784             140          120.0                  0   \n",
      "6     2501  107721584               9            7.0                  0   \n",
      "7     2501  107781849              14           12.0                  0   \n",
      "9     2501  107820047              64           50.0                  0   \n",
      "10    2501  107829242              63           61.0                  0   \n",
      "11    2501  107837364              14           12.0                  0   \n",
      "12    2501  107858284              82           65.0                  0   \n",
      "13    2501  107884951              27           15.0                  0   \n",
      "14    2501  107894171              16            4.0                  0   \n",
      "15    2501  107907568               2            0.0                  0   \n",
      "17    2501  107949933              10            8.0                  0   \n",
      "19    2501  107975586               6            4.0                  0   \n",
      "20    2501  108033842              57           43.0                  0   \n",
      "22    2501  108051967              60           44.0                  0   \n",
      "23    2501  108058736              19           17.0                  0   \n",
      "24    2501  108058739              56           41.0                  0   \n",
      "25    2501  108068562              30           13.0                  0   \n",
      "28    2502  107643502              27            6.0                  0   \n",
      "29    2502  107673347               8            6.0                  0   \n",
      "30    2502  107673776              91           79.0                  0   \n",
      "31    2502  107700722             165          145.0                  0   \n",
      "32    2502  107711607              14            2.0                  0   \n",
      "33    2502  107737576              20            8.0                  0   \n",
      "35    2502  107790594              42           30.0                  0   \n",
      "36    2502  107815341              83           66.0                  0   \n",
      "37    2502  107829240              12            0.0                  0   \n",
      "38    2502  107831024              18            3.0                  0   \n",
      "39    2502  107831025              84           68.0                  0   \n",
      "41    2502  107874920              33           19.0                  0   \n",
      "42    2502  107896329             127          111.0                  0   \n",
      "45    2502  107949935              96           75.0                  0   \n",
      "46    2502  107971789              80           65.0                  0   \n",
      "47    2502  108033836             134          119.0                  0   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "1    172.600          8.6300                   12.0          14.8750  \n",
      "3     15.077          1.5077                    2.0           6.3182  \n",
      "4    758.000          5.4143                   20.0          38.4615  \n",
      "6     15.015          1.6683                    2.0           6.3182  \n",
      "7     15.035          1.0739                    2.0           6.3182  \n",
      "9    530.400          8.2875                   14.0          38.4615  \n",
      "10    15.000          0.2381                    2.0           6.3182  \n",
      "11    15.046          1.0747                    2.0           6.3182  \n",
      "12   401.700          4.8988                   17.0          23.4667  \n",
      "13   172.083          6.3734                   12.0          14.8750  \n",
      "14   172.700         10.7937                   12.0          14.8750  \n",
      "15    15.033          7.5165                    2.0           6.3182  \n",
      "17    14.017          1.4017                    2.0           6.3182  \n",
      "19    14.600          2.4333                    2.0           6.3182  \n",
      "20   334.500          5.8684                   14.0          23.4667  \n",
      "22   382.600          6.3767                   16.0          23.4667  \n",
      "23    14.531          0.7648                    2.0           6.3182  \n",
      "24   340.600          6.0821                   15.0          23.4667  \n",
      "25   397.800         13.2600                   17.0          23.4667  \n",
      "28   486.600         18.0222                   21.0          23.4667  \n",
      "29    15.042          1.8803                    2.0           6.3182  \n",
      "30   171.900          1.8890                   12.0          14.8750  \n",
      "31   757.605          4.5915                   20.0          38.4615  \n",
      "32   172.100         12.2929                   12.0          14.8750  \n",
      "33   204.245         10.2123                   12.0          17.0000  \n",
      "35   173.000          4.1190                   12.0          14.8750  \n",
      "36   400.000          4.8193                   17.0          23.4667  \n",
      "37   172.300         14.3583                   12.0          14.8750  \n",
      "38   259.000         14.3889                   15.0          17.0000  \n",
      "39   367.200          4.3714                   16.0          23.4667  \n",
      "41   530.200         16.0667                   14.0          38.4615  \n",
      "42   381.600          3.0047                   16.0          23.4667  \n",
      "45   486.014          5.0626                   21.0          23.4667  \n",
      "46   568.600          7.1075                   15.0          38.4615  \n",
      "47   569.100          4.2470                   15.0          38.4615  \n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank254_df = pd.DataFrame(aggregated_total_durations_df4)\n",
    "#ProductionTank254_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank254_df = remove_outliers_iqr(ProductionTank254_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank254_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b6140e-6e99-4269-b228-9eaecabf6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "1    2501  107599589       -0.680765      -0.761754                0.0   \n",
      "3    2501  107654587       -0.911421      -0.761754                0.0   \n",
      "4    2501  107673784        2.087108       2.071335                0.0   \n",
      "6    2501  107721584       -0.934486      -0.787049                0.0   \n",
      "7    2501  107781849       -0.819158      -0.660572                0.0   \n",
      "\n",
      "   Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "1   172.600        0.498541                   12.0          14.8750  \n",
      "3    15.077       -1.017904                    2.0           6.3182  \n",
      "4   758.000       -0.186130                   20.0          38.4615  \n",
      "6    15.015       -0.983710                    2.0           6.3182  \n",
      "7    15.035       -1.110267                    2.0           6.3182  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "ProductionTank254_df[numerical_cols] = scaler.fit_transform(ProductionTank254_df[numerical_cols])\n",
    "print(ProductionTank254_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "149bc04e-5114-4058-b652-4ca75a32b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |    Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+=============+============+===========+\n",
      "|  0 | Linear Regression           | 8.17797e-27 | 8.09254e-27 |   1        |  1        |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.00713107  | 0.00969976  |   0.993528 |  0.983598 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.441399    | 0.711067    |   0.599415 | -0.202425 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.00604294  | 0.0140078   |   0.994516 |  0.976313 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 3.5186e-07  | 0.0124612   |   1        |  0.978928 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           | 0.107588    |   1        |  0.818067 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.00660125  | 0.0181899   |   0.994009 |  0.969241 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.00366099  | 0.0269844   |   0.996678 |  0.954369 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 1.51585e-30 | 0.017709    |   1        |  0.970054 |\n",
      "+----+-----------------------------+-------------+-------------+------------+-----------+\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '254AGresults.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-89cc1b2ec678>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'keys'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtablefmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'grid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;31m# Save results DataFrame to an Excel file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m \u001b[0mresults_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'254AGresults.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2187\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2188\u001b[0m         )\n\u001b[1;32m-> 2189\u001b[1;33m         formatter.write(\n\u001b[0m\u001b[0;32m   2190\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[1;31m# abstract class 'ExcelWriter' with abstract attributes 'engine',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[1;31m# 'save', 'supported_extensions' and 'write_cells'  [abstract]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[0m\u001b[0;32m    816\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, **engine_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Append mode is not supported with xlsxwriter!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, **engine_kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIOHandles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"copression\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m    811\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '254AGresults.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'aggregated_ProductionTank2202_dfGUM' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('254AGresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ed0f7-c8a5-4aad-82a2-bcd72d90050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "    \n",
    "     # Save the results to an Excel file\n",
    "df.to_excel(\"25MT04AGresultsCVmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c32b6-bf55-4606-9ade-b4cfdf9c1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace  with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Ridge Regression: {ridge_grid.best_params_}\")\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Lasso Regression: {lasso_grid.best_params_}\")\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Random Forest Regressor: {rf_grid.best_params_}\")\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Gradient Boosting Regressor: {gb_grid.best_params_}\")\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Decision Tree Regressor: {dt_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Bagging Regressor: {bag_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('254AGresultsTUNED.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c0357-30c7-4762-b52d-3e36d4f2cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Drop the target variable and split data\n",
    "# Define features and targetProductionTank22_df\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model\n",
    "model = SVR()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (For example, using Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67307c23-c627-4403-9c97-3ae3fe88a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_svr(X_train, y_train):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Hyperparameters grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }\n",
    "    \n",
    "    # Using GridSearchCV to find the best hyperparameters\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_svr = grid_search.best_estimator_\n",
    "    return best_svr, scaler\n",
    "\n",
    "def evaluate_svr(svr_model, scaler, X_test, y_test):\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = svr_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"R-squared (R2): {r2:.2f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # diagonal line\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('SVR Predictions vs Actual Values')\n",
    "    plt.show()\n",
    "\n",
    "# Training the SVR model\n",
    "best_svr, scaler = train_svr(X_train, y_train)\n",
    "\n",
    "# Evaluating the trained SVR model\n",
    "evaluate_svr(best_svr, scaler, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee5d49-a065-4437-b16a-03e70674588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank25MT4_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_25MT4resultsTUNED_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a7dbc-bed6-452f-b173-cb9924392ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank25MT4_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('25MT4AGresultsTUNEDLSTMSNN Neural Network.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c78ca0-9f6d-4444-8fda-354ef668951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddc868-9492-4443-bd59-d12cb15eb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7e8f3-8624-4a77-94ec-b28fca8e2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('simple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('25MT4GAGresultsLSTMTUNED.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d1a1a-586c-40ed-b94c-9429d58198eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank25MT04_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank25MT4_df)\n",
    "\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('254neural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('25MT4GAGTdenseNN_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3f562d-46f9-48f7-87d2-70d21067a3c2",
   "metadata": {},
   "source": [
    "### Investigation into the relationship if any between gum addition and the deaeration startphase delay time. for the production tanks 25MT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833ee841-a382-4370-a244-8ca11c158645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85bae6c-f6bd-4d1e-b825-e0134ecf8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\Deaeration Results CSV\\DeaerationPhase25MT34.csv'\n",
    "DeaerationPhase25MT34 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e944d783-88fa-4894-a47c-59498d3edb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>DEPhase_start_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2503</td>\n",
       "      <td>107548288</td>\n",
       "      <td>STEP2_CONS-Deaeration</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2503</td>\n",
       "      <td>107582580</td>\n",
       "      <td>STEP2_CONS-Deaeration</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503</td>\n",
       "      <td>107588998</td>\n",
       "      <td>STEP2_CONS-Deaeration</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2503</td>\n",
       "      <td>107591594</td>\n",
       "      <td>STEP2_CONS-Deaeration</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2503</td>\n",
       "      <td>107610053</td>\n",
       "      <td>STEP2_CONS-Deaeration</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tank_1    BATCHID       Instruction_Step  DEPhase_start_delay\n",
       "0    2503  107548288  STEP2_CONS-Deaeration                  247\n",
       "1    2503  107582580  STEP2_CONS-Deaeration                  694\n",
       "2    2503  107588998  STEP2_CONS-Deaeration                  425\n",
       "3    2503  107591594  STEP2_CONS-Deaeration                   54\n",
       "4    2503  107610053  STEP2_CONS-Deaeration                  430"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeaerationPhase25MT34.rename(columns = {'Phase_start_delay':'DEPhase_start_delay'}, inplace = True)\n",
    "DeaerationPhase25MT34.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6b0ab6-57d9-4140-9a7e-ef49de4e45f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Quantity' 'Flowrate_KGMIN' 'Target_Phase_duration' 'Target_Flowrate'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-90fd5887195f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDeaerationPhase25MT34\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quantity'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Flowrate_KGMIN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Target_Phase_duration'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Target_Flowrate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Quantity' 'Flowrate_KGMIN' 'Target_Phase_duration' 'Target_Flowrate'] not found in axis\""
     ]
    }
   ],
   "source": [
    "DeaerationPhase25MT34.drop(columns=['Quantity','Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea37f0-11c0-4b9e-982c-e72899175586",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeaerationPhase25MT34.rename(columns = {'Phase_duration':'DEPhase_duration','Phase_overrun':'DEPhase_overrun','Phase_start_delay':'DEPhase_start_delay'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093a081-906f-4663-98e4-166f0e7280c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\Agitation Results CSV\\Agitation25MT10.csv'\n",
    "Agitation25MT10 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d089367-55af-43b4-af9c-733e8fc75082",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agitation25MT10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea3323-e101-4cc3-8b5a-124e5aea91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Agitation25MT10.drop(columns=['Quantity','Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441c746-a56c-4c35-8010-b808abbe1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agitation25MT10.rename(columns = {'Phase_duration':'AGPhase_duration','Phase_overrun':'AGPhase_overrun','Phase_start_delay':'AGPhase_start_delay'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b43150-321f-40b0-9a4a-8b1e97fe4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Agitation23MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a76cb-da84-4dbc-8bdb-522e4c55d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\GUM ADDITION CSV\\GUMADD25MT10.csv'\n",
    "GUMADD25MT10 = pd.read_csv(file_path)\n",
    "#GUMADD25MT10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849a39e-4955-4f7e-81ad-d4f5afb32f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GUMADD25MT10.drop(columns=['Phase_start_delay','Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1914dad9-172c-4ca3-a4c4-f9ad0fb5574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GUMADD25MT10.rename(columns = {'Quantity':'GUMQuantity','Phase_duration':'GUMPhase_duration','Phase_overrun':'GUMPhase_overrun'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38622d7-01ff-42cf-9ef6-d24cb78dd9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUMADD25MT10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f963908-1168-42ae-871b-1172f704abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [GUMADD25MT10,Agitation25MT10,DeaerationPhase25MT34]\n",
    "\n",
    "result = pd.concat((frames),axis=1)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa1fc0-3e58-4e2c-b78e-fb6918adbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.drop(columns=('Instruction_Step'),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8adbf-2c6f-4d87-925d-9122dfe38be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns\n",
    "df = result.loc[:, ~result.columns.duplicated()]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5a59a-2664-42d3-9683-3a243c64f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e314a6-5da7-44e9-9002-523d4d27fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6d744-21c5-4cf1-b023-166eb5b351b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to new data types\n",
    "df = df.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc9012-2022-4599-93fa-328494edacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank2510_df = pd.DataFrame(df)\n",
    "ProductionTank2510_df\n",
    "columns_to_check = ['GUMQuantity','GUMPhase_duration','GUMPhase_overrun','AGPhase_duration','AGPhase_overrun','AGPhase_start_delay','DEPhase_duration','DEPhase_overrun','DEPhase_start_delay']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank2510_df = remove_outliers_iqr(ProductionTank2510_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank2510_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ff71a-cac9-45a6-ae12-5c91ac6f698a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686edb2-58fa-4901-bd31-b0538bdc4328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84081f02-d106-4814-b875-17a944f10c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f257fe-4ee8-461d-bb2f-6d6ec64a345c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3a93c-0f1c-4869-bb2d-bab96a0a3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['GUMPhase_duration', 'GUMPhase_overrun', 'GUMQuantity', 'AGPhase_duration', 'AGPhase_overrun', 'DEPhase_duration', 'DEPhase_start_delay']\n",
    "ProductionTank2510_df[numerical_cols] = scaler.fit_transform(ProductionTank2510_df[numerical_cols])\n",
    "print(ProductionTank2510_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3b1d1-20da-4df7-8618-076970a57a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341afcdf-b167-4af1-b228-bfee522d19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ef5b7-c9b6-4240-a7ac-15b9df474043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to visualize relationships between numerical columns\n",
    "#sns.pairplot(df)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b081aa-8bce-4089-963a-52c971661f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation between GUMPhase_overrun and DEPhase_start_delay\n",
    "correlation = df['GUMQuantity'].corr(df['DEPhase_start_delay'])\n",
    "\n",
    "# Create a scatter plot to visualize the relationship\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df, x='GUMPhase_duration', y='DEPhase_start_delay')\n",
    "plt.title(f'Correlation: {correlation:.2f}')\n",
    "plt.xlabel('GUMPhase_duration')\n",
    "plt.ylabel('DEPhase_start_delay ')\n",
    "plt.show()\n",
    "\n",
    "print(f'Correlation between GUMQuantity and DEPhase_start_delay: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b8cf9-ba20-4f33-8bb6-daef11e125d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank2510_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['DEPhase_start_delay'], axis=1)  # Features without the target variable\n",
    "y = df['DEPhase_start_delay']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(gb_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search to find the best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best parameters on the full training data\n",
    "best_gb_model = GradientBoostingRegressor(**best_params, random_state=42)\n",
    "best_gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print best parameters and MSE\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b02e86-e4a7-4e7c-961f-7fcabe59c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank2510_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['DEPhase_start_delay'], axis=1)  # Features without the target variable\n",
    "y = df['DEPhase_start_delay']  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f702cf-0cfd-4e9a-acdb-6351d08b9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.DataFrame(ProductionTank2510_df)\n",
    "\n",
    "# Drop the target variable and split data\n",
    "X = df.drop(columns=[\"DEPhase_start_delay\"])\n",
    "y = df[\"DEPhase_start_delay\"]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model\n",
    "model = SVR()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (For example, using Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5896056-f170-4f7e-af4c-7baa34e86905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_svr(X_train, y_train):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Hyperparameters grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }\n",
    "    \n",
    "    # Using GridSearchCV to find the best hyperparameters\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_svr = grid_search.best_estimator_\n",
    "    return best_svr, scaler\n",
    "\n",
    "def evaluate_svr(svr_model, scaler, X_test, y_test):\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = svr_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"R-squared (R2): {r2:.2f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # diagonal line\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('SVR Predictions vs Actual Values')\n",
    "    plt.show()\n",
    "\n",
    "# Training the SVR model\n",
    "best_svr, scaler = train_svr(X_train, y_train)\n",
    "\n",
    "# Evaluating the trained SVR model\n",
    "evaluate_svr(best_svr, scaler, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d7a4c-5887-47c9-89c4-8f73d14fb273",
   "metadata": {},
   "source": [
    "If SVR predicts a certain value for \"deaeration start phase time delay\" based on the input features for a given batch of beverage production, it's essentially telling you its best estimate of the delay for that batch based on the patterns it has learned from the training data.\n",
    "\n",
    "If the prediction is accurate (or close to the actual delay), this suggests that the model has identified meaningful patterns in your input features that relate to the delay. Conversely, if predictions are off, the features might not contain enough information, the model may need better hyperparameters, or the data might require further preprocessing.\n",
    "\n",
    "The advantage of using SVR (or any other machine learning model) for this task is that once trained, you can use it to make predictions for future batches, allowing you to potentially anticipate delays and make necessary adjustments in the production process to mitigate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0016a88-69e6-4af5-8746-f2e9815a455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.DataFrame(ProductionTank2510_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"DEPhase_start_delay\", axis=1)\n",
    "y = df['DEPhase_start_delay']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train MLP Regressor\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=5000, random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db2d24-3830-4f66-be05-abce4f978912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load your dataset (replace with your actual dataset name)\n",
    "# df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "df = pd.DataFrame(ProductionTank2510_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"DEPhase_start_delay\", axis=1)\n",
    "y = df['DEPhase_start_delay']\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the ANN model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict with the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "# If you'd like to visualize the training loss & MAE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation MAE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef17a41-9241-45e8-9b2f-7bc4e29db40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

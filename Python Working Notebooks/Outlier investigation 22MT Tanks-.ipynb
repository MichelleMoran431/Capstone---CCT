{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34dcc151-ba07-4dd2-a729-8e542887a504",
   "metadata": {},
   "source": [
    "## Looking at all tanks from 22MT - 20 tonne Capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995b1ab1-87b0-48f6-a021-63abb8755064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeaea3fa-7f24-4922-8b17-10c4c082d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0f3e12-cbc5-4462-8bdc-46fe09b0dce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>9482</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>TAKE A SAMPLE AND SUBMIT FOR QA.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:43</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>9483</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>08/05/2022 11:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>9484</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>STEP8_AGITATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>9485</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S4_BATCH_COMPLETE_QA_PENDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>9486</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S7_RELEASED_TO_FILLING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9487 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Material    BATCHID Tank_1  \\\n",
       "0              0   1002150  107643491   2503   \n",
       "1              1   1002150  107643491   2503   \n",
       "2              2   1002150  107643491   2503   \n",
       "3              3   1002150  107643491   2503   \n",
       "4              4   1002150  107643491   2503   \n",
       "...          ...       ...        ...    ...   \n",
       "9482        9482   3055706  107737576   2502   \n",
       "9483        9483   3055706  107737576   2502   \n",
       "9484        9484   3055706  107737576   2502   \n",
       "9485        9485   3055706  107737576   2502   \n",
       "9486        9486   3055706  107737576   2502   \n",
       "\n",
       "                                   Instruction_Step INGRED_ID  \\\n",
       "0                              S3_BATCH_IN_PROGRESS       NaN   \n",
       "1                                        STEP1_CONS   1002565   \n",
       "2                       PLEASE VERIFY BULK ADDITION       NaN   \n",
       "3                                        STEP1_CONS   1037802   \n",
       "4                                        STEP1_CONS   1002818   \n",
       "...                                             ...       ...   \n",
       "9482               TAKE A SAMPLE AND SUBMIT FOR QA.       NaN   \n",
       "9483  SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)       NaN   \n",
       "9484                                STEP8_AGITATION       NaN   \n",
       "9485                   S4_BATCH_COMPLETE_QA_PENDING       NaN   \n",
       "9486                         S7_RELEASED_TO_FILLING       NaN   \n",
       "\n",
       "                               INGRED_Name  Quantity       Phase_start  \\\n",
       "0                                      NaN     0.000  09/03/2022 10:42   \n",
       "1                            WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2                                      NaN     0.000  09/03/2022 11:16   \n",
       "3     S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4     S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "...                                    ...       ...               ...   \n",
       "9482                                   NaN     0.000  08/05/2022 11:43   \n",
       "9483                                   NaN     0.000  08/05/2022 11:54   \n",
       "9484                                   NaN     0.000  08/05/2022 11:56   \n",
       "9485                                   NaN     0.000  08/05/2022 11:56   \n",
       "9486                                   NaN     0.000  08/05/2022 12:02   \n",
       "\n",
       "             Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0     09/03/2022 10:42               0                  0             1   \n",
       "1     09/03/2022 11:16              34                  0             2   \n",
       "2     09/03/2022 11:17               1                  0             3   \n",
       "3     09/03/2022 11:27              10                  0             4   \n",
       "4     09/03/2022 11:38              11                  0             5   \n",
       "...                ...             ...                ...           ...   \n",
       "9482  08/05/2022 11:54              11                  0            19   \n",
       "9483  08/05/2022 11:55               1                  0            20   \n",
       "9484  08/05/2022 11:56               0                  1            21   \n",
       "9485  08/05/2022 11:56               0                  0            22   \n",
       "9486  08/05/2022 12:02               0                  6            23   \n",
       "\n",
       "      Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0             0.0000              NaN                      0            NaN   \n",
       "1           169.4118         733.5050                      8           26.0   \n",
       "2             0.0000              NaN                      3            0.0   \n",
       "3             0.5629           6.3182                      1            9.0   \n",
       "4             7.1605           6.3182                     12            0.0   \n",
       "...              ...              ...                    ...            ...   \n",
       "9482          0.0000              NaN                     10            1.0   \n",
       "9483          0.0000              NaN                     10            0.0   \n",
       "9484          0.0000              NaN                      0            0.0   \n",
       "9485          0.0000              NaN                      0            NaN   \n",
       "9486          0.0000              NaN                     14            0.0   \n",
       "\n",
       "      Deaeration Phase  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "9482                 0  \n",
       "9483                 0  \n",
       "9484                 0  \n",
       "9485                 0  \n",
       "9486                 0  \n",
       "\n",
       "[9487 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f004067c-b57d-42c7-af68-8becb4f2f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2aeb92-6db6-461e-a672-7cc463fc741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Material    BATCHID Tank_1             Instruction_Step   INGRED_ID  \\\n",
      "2001   1397022  107956670   2202         S3_BATCH_IN_PROGRESS         NaN   \n",
      "2002   1397022  107956670   2202                   STEP1_CONS     1002565   \n",
      "2003   1397022  107956670   2202  PLEASE VERIFY BULK ADDITION         NaN   \n",
      "2004   1397022  107956670   2202                   STEP1_CONS     1037802   \n",
      "2005   1397022  107956670   2202                   STEP1_CONS     1002818   \n",
      "...        ...        ...    ...                          ...         ...   \n",
      "7818   1775253  108051514   2203                   STEP2_CONS  U_86MT15_1   \n",
      "7819   1775253  108051514   2203              STEP2_AGITATION         NaN   \n",
      "7820   1775253  108051514   2203            WEIGHT_VALIDATION         NaN   \n",
      "7821   1775253  108051514   2203              STEP3_AGITATION         NaN   \n",
      "7822   1775253  108051514   2203                           HP         NaN   \n",
      "\n",
      "                               INGRED_Name   Quantity       Phase_start  \\\n",
      "2001                                   NaN      0.000  03/11/2022 07:33   \n",
      "2002                         WATER TREATED   8623.000  03/11/2022 07:34   \n",
      "2003                                   NaN      0.000  03/11/2022 07:44   \n",
      "2004  S813     SOD BENZOATE          XFX25     19.446  03/11/2022 08:04   \n",
      "2005  S651     CITRIC ACID ANH    BG XFX25    516.000  03/11/2022 08:21   \n",
      "...                                    ...        ...               ...   \n",
      "7818                                   NaN    815.800  04/02/2023 22:41   \n",
      "7819                                   NaN      0.000  04/02/2023 23:02   \n",
      "7820                                   NaN      0.000  04/02/2023 23:32   \n",
      "7821                                   NaN      0.000  04/02/2023 23:48   \n",
      "7822                                   NaN  19858.664  04/02/2023 23:50   \n",
      "\n",
      "             Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
      "2001  03/11/2022 07:33               0                  0             1   \n",
      "2002  03/11/2022 07:44              10                  1             2   \n",
      "2003  03/11/2022 08:04              20                  0             3   \n",
      "2004  03/11/2022 08:21              17                  0             4   \n",
      "2005  03/11/2022 08:29               8                  0             5   \n",
      "...                ...             ...                ...           ...   \n",
      "7818  04/02/2023 23:02              21                  0            13   \n",
      "7819  04/02/2023 23:32              30                  0            14   \n",
      "7820  04/02/2023 23:47              15                  0            15   \n",
      "7821  04/02/2023 23:48               0                  1            16   \n",
      "7822  05/02/2023 01:27              97                  2            17   \n",
      "\n",
      "      Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
      "2001          0.0000              NaN                      0            NaN   \n",
      "2002        862.3000         733.5050                     12            0.0   \n",
      "2003          0.0000              NaN                      3           17.0   \n",
      "2004          1.1439           6.3182                      3           14.0   \n",
      "2005         64.5000          38.4615                     13            0.0   \n",
      "...              ...              ...                    ...            ...   \n",
      "7818         38.8476          79.0160                     10           11.0   \n",
      "7819          0.0000              NaN                     30            0.0   \n",
      "7820          0.0000              NaN                      3           12.0   \n",
      "7821          0.0000              NaN                      0            0.0   \n",
      "7822        204.7285         237.8504                     83           14.0   \n",
      "\n",
      "      Deaeration Phase  \n",
      "2001                 0  \n",
      "2002                 0  \n",
      "2003                 0  \n",
      "2004                 0  \n",
      "2005                 0  \n",
      "...                ...  \n",
      "7818                 0  \n",
      "7819                 0  \n",
      "7820                 0  \n",
      "7821                 0  \n",
      "7822                 0  \n",
      "\n",
      "[947 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "tanks = ('2202','2203','2204')  # List of tank IDs you want to query\n",
    "ProductionTanks_df = ProductionTank.query('Tank_1 in @tanks')\n",
    "print(ProductionTanks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16d7fbf-8c55-4875-9773-f284f30d1ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "0   107848868            1685          734.0         120.952381   \n",
      "1   107862335             530          210.0         307.705882   \n",
      "2   107867810            1280          909.0          67.812500   \n",
      "3   107872112            3170         2922.0           1.812500   \n",
      "4   107887071             287          124.0         295.000000   \n",
      "5   107899925            1666         1180.0          83.909091   \n",
      "6   107899926            1608         1114.0          95.130435   \n",
      "7   107907563             750          489.0         111.714286   \n",
      "8   107915806             485          156.0         287.411765   \n",
      "9   107925352             628          202.0         195.809524   \n",
      "10  107933869             428          250.0         258.529412   \n",
      "11  107949891            1430         1286.0          19.272727   \n",
      "12  107949892             279          134.0           5.545455   \n",
      "13  107956670             621          362.0         247.105263   \n",
      "14  107963676             229           94.0         768.428571   \n",
      "15  107963677             403           86.0         456.666667   \n",
      "16  107964387             583          163.0         162.714286   \n",
      "17  107964409             116            7.0           2.000000   \n",
      "18  107964410             591          300.0         175.117647   \n",
      "19  107969769             624          316.0         170.038462   \n",
      "20  107971404             539          125.0         104.190476   \n",
      "21  107978116             480          270.0         208.700000   \n",
      "22  107978117             296           16.0         129.882353   \n",
      "23  107978118             482           82.0          96.000000   \n",
      "24  107992045             820          386.0         184.363636   \n",
      "25  107993270             767          382.0         143.840000   \n",
      "26  107999492            2784         2243.0          88.031250   \n",
      "27  107999493            1127          838.0         173.823529   \n",
      "28  107999494            1386          905.0         125.173913   \n",
      "29  108015838             955          621.0         144.160000   \n",
      "30  108015839             813          347.0         138.200000   \n",
      "31  108026759             771          482.0         205.411765   \n",
      "32  108026760             762          376.0         148.545455   \n",
      "33  108030821            3534         3074.0           7.807692   \n",
      "34  108033603            1313          896.0          92.178571   \n",
      "35  108033608             565          310.0         309.764706   \n",
      "36  108042635             627          375.0         218.375000   \n",
      "37  108042636             565          177.0         158.086957   \n",
      "38  108045117            1351          895.0         155.190476   \n",
      "39  108051514             617          371.0         227.941176   \n",
      "40  108059029             768          252.0         174.307692   \n",
      "41  108067819            1076          611.0         140.294118   \n",
      "42  108073631             890          463.0          99.592593   \n",
      "43  108073632             873          667.0         223.894737   \n",
      "44  108075449            1001          724.0          90.782609   \n",
      "45  108084749             674          196.0         230.130435   \n",
      "46  108084750             204           11.0           0.600000   \n",
      "\n",
      "    Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "0        1689.5875              46.333333       293.502929  \n",
      "1        1393.4183              19.176471       152.181450  \n",
      "2        1972.4618              13.562500       181.465283  \n",
      "3        1508.6187              16.250000       270.812300  \n",
      "4        1445.1655              11.437500       226.111543  \n",
      "5        2085.4873              23.000000       246.789922  \n",
      "6        2106.2353              22.565217       223.460930  \n",
      "7        2225.0568              13.952381       188.249709  \n",
      "8        1456.1131              20.235294       145.112670  \n",
      "9        1487.5390              21.857143       266.692063  \n",
      "10       1706.6223              11.176471       223.400512  \n",
      "11        512.7143              13.454545       547.500000  \n",
      "12        327.0000              13.454545       547.500000  \n",
      "13       1534.1302              16.263158       160.241280  \n",
      "14        235.1088              19.571429       131.960800  \n",
      "15        467.2167              27.333333       158.433200  \n",
      "16       1804.2138              21.666667       260.606725  \n",
      "17          0.0000              22.166667              NaN  \n",
      "18       1534.4335              17.352941       247.907363  \n",
      "19       1215.1144              12.769231       135.836845  \n",
      "20       2154.2360              21.666667       266.692063  \n",
      "21       1274.7112              11.100000       177.123836  \n",
      "22       1769.8498              17.352941       247.907363  \n",
      "23       1712.2831              18.565217       247.907363  \n",
      "24       1604.8217              21.272727       238.559611  \n",
      "25       1865.0096              17.480000       202.689200  \n",
      "26       2047.5261              18.781250       192.383100  \n",
      "27       2004.0834              17.352941       247.907363  \n",
      "28       1511.9261              21.826087       223.460930  \n",
      "29       1295.4346              14.680000       142.369308  \n",
      "30       1705.2452              19.640000       158.806300  \n",
      "31       1485.2932              17.352941       247.907363  \n",
      "32       1837.2263              18.909091       272.034700  \n",
      "33       1821.4777              19.769231       183.624944  \n",
      "34       2297.6791              16.928571       176.187800  \n",
      "35       1409.3757              15.588235       238.648263  \n",
      "36       2043.0124              18.562500       272.034700  \n",
      "37       1935.9490              18.217391       247.907363  \n",
      "38       1483.9865              22.428571       266.692063  \n",
      "39       1623.8706              17.352941       247.907363  \n",
      "40       1341.8550              21.269231       159.969536  \n",
      "41       1804.0260              15.382353       195.204555  \n",
      "42       2235.8036              17.222222       185.448846  \n",
      "43       1306.4656              11.368421       167.966560  \n",
      "44       2125.2654              12.695652       171.444523  \n",
      "45       2096.9412              23.086957       206.534280  \n",
      "46        210.2762              42.400000       237.850400  \n"
     ]
    }
   ],
   "source": [
    "#Aggregate data per tank\n",
    "aggregated_ProductionTank22_df1 = ProductionTanks_df.groupby(['BATCHID']).agg({\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'mean',\n",
    "    #'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    " #Print the aggregated DataFrame\n",
    "print(aggregated_ProductionTank22_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa77add-b0fd-48fd-bffa-bc4f4fb3dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "aggregated_ProductionTank22_df1.dropna(inplace=True)  # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a213668-1f1f-49a8-9515-39cc2db20641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling duplicates\n",
    "aggregated_ProductionTank22_df1.drop_duplicates(inplace=True)  # Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6cd17e-b655-4ef1-8ba5-ade69437a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "1   107862335             530          210.0         307.705882   \n",
      "2   107867810            1280          909.0          67.812500   \n",
      "4   107887071             287          124.0         295.000000   \n",
      "5   107899925            1666         1180.0          83.909091   \n",
      "6   107899926            1608         1114.0          95.130435   \n",
      "7   107907563             750          489.0         111.714286   \n",
      "8   107915806             485          156.0         287.411765   \n",
      "9   107925352             628          202.0         195.809524   \n",
      "10  107933869             428          250.0         258.529412   \n",
      "13  107956670             621          362.0         247.105263   \n",
      "16  107964387             583          163.0         162.714286   \n",
      "18  107964410             591          300.0         175.117647   \n",
      "19  107969769             624          316.0         170.038462   \n",
      "20  107971404             539          125.0         104.190476   \n",
      "21  107978116             480          270.0         208.700000   \n",
      "22  107978117             296           16.0         129.882353   \n",
      "23  107978118             482           82.0          96.000000   \n",
      "24  107992045             820          386.0         184.363636   \n",
      "25  107993270             767          382.0         143.840000   \n",
      "27  107999493            1127          838.0         173.823529   \n",
      "28  107999494            1386          905.0         125.173913   \n",
      "29  108015838             955          621.0         144.160000   \n",
      "30  108015839             813          347.0         138.200000   \n",
      "31  108026759             771          482.0         205.411765   \n",
      "32  108026760             762          376.0         148.545455   \n",
      "34  108033603            1313          896.0          92.178571   \n",
      "35  108033608             565          310.0         309.764706   \n",
      "36  108042635             627          375.0         218.375000   \n",
      "37  108042636             565          177.0         158.086957   \n",
      "38  108045117            1351          895.0         155.190476   \n",
      "39  108051514             617          371.0         227.941176   \n",
      "40  108059029             768          252.0         174.307692   \n",
      "41  108067819            1076          611.0         140.294118   \n",
      "42  108073631             890          463.0          99.592593   \n",
      "43  108073632             873          667.0         223.894737   \n",
      "44  108075449            1001          724.0          90.782609   \n",
      "45  108084749             674          196.0         230.130435   \n",
      "\n",
      "    Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "1        1393.4183              19.176471       152.181450  \n",
      "2        1972.4618              13.562500       181.465283  \n",
      "4        1445.1655              11.437500       226.111543  \n",
      "5        2085.4873              23.000000       246.789922  \n",
      "6        2106.2353              22.565217       223.460930  \n",
      "7        2225.0568              13.952381       188.249709  \n",
      "8        1456.1131              20.235294       145.112670  \n",
      "9        1487.5390              21.857143       266.692063  \n",
      "10       1706.6223              11.176471       223.400512  \n",
      "13       1534.1302              16.263158       160.241280  \n",
      "16       1804.2138              21.666667       260.606725  \n",
      "18       1534.4335              17.352941       247.907363  \n",
      "19       1215.1144              12.769231       135.836845  \n",
      "20       2154.2360              21.666667       266.692063  \n",
      "21       1274.7112              11.100000       177.123836  \n",
      "22       1769.8498              17.352941       247.907363  \n",
      "23       1712.2831              18.565217       247.907363  \n",
      "24       1604.8217              21.272727       238.559611  \n",
      "25       1865.0096              17.480000       202.689200  \n",
      "27       2004.0834              17.352941       247.907363  \n",
      "28       1511.9261              21.826087       223.460930  \n",
      "29       1295.4346              14.680000       142.369308  \n",
      "30       1705.2452              19.640000       158.806300  \n",
      "31       1485.2932              17.352941       247.907363  \n",
      "32       1837.2263              18.909091       272.034700  \n",
      "34       2297.6791              16.928571       176.187800  \n",
      "35       1409.3757              15.588235       238.648263  \n",
      "36       2043.0124              18.562500       272.034700  \n",
      "37       1935.9490              18.217391       247.907363  \n",
      "38       1483.9865              22.428571       266.692063  \n",
      "39       1623.8706              17.352941       247.907363  \n",
      "40       1341.8550              21.269231       159.969536  \n",
      "41       1804.0260              15.382353       195.204555  \n",
      "42       2235.8036              17.222222       185.448846  \n",
      "43       1306.4656              11.368421       167.966560  \n",
      "44       2125.2654              12.695652       171.444523  \n",
      "45       2096.9412              23.086957       206.534280  \n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank22_df2 = pd.DataFrame(aggregated_ProductionTank22_df1)\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration', 'Target_Flowrate']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "    ProductionTank22_df2 = remove_outliers_iqr(ProductionTank22_df2, col)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank22_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a7bb26-b28e-4fc9-91bd-632857e04200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Summary Statistics:\n",
      "            BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "count  4.600000e+01       46.000000      46.000000          46.000000   \n",
      "mean   1.079843e+08      941.673913     589.695652         170.651000   \n",
      "std    6.504945e+04      709.918964     665.706371         128.386238   \n",
      "min    1.078489e+08      204.000000      11.000000           0.600000   \n",
      "25%    1.079499e+08      545.500000     197.500000          96.898148   \n",
      "50%    1.079851e+08      756.000000     373.000000         151.867965   \n",
      "75%    1.080336e+08     1114.250000     731.500000         215.956250   \n",
      "max    1.080848e+08     3534.000000    3074.000000         768.428571   \n",
      "\n",
      "       Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "count       46.000000              46.000000        46.000000  \n",
      "mean      1580.649296              18.905746       226.759461  \n",
      "std        522.742511               6.635647        82.019334  \n",
      "min        210.276200              11.100000       131.960800  \n",
      "25%       1418.323150              15.433824       176.421809  \n",
      "50%       1656.729050              17.848696       223.460930  \n",
      "75%       1963.333600              21.271853       247.907363  \n",
      "max       2297.679100              46.333333       547.500000  \n",
      "\n",
      "Cleaned DataFrame Summary Statistics:\n",
      "            BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "count  3.700000e+01       37.000000      37.000000          37.000000   \n",
      "mean   1.079896e+08      799.972973     447.081081         172.454831   \n",
      "std    6.297279e+04      344.974515     302.646785          66.470518   \n",
      "min    1.078623e+08      287.000000      16.000000          67.812500   \n",
      "25%    1.079567e+08      565.000000     210.000000         125.173913   \n",
      "50%    1.079933e+08      750.000000     371.000000         162.714286   \n",
      "75%    1.080426e+08      955.000000     621.000000         218.375000   \n",
      "max    1.080847e+08     1666.000000    1180.000000         309.764706   \n",
      "\n",
      "       Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "count       37.000000              37.000000        37.000000  \n",
      "mean      1726.765989              17.630179       212.631555  \n",
      "std        315.059563               3.644878        42.938155  \n",
      "min       1215.114400              11.100000       135.836845  \n",
      "25%       1483.986500              15.382353       176.187800  \n",
      "50%       1706.622300              17.352941       223.460930  \n",
      "75%       2004.083400              21.269231       247.907363  \n",
      "max       2297.679100              23.086957       272.034700  \n"
     ]
    }
   ],
   "source": [
    "# For the original DataFrame\n",
    "print(\"Original DataFrame Summary Statistics:\")\n",
    "print(aggregated_ProductionTank22_df1.describe())\n",
    "\n",
    "# After removing outliers\n",
    "print(\"\\nCleaned DataFrame Summary Statistics:\")\n",
    "print(ProductionTank22_df2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73378539-de89-4434-b63c-51249f8a9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "0  107848868        1.058628       0.219164          -0.391380   \n",
      "1  107862335       -0.586296      -0.576668           1.079316   \n",
      "2  107867810        0.481836       0.484948          -0.809860   \n",
      "3  107872112        3.173530       3.542217          -1.329614   \n",
      "4  107887071       -0.932371      -0.707281           0.979257   \n",
      "\n",
      "   Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "0        0.210700              46.333333       293.502929  \n",
      "1       -0.362128              19.176471       152.181450  \n",
      "2        0.757815              13.562500       181.465283  \n",
      "3       -0.139316              16.250000       270.812300  \n",
      "4       -0.262043              11.437500       226.111543  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "aggregated_ProductionTank22_df1[numerical_cols] = scaler.fit_transform(aggregated_ProductionTank22_df1[numerical_cols])\n",
    "print(aggregated_ProductionTank22_df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b54a05-5b89-4043-be08-937efb68029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "1  107862335       -0.793383      -0.794164           2.062819   \n",
      "2  107867810        1.410679       1.547317          -1.595982   \n",
      "4  107887071       -1.507499      -1.082244           1.869032   \n",
      "5  107899925        2.545037       2.455102          -1.350480   \n",
      "6  107899926        2.374589       2.234018          -1.179335   \n",
      "\n",
      "   Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "1       -1.072641              19.176471       152.181450  \n",
      "2        0.790596              13.562500       181.465283  \n",
      "4       -0.906130              11.437500       226.111543  \n",
      "5        1.154288              23.000000       246.789922  \n",
      "6        1.221050              22.565217       223.460930  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "ProductionTank22_df2[numerical_cols] = scaler.fit_transform(ProductionTank22_df2[numerical_cols])\n",
    "print(ProductionTank22_df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa2eb81-b103-4ae6-867b-e87cec8a9344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.0659332   |  0.0802618 | 0.919859   |  0.9429   |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.0681801   |  0.0804267 | 0.917128   |  0.942783 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.819933    |  1.73434   | 0.00337975 | -0.233835 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0253273   |  0.0510163 | 0.969215   |  0.963706 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 3.18288e-05 |  0.121393  | 0.999961   |  0.913639 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           |  0.520986  | 1          |  0.629363 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0266291   |  0.0538929 | 0.967633   |  0.96166  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.0241122   |  0.110027  | 0.970692   |  0.921725 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate','Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "gb_feature_importance = gb_model.feature_importances_\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22results.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "794b04f8-797b-4883-a7d0-9d12e4cba5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.038242\n",
      "  Std MSE: 0.034959\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.039056\n",
      "  Std MSE: 0.033210\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.109610\n",
      "  Std MSE: 0.733787\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.080936\n",
      "  Std MSE: 0.041989\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.073877\n",
      "  Std MSE: 0.041258\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.119150\n",
      "  Std MSE: 0.785001\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 5079474864687.988281\n",
      "  Std MSE: 4559358708925.739258\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.102352\n",
      "  Std MSE: 0.060081\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.087979\n",
      "  Std MSE: 0.064527\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.078568\n",
      "  Std MSE: 0.038442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61087bc4-c75a-4f2a-832a-bbd1571984bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22 TUN results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e7da37-ffc1-440d-85f3-435d72d59058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|    | Model                     |   Train MSE |    Test MSE |     Train R2 |      Test R2 |\n",
      "+====+===========================+=============+=============+==============+==============+\n",
      "|  0 | LinearRegression          | 0.063388    | 0.0950418   |  0.935507    |  0.883101    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  1 | Ridge                     | 0.0652517   | 0.0970635   |  0.933592    |  0.880517    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  2 | Lasso                     | 0.956798    | 1.05775     |  0.034345    | -0.160456    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  3 | RandomForestRegressor     | 0.0211661   | 0.172026    |  0.977975    |  0.79776     |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  4 | GradientBoostingRegressor | 2.96982e-05 | 0.19948     |  0.99997     |  0.772009    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  5 | SVR                       | 1.07977     | 1.10544     | -0.0856744   | -0.175776    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  6 | MLPRegressor              | 5.55221e+12 | 5.55269e+12 | -5.39425e+12 | -7.64928e+12 |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  7 | DecisionTreeRegressor     | 0           | 0.331551    |  1           |  0.647668    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  8 | BaggingRegressor          | 0.0208995   | 0.169059    |  0.978286    |  0.801356    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  9 | AdaBoostRegressor         | 0.0155187   | 0.149936    |  0.984015    |  0.832639    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Initialize k-fold cross-validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Iterate through each model and perform k-fold cross-validation\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    train_mse_list = []\n",
    "    test_mse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_mse_list.append(train_mse)\n",
    "        test_mse_list.append(test_mse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "    \n",
    "    mean_train_mse = sum(train_mse_list) / num_folds\n",
    "    mean_test_mse = sum(test_mse_list) / num_folds\n",
    "    mean_train_r2 = sum(train_r2_list) / num_folds\n",
    "    mean_test_r2 = sum(test_r2_list) / num_folds\n",
    "    \n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': mean_train_mse, 'Test MSE': mean_test_mse,\n",
    "                                    'Train R2': mean_train_r2, 'Test R2': mean_test_r2}, ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('kfold_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb02eba1-3624-4806-8cf9-e3009672a635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                     |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+===========================+=============+============+============+===========+\n",
      "|  0 | LinearRegression          | 0.214924    |   0.24649  |  0.738762  |  0.824643 |\n",
      "+----+---------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge                     | 0.2159      |   0.261725 |  0.737576  |  0.813805 |\n",
      "+----+---------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso                     | 0.813518    |   1.7414   |  0.0111774 | -0.238859 |\n",
      "+----+---------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | RandomForestRegressor     | 0.0529019   |   0.548713 |  0.935698  |  0.609637 |\n",
      "+----+---------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | GradientBoostingRegressor | 1.90366e-05 |   0.627053 |  0.999977  |  0.553904 |\n",
      "+----+---------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# List of regression models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "]\n",
    "\n",
    "# Apply PCR to each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # Apply PCA to reduce dimensionality\n",
    "    num_components = 5  # You can choose the number of principal components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Train the model with principal components\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    pred_train = model.predict(X_train_pca)\n",
    "    pred_test = model.predict(X_test_pca)\n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "\n",
    "    # Store results in the DataFrame\n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': train_mse,\n",
    "                                    'Test MSE': test_mse, 'Train R2': train_r2, 'Test R2': test_r2},\n",
    "                                   ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('pcr_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83756c57-8d08-4b62-8dc7-12cd5534b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-------------+------------+--------------+------------+\n",
      "|    | Model                     |   Train MSE |   Test MSE |     Train R2 |    Test R2 |\n",
      "+====+===========================+=============+============+==============+============+\n",
      "|  0 | LinearRegression          | 0.214924    |  0.24649   |  0.738762    |  0.824643  |\n",
      "+----+---------------------------+-------------+------------+--------------+------------+\n",
      "|  1 | Ridge                     | 0.2159      |  0.261725  |  0.737576    |  0.813805  |\n",
      "+----+---------------------------+-------------+------------+--------------+------------+\n",
      "|  2 | Lasso                     | 0.813518    |  1.7414    |  0.0111774   | -0.238859  |\n",
      "+----+---------------------------+-------------+------------+--------------+------------+\n",
      "|  3 | RandomForestRegressor     | 0.0529019   |  0.548713  |  0.935698    |  0.609637  |\n",
      "+----+---------------------------+-------------+------------+--------------+------------+\n",
      "|  4 | GradientBoostingRegressor | 1.90366e-05 |  0.627053  |  0.999977    |  0.553904  |\n",
      "+----+---------------------------+-------------+------------+--------------+------------+\n",
      "|  5 | MLPRegressor              | 2.33865e+11 |  2.339e+11 | -2.84261e+11 | -1.664e+11 |\n",
      "+----+---------------------------+-------------+------------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor  # Import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# List of regression models including MLPRegressor\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)  # Neural Network\n",
    "]\n",
    "\n",
    "# Apply PCR to each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # Apply PCA to reduce dimensionality\n",
    "    num_components = 5  # You can choose the number of principal components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Train the model with principal components\n",
    "    if model_name == 'MLPRegressor':\n",
    "        # For the neural network, use the original features instead of principal components\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_test = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train_pca, y_train)\n",
    "        pred_train = model.predict(X_train_pca)\n",
    "        pred_test = model.predict(X_test_pca)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "\n",
    "    # Store results in the DataFrame\n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': train_mse,\n",
    "                                    'Test MSE': test_mse, 'Train R2': train_r2, 'Test R2': test_r2},\n",
    "                                   ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('pcr_nn_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b82bc5b2-2923-495f-8939-eaa7a10d0e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+========================+=============+============+============+===========+\n",
      "|  0 | K-Nearest Neighbors    |   0.247304  |   0.517502 |   0.699404 |  0.631841 |\n",
      "+----+------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Support Vector Machine |   0.0490177 |   0.335433 |   0.940419 |  0.761368 |\n",
      "+----+------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "#Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN'\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can choose the number of neighbors\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "knn_pred_train = knn_model.predict(X_train_scaled)\n",
    "knn_pred_test = knn_model.predict(X_test_scaled)\n",
    "knn_train_mse = mean_squared_error(y_train, knn_pred_train)\n",
    "knn_test_mse = mean_squared_error(y_test, knn_pred_test)\n",
    "knn_train_r2 = r2_score(y_train, knn_pred_train)\n",
    "knn_test_r2 = r2_score(y_test, knn_pred_test)\n",
    "results_df = results_df.append({'Model': 'K-Nearest Neighbors', 'Train MSE': knn_train_mse,\n",
    "                                'Test MSE': knn_test_mse, 'Train R2': knn_train_r2, 'Test R2': knn_test_r2},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')  # You can choose the kernel and tune other hyperparameters\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_pred_train = svm_model.predict(X_train_scaled)\n",
    "svm_pred_test = svm_model.predict(X_test_scaled)\n",
    "svm_train_mse = mean_squared_error(y_train, svm_pred_train)\n",
    "svm_test_mse = mean_squared_error(y_test, svm_pred_test)\n",
    "svm_train_r2 = r2_score(y_train, svm_pred_train)\n",
    "svm_test_r2 = r2_score(y_test, svm_pred_test)\n",
    "results_df = results_df.append({'Model': 'Support Vector Machine', 'Train MSE': svm_train_mse,\n",
    "                                'Test MSE': svm_test_mse, 'Train R2': svm_train_r2, 'Test R2': svm_test_r2},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ebb291b-b144-4659-8608-e2170fa3e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "+----+------------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                        |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+==============================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network        |    0.141963 |   0.593565 |   0.82762  |  0.634188 |\n",
      "+----+------------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Convolutional Neural Network |    0.338521 |   0.606863 |   0.588948 |  0.625993 |\n",
      "+----+------------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_start_delay'], axis=1)\n",
    "y = df['Phase_start_delay']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Define a Convolutional Neural Network (CNN)\n",
    "def build_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Reshape data for CNN (add an extra dimension for channels)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Define a Convolutional Neural Network (CNN)\n",
    "def build_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the CNN\n",
    "cnn = build_cnn()\n",
    "cnn.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_cnn = cnn.predict(X_train_reshaped)\n",
    "pred_test_cnn = cnn.predict(X_test_reshaped)\n",
    "train_mse_cnn = mean_squared_error(y_train, pred_train_cnn)\n",
    "test_mse_cnn = mean_squared_error(y_test, pred_test_cnn)\n",
    "train_r2_cnn = r2_score(y_train, pred_train_cnn)\n",
    "test_r2_cnn = r2_score(y_test, pred_test_cnn)\n",
    "results_df = results_df.append({'Model': 'Convolutional Neural Network', 'Train MSE': train_mse_cnn,\n",
    "                                'Test MSE': test_mse_cnn, 'Train R2': train_r2_cnn, 'Test R2': test_r2_cnn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('neural_network_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe39e9-fa53-4372-982e-9124a7fddb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71634fb-8f1e-4d2d-9023-7feb5921af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2fe209-8501-48ee-b35f-0b7d888f16c9",
   "metadata": {},
   "source": [
    "### Deaeration for Tanks 2 MT 1&2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351e04f5-c156-43f5-b04f-7aa88e1e6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac75ad5-8489-43d2-a1c5-a7912cb763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a42ef6-82d3-4d16-a479-1f451969c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9482</th>\n",
       "      <td>9482</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>TAKE A SAMPLE AND SUBMIT FOR QA.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:43</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>9483</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:54</td>\n",
       "      <td>08/05/2022 11:55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>9484</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>STEP8_AGITATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>9485</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S4_BATCH_COMPLETE_QA_PENDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>08/05/2022 11:56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>9486</td>\n",
       "      <td>3055706</td>\n",
       "      <td>107737576</td>\n",
       "      <td>2502</td>\n",
       "      <td>S7_RELEASED_TO_FILLING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>08/05/2022 12:02</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9487 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Material    BATCHID  Tank_1  \\\n",
       "0              0   1002150  107643491    2503   \n",
       "1              1   1002150  107643491    2503   \n",
       "2              2   1002150  107643491    2503   \n",
       "3              3   1002150  107643491    2503   \n",
       "4              4   1002150  107643491    2503   \n",
       "...          ...       ...        ...     ...   \n",
       "9482        9482   3055706  107737576    2502   \n",
       "9483        9483   3055706  107737576    2502   \n",
       "9484        9484   3055706  107737576    2502   \n",
       "9485        9485   3055706  107737576    2502   \n",
       "9486        9486   3055706  107737576    2502   \n",
       "\n",
       "                                   Instruction_Step INGRED_ID  \\\n",
       "0                              S3_BATCH_IN_PROGRESS       NaN   \n",
       "1                                        STEP1_CONS   1002565   \n",
       "2                       PLEASE VERIFY BULK ADDITION       NaN   \n",
       "3                                        STEP1_CONS   1037802   \n",
       "4                                        STEP1_CONS   1002818   \n",
       "...                                             ...       ...   \n",
       "9482               TAKE A SAMPLE AND SUBMIT FOR QA.       NaN   \n",
       "9483  SAMPLE TO LAB. RESULTS OK? (NO TO HOMOGENISE)       NaN   \n",
       "9484                                STEP8_AGITATION       NaN   \n",
       "9485                   S4_BATCH_COMPLETE_QA_PENDING       NaN   \n",
       "9486                         S7_RELEASED_TO_FILLING       NaN   \n",
       "\n",
       "                               INGRED_Name  Quantity       Phase_start  \\\n",
       "0                                      NaN     0.000  09/03/2022 10:42   \n",
       "1                            WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2                                      NaN     0.000  09/03/2022 11:16   \n",
       "3     S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4     S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "...                                    ...       ...               ...   \n",
       "9482                                   NaN     0.000  08/05/2022 11:43   \n",
       "9483                                   NaN     0.000  08/05/2022 11:54   \n",
       "9484                                   NaN     0.000  08/05/2022 11:56   \n",
       "9485                                   NaN     0.000  08/05/2022 11:56   \n",
       "9486                                   NaN     0.000  08/05/2022 12:02   \n",
       "\n",
       "             Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0     09/03/2022 10:42               0                  0             1   \n",
       "1     09/03/2022 11:16              34                  0             2   \n",
       "2     09/03/2022 11:17               1                  0             3   \n",
       "3     09/03/2022 11:27              10                  0             4   \n",
       "4     09/03/2022 11:38              11                  0             5   \n",
       "...                ...             ...                ...           ...   \n",
       "9482  08/05/2022 11:54              11                  0            19   \n",
       "9483  08/05/2022 11:55               1                  0            20   \n",
       "9484  08/05/2022 11:56               0                  1            21   \n",
       "9485  08/05/2022 11:56               0                  0            22   \n",
       "9486  08/05/2022 12:02               0                  6            23   \n",
       "\n",
       "      Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0             0.0000              NaN                      0            NaN   \n",
       "1           169.4118         733.5050                      8           26.0   \n",
       "2             0.0000              NaN                      3            0.0   \n",
       "3             0.5629           6.3182                      1            9.0   \n",
       "4             7.1605           6.3182                     12            0.0   \n",
       "...              ...              ...                    ...            ...   \n",
       "9482          0.0000              NaN                     10            1.0   \n",
       "9483          0.0000              NaN                     10            0.0   \n",
       "9484          0.0000              NaN                      0            0.0   \n",
       "9485          0.0000              NaN                      0            NaN   \n",
       "9486          0.0000              NaN                     14            0.0   \n",
       "\n",
       "      Deaeration Phase  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "9482                 0  \n",
       "9483                 0  \n",
       "9484                 0  \n",
       "9485                 0  \n",
       "9486                 0  \n",
       "\n",
       "[9487 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf73d0c-7499-465d-8d22-5701d012c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29eb9da9-262d-406d-ba7a-38815a02423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Data = pd.DataFrame(ProductionTank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3327649b-010d-47d2-9241-b9bd93cd5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.replace(\"STEP2_CONS\", \n",
    "           \"STEP2_CONS-Deaeration\", \n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d862f7-a2d3-472d-87b3-1b3f350b6b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction_Step     25\n",
      "Phase_start_delay     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Data[['Instruction_Step', 'Phase_start_delay']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97f96b8-b75f-4036-8ea4-94bf7318ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = Data[Data['Instruction_Step'] == 'STEP2_CONS-Deaeration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268b431-79ca-455f-8f1b-7ebf01ae0b4d",
   "metadata": {},
   "source": [
    "#### Exploring the different deaeration times ( start Phase delay duration) for each of the groups of productions tanks and their common materials "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ec279-fc68-4b75-ad24-25f8e25665fb",
   "metadata": {},
   "source": [
    "#### Deaeration in  Production Tanks : ''2301','2302','2304','2305'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4c09b9-f558-4a64-9b0d-423f998d4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanks_in_group1 = [2501,2502]\n",
    "instruction_step_of_interest = 'STEP2_CONS-Deaeration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753d659e-387e-4571-94d1-6b6fcd317ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = Data[(Data['Tank_1'].isin(tanks_in_group1)) & \n",
    "                    (Data['Instruction_Step'] == instruction_step_of_interest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b5ee40-0fdf-4d30-81b4-9ee819779830",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_materials = filtered_data.groupby('Material').filter(lambda x: x['Tank_1'].nunique() == len(tanks_in_group1))['Material'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d032e018-1612-4023-b084-a98a797e4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data1 = filtered_data[filtered_data['Material'].isin(common_materials)]\n",
    "#filtered_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c373d248-daee-42cb-95cb-a27ca471c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'BATCHID','Instruction_Step'])['Phase_duration'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4796b7-633c-4f6c-ab54-68e63139dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=filtered_data, x='Material', y='Phase_start_delay', hue='Tank_1', ci=None)\n",
    "\n",
    "plt.title('Phase_start_delay for ALL Materials during Deaeration Phase Across 25MT Tanks')\n",
    "plt.ylabel('Phase_start_delay')\n",
    "plt.xlabel('Material')\n",
    "plt.legend(title='Tank_1', loc='upper right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f8229b-87ff-4d87-8131-2d4512ac1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=filtered_data1, x='Material', y='Phase_start_delay', hue='Tank_1', ci=None)\n",
    "\n",
    "plt.title('Phase_start_delay for Common Materials during Deaeration Phase Across 25MT Tanks')\n",
    "plt.ylabel('Phase_start_delay')\n",
    "plt.xlabel('Material')\n",
    "plt.legend(title='Tank_1', loc='upper right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f53f8-38a7-40f4-b42a-7607205f32bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33d6366-beb5-41e8-ac7f-639bc9e1bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredient_of_interest = ['1461896', '1254972','1031006','1243269','1196706','1815609']\n",
    "#ingredient_data = data[data['INGRED_ID'] == ingredient_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00cc340d-2365-4260-ad2b-13912e94dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID       Instruction_Step  Phase_start_delay\n",
      "0     2501  107548283  STEP2_CONS-Deaeration                622\n",
      "1     2501  107599589  STEP2_CONS-Deaeration                477\n",
      "2     2501  107619398  STEP2_CONS-Deaeration                238\n",
      "3     2501  107654587  STEP2_CONS-Deaeration                161\n",
      "4     2501  107673784  STEP2_CONS-Deaeration                433\n",
      "5     2501  107692170  STEP2_CONS-Deaeration                900\n",
      "6     2501  107721584  STEP2_CONS-Deaeration                765\n",
      "7     2501  107781849  STEP2_CONS-Deaeration                539\n",
      "8     2501  107799508  STEP2_CONS-Deaeration                291\n",
      "9     2501  107829242  STEP2_CONS-Deaeration                329\n",
      "10    2501  107837364  STEP2_CONS-Deaeration                227\n",
      "11    2501  107858284  STEP2_CONS-Deaeration                590\n",
      "12    2501  107884951  STEP2_CONS-Deaeration                844\n",
      "13    2501  107894171  STEP2_CONS-Deaeration                663\n",
      "14    2501  107907568  STEP2_CONS-Deaeration                682\n",
      "15    2501  107926373  STEP2_CONS-Deaeration                573\n",
      "16    2501  107949933  STEP2_CONS-Deaeration               2261\n",
      "17    2501  107963440  STEP2_CONS-Deaeration                513\n",
      "18    2501  107975586  STEP2_CONS-Deaeration                569\n",
      "19    2501  108033842  STEP2_CONS-Deaeration                109\n",
      "20    2501  108049009  STEP2_CONS-Deaeration                392\n",
      "21    2501  108051967  STEP2_CONS-Deaeration                182\n",
      "22    2501  108058736  STEP2_CONS-Deaeration                169\n",
      "23    2501  108058739  STEP2_CONS-Deaeration               2050\n",
      "24    2501  108068562  STEP2_CONS-Deaeration                386\n",
      "25    2502  107573888  STEP2_CONS-Deaeration                574\n",
      "26    2502  107630217  STEP2_CONS-Deaeration                302\n",
      "27    2502  107643502  STEP2_CONS-Deaeration                349\n",
      "28    2502  107673347  STEP2_CONS-Deaeration                214\n",
      "29    2502  107673776  STEP2_CONS-Deaeration                191\n",
      "30    2502  107700722  STEP2_CONS-Deaeration               4187\n",
      "31    2502  107711607  STEP2_CONS-Deaeration                174\n",
      "32    2502  107737576  STEP2_CONS-Deaeration                209\n",
      "33    2502  107741788  STEP2_CONS-Deaeration               1142\n",
      "34    2502  107790594  STEP2_CONS-Deaeration                791\n",
      "35    2502  107815341  STEP2_CONS-Deaeration                523\n",
      "36    2502  107829240  STEP2_CONS-Deaeration                248\n",
      "37    2502  107831024  STEP2_CONS-Deaeration                152\n",
      "38    2502  107831025  STEP2_CONS-Deaeration                562\n",
      "39    2502  107872046  STEP2_CONS-Deaeration                557\n",
      "40    2502  107874920  STEP2_CONS-Deaeration                222\n",
      "41    2502  107896329  STEP2_CONS-Deaeration                985\n",
      "42    2502  107907571  STEP2_CONS-Deaeration                780\n",
      "43    2502  107916897  STEP2_CONS-Deaeration                145\n",
      "44    2502  107949935  STEP2_CONS-Deaeration                302\n",
      "45    2502  107971789  STEP2_CONS-Deaeration                267\n",
      "46    2502  108033836  STEP2_CONS-Deaeration                904\n",
      "47    2502  108045551  STEP2_CONS-Deaeration                218\n",
      "48    2502  108084758  STEP2_CONS-Deaeration                331\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = [2501,2502]\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP2_CONS-Deaeration']\n",
    "filtered_data = Data[(Data['Instruction_Step'].isin(desired_steps)) & (Data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_Phase_start_delay = filtered_data.groupby(['Tank_1','BATCHID','Instruction_Step'])['Phase_start_delay'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID','Material']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "#print(aggregated_total_durations_df2)\n",
    "print(total_Phase_start_delay)\n",
    "\n",
    "\n",
    "aggregated_total_durations_df2.to_csv('DeaerationPhase25MT12.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea720dac-c31d-41ba-8be7-c425a58ae6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2501  107548283   1880112              15            7.0   \n",
      "1     2501  107599589   1648718             166          132.0   \n",
      "2     2501  107619398   1880112              11            3.0   \n",
      "3     2501  107654587   1756358               8            2.0   \n",
      "4     2501  107673784   1397022             375          366.0   \n",
      "5     2501  107692170   1486042              10            3.0   \n",
      "6     2501  107721584   1756358               5            0.0   \n",
      "7     2501  107781849   1756358              15            9.0   \n",
      "8     2501  107799508   1521498              11            3.0   \n",
      "9     2501  107829242   1756358              11            5.0   \n",
      "10    2501  107837364   1756358               5            0.0   \n",
      "11    2501  107858284   3044756               8            2.0   \n",
      "12    2501  107884951   1648718             220          186.0   \n",
      "13    2501  107894171   1648718             406          371.0   \n",
      "14    2501  107907568   1756358              10            4.0   \n",
      "15    2501  107926373   1006884               9            2.0   \n",
      "16    2501  107949933   1756358               5            0.0   \n",
      "17    2501  107963440   1529065              17           11.0   \n",
      "18    2501  107975586   1756358               3            0.0   \n",
      "19    2501  108033842   1607495               5            0.0   \n",
      "20    2501  108049009   1875468              52           43.0   \n",
      "21    2501  108051967   1172415              61           41.0   \n",
      "22    2501  108058736   1756358               3            0.0   \n",
      "23    2501  108058739   1974017              10            3.0   \n",
      "24    2501  108068562   1552603              19           12.0   \n",
      "25    2502  107573888   1779699              14            6.0   \n",
      "26    2502  107630217   1667507              10            3.0   \n",
      "27    2502  107643502   1779699               9            1.0   \n",
      "28    2502  107673347   1756358               4            0.0   \n",
      "29    2502  107673776   1648718             267          235.0   \n",
      "30    2502  107700722   1875468              11            2.0   \n",
      "31    2502  107711607   1648718              79           46.0   \n",
      "32    2502  107737576   3055706              10            5.0   \n",
      "33    2502  107741788   1779699               9            1.0   \n",
      "34    2502  107790594   1648718             162          128.0   \n",
      "35    2502  107815341   3044756              38           32.0   \n",
      "36    2502  107829240   1648718             210          177.0   \n",
      "37    2502  107831024   1667507              10            6.0   \n",
      "38    2502  107831025   1875468               7            0.0   \n",
      "39    2502  107872046   1172993              41           32.0   \n",
      "40    2502  107874920   1529065               4            0.0   \n",
      "41    2502  107896329   1172415              24            4.0   \n",
      "42    2502  107907571   1875468              64           55.0   \n",
      "43    2502  107916897   1779699             557          549.0   \n",
      "44    2502  107949935   1779699              14            6.0   \n",
      "45    2502  107971789   1006884              17           10.0   \n",
      "46    2502  108033836   1006884              27           20.0   \n",
      "47    2502  108045551   1529065              15            6.0   \n",
      "48    2502  108084758   1875468              16            7.0   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0                 622   519.796         34.6531                   8.00   \n",
      "1                 477  2066.121         52.5320                   8.50   \n",
      "2                 238   519.297         47.2088                   8.00   \n",
      "3                 161    27.911          3.4889                   6.00   \n",
      "4                 433   398.803          1.0635                   9.00   \n",
      "5                 900   285.129         28.5129                   7.00   \n",
      "6                 765    27.895          5.5790                   6.00   \n",
      "7                 539    27.883          1.8589                   6.00   \n",
      "8                 291   348.952         31.7229                   8.00   \n",
      "9                 329    27.889          2.5354                   6.00   \n",
      "10                227    27.893          5.5786                   6.00   \n",
      "11                590   252.631         31.5789                   6.00   \n",
      "12                844  2064.760         39.4834                   8.50   \n",
      "13                663  2064.891         58.4828                   8.75   \n",
      "14                682    27.955          2.7955                   6.00   \n",
      "15                573   306.234         34.0260                   7.00   \n",
      "16               2261    26.038          5.2076                   6.00   \n",
      "17                513   262.873         15.4631                   6.00   \n",
      "18                569    26.958          8.9860                   6.00   \n",
      "19                109   365.200         73.0400                   8.00   \n",
      "20                392   399.026          7.6736                   9.00   \n",
      "21                182   383.001          9.7920                  10.00   \n",
      "22                169    26.985          8.9950                   6.00   \n",
      "23               2050   274.253         27.4253                   7.00   \n",
      "24                386   198.649         10.4552                   7.00   \n",
      "25                574   359.335         25.6668                   8.00   \n",
      "26                302   338.087         33.8087                   7.00   \n",
      "27                349   359.535         39.9483                   8.00   \n",
      "28                214    27.928          6.9820                   6.00   \n",
      "29                191  2064.623         57.5114                   8.50   \n",
      "30               4187   398.504         36.2276                   9.00   \n",
      "31                174  2064.432        126.1485                   8.50   \n",
      "32                209   216.511         21.6511                   5.00   \n",
      "33               1142   359.335         39.9261                   8.00   \n",
      "34                791  2065.375         49.1544                   8.50   \n",
      "35                523   252.768          6.6518                   6.00   \n",
      "36                248  2065.845         97.1284                   8.50   \n",
      "37                152   129.033         12.9033                   4.00   \n",
      "38                562   193.891         27.6987                   7.00   \n",
      "39                557   418.152         10.1988                   9.00   \n",
      "40                222   389.500         97.3750                   9.00   \n",
      "41                985   384.000         27.0089                  10.00   \n",
      "42                780   398.813          6.2315                   9.00   \n",
      "43                145   359.635          0.6457                   8.00   \n",
      "44                302   359.029         25.6449                   8.00   \n",
      "45                267   306.310         18.0182                   7.00   \n",
      "46                904   302.247         11.1943                   7.00   \n",
      "47                218   390.000         26.0000                   9.00   \n",
      "48                331   400.200         25.0125                   9.00   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0         65.412400  \n",
      "1         52.930175  \n",
      "2         65.412400  \n",
      "3          4.488600  \n",
      "4         45.283300  \n",
      "5         42.155900  \n",
      "6          4.488600  \n",
      "7          4.488600  \n",
      "8         45.283300  \n",
      "9          4.488600  \n",
      "10         4.488600  \n",
      "11        42.155900  \n",
      "12        52.930175  \n",
      "13        52.930175  \n",
      "14         4.488600  \n",
      "15        45.283300  \n",
      "16         4.488600  \n",
      "17        42.155900  \n",
      "18         4.488600  \n",
      "19        45.283300  \n",
      "20        45.283300  \n",
      "21        14.892450  \n",
      "22         4.488600  \n",
      "23        42.155900  \n",
      "24        29.540000  \n",
      "25        45.283300  \n",
      "26        45.283300  \n",
      "27        45.283300  \n",
      "28         4.488600  \n",
      "29        52.930175  \n",
      "30        45.283300  \n",
      "31        52.930175  \n",
      "32        42.155900  \n",
      "33        45.283300  \n",
      "34        52.930175  \n",
      "35        42.155900  \n",
      "36        52.930175  \n",
      "37        29.540000  \n",
      "38        29.540000  \n",
      "39        45.283300  \n",
      "40        45.283300  \n",
      "41        14.892450  \n",
      "42        45.283300  \n",
      "43        45.283300  \n",
      "44        45.283300  \n",
      "45        45.283300  \n",
      "46        45.283300  \n",
      "47        45.283300  \n",
      "48        45.283300  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = [2501,2502]\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP2_CONS-Deaeration']\n",
    "filtered_data = Data[(Data['Instruction_Step'].isin(desired_steps)) & (Data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_Phase_start_delay = filtered_data.groupby(['Tank_1','Material','Instruction_Step'])['Phase_start_delay'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID','Material']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "print(aggregated_total_durations_df2)\n",
    "aggregated_total_durations_df2.to_csv('DeaerationPhase25MT14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c827824-d055-4ce5-a232-697b9b4bddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "#aggregated_total_durations_df2.dropna(inplace=True)  # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1dd2246-274f-43c0-8e34-ce1380e376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling du# Handling duplicates\n",
    "#aggregated_total_durations_df2.drop_duplicates(inplace=True)  # Remove duplicate rowsplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff37f00e-5bfc-4898-9d25-43652b4b4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2501  107548283   1880112              15            7.0   \n",
      "2     2501  107619398   1880112              11            3.0   \n",
      "3     2501  107654587   1756358               8            2.0   \n",
      "5     2501  107692170   1486042              10            3.0   \n",
      "6     2501  107721584   1756358               5            0.0   \n",
      "7     2501  107781849   1756358              15            9.0   \n",
      "8     2501  107799508   1521498              11            3.0   \n",
      "9     2501  107829242   1756358              11            5.0   \n",
      "10    2501  107837364   1756358               5            0.0   \n",
      "11    2501  107858284   3044756               8            2.0   \n",
      "14    2501  107907568   1756358              10            4.0   \n",
      "15    2501  107926373   1006884               9            2.0   \n",
      "17    2501  107963440   1529065              17           11.0   \n",
      "18    2501  107975586   1756358               3            0.0   \n",
      "22    2501  108058736   1756358               3            0.0   \n",
      "24    2501  108068562   1552603              19           12.0   \n",
      "25    2502  107573888   1779699              14            6.0   \n",
      "26    2502  107630217   1667507              10            3.0   \n",
      "27    2502  107643502   1779699               9            1.0   \n",
      "28    2502  107673347   1756358               4            0.0   \n",
      "32    2502  107737576   3055706              10            5.0   \n",
      "33    2502  107741788   1779699               9            1.0   \n",
      "37    2502  107831024   1667507              10            6.0   \n",
      "38    2502  107831025   1875468               7            0.0   \n",
      "41    2502  107896329   1172415              24            4.0   \n",
      "44    2502  107949935   1779699              14            6.0   \n",
      "45    2502  107971789   1006884              17           10.0   \n",
      "46    2502  108033836   1006884              27           20.0   \n",
      "47    2502  108045551   1529065              15            6.0   \n",
      "48    2502  108084758   1875468              16            7.0   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0                 622   519.796         34.6531                    8.0   \n",
      "2                 238   519.297         47.2088                    8.0   \n",
      "3                 161    27.911          3.4889                    6.0   \n",
      "5                 900   285.129         28.5129                    7.0   \n",
      "6                 765    27.895          5.5790                    6.0   \n",
      "7                 539    27.883          1.8589                    6.0   \n",
      "8                 291   348.952         31.7229                    8.0   \n",
      "9                 329    27.889          2.5354                    6.0   \n",
      "10                227    27.893          5.5786                    6.0   \n",
      "11                590   252.631         31.5789                    6.0   \n",
      "14                682    27.955          2.7955                    6.0   \n",
      "15                573   306.234         34.0260                    7.0   \n",
      "17                513   262.873         15.4631                    6.0   \n",
      "18                569    26.958          8.9860                    6.0   \n",
      "22                169    26.985          8.9950                    6.0   \n",
      "24                386   198.649         10.4552                    7.0   \n",
      "25                574   359.335         25.6668                    8.0   \n",
      "26                302   338.087         33.8087                    7.0   \n",
      "27                349   359.535         39.9483                    8.0   \n",
      "28                214    27.928          6.9820                    6.0   \n",
      "32                209   216.511         21.6511                    5.0   \n",
      "33               1142   359.335         39.9261                    8.0   \n",
      "37                152   129.033         12.9033                    4.0   \n",
      "38                562   193.891         27.6987                    7.0   \n",
      "41                985   384.000         27.0089                   10.0   \n",
      "44                302   359.029         25.6449                    8.0   \n",
      "45                267   306.310         18.0182                    7.0   \n",
      "46                904   302.247         11.1943                    7.0   \n",
      "47                218   390.000         26.0000                    9.0   \n",
      "48                331   400.200         25.0125                    9.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0          65.41240  \n",
      "2          65.41240  \n",
      "3           4.48860  \n",
      "5          42.15590  \n",
      "6           4.48860  \n",
      "7           4.48860  \n",
      "8          45.28330  \n",
      "9           4.48860  \n",
      "10          4.48860  \n",
      "11         42.15590  \n",
      "14          4.48860  \n",
      "15         45.28330  \n",
      "17         42.15590  \n",
      "18          4.48860  \n",
      "22          4.48860  \n",
      "24         29.54000  \n",
      "25         45.28330  \n",
      "26         45.28330  \n",
      "27         45.28330  \n",
      "28          4.48860  \n",
      "32         42.15590  \n",
      "33         45.28330  \n",
      "37         29.54000  \n",
      "38         29.54000  \n",
      "41         14.89245  \n",
      "44         45.28330  \n",
      "45         45.28330  \n",
      "46         45.28330  \n",
      "47         45.28330  \n",
      "48         45.28330  \n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank254_df = pd.DataFrame(aggregated_total_durations_df2)\n",
    "ProductionTank254_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "  ProductionTank254_df = remove_outliers_iqr(ProductionTank254_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank254_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea6a804-d22e-41f5-9e07-92934bbc8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1    BATCHID  Material  Phase_duration  Phase_overrun  \\\n",
      "0     2501  107548283   1880112        0.618172       0.543400   \n",
      "2     2501  107619398   1880112       -0.095103      -0.362267   \n",
      "3     2501  107654587   1756358       -0.630060      -0.588683   \n",
      "5     2501  107692170   1486042       -0.273422      -0.362267   \n",
      "6     2501  107721584   1756358       -1.165017      -1.041517   \n",
      "7     2501  107781849   1756358        0.618172       0.996234   \n",
      "8     2501  107799508   1521498       -0.095103      -0.362267   \n",
      "9     2501  107829242   1756358       -0.095103       0.090567   \n",
      "10    2501  107837364   1756358       -1.165017      -1.041517   \n",
      "11    2501  107858284   3044756       -0.630060      -0.588683   \n",
      "14    2501  107907568   1756358       -0.273422      -0.135850   \n",
      "15    2501  107926373   1006884       -0.451741      -0.588683   \n",
      "17    2501  107963440   1529065        0.974810       1.449067   \n",
      "18    2501  107975586   1756358       -1.521655      -1.041517   \n",
      "22    2501  108058736   1756358       -1.521655      -1.041517   \n",
      "24    2501  108068562   1552603        1.331448       1.675484   \n",
      "25    2502  107573888   1779699        0.439853       0.316983   \n",
      "26    2502  107630217   1667507       -0.273422      -0.362267   \n",
      "27    2502  107643502   1779699       -0.451741      -0.815100   \n",
      "28    2502  107673347   1756358       -1.343336      -1.041517   \n",
      "32    2502  107737576   3055706       -0.273422       0.090567   \n",
      "33    2502  107741788   1779699       -0.451741      -0.815100   \n",
      "37    2502  107831024   1667507       -0.273422       0.316983   \n",
      "38    2502  107831025   1875468       -0.808379      -1.041517   \n",
      "41    2502  107896329   1172415        2.223042      -0.135850   \n",
      "44    2502  107949935   1779699        0.439853       0.316983   \n",
      "45    2502  107971789   1006884        0.974810       1.222650   \n",
      "46    2502  108033836   1006884        2.757999       3.486817   \n",
      "47    2502  108045551   1529065        0.618172       0.316983   \n",
      "48    2502  108084758   1875468        0.796491       0.543400   \n",
      "\n",
      "    Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "0            0.579795   519.796        1.098275                    8.0   \n",
      "2           -0.873793   519.297        2.072368                    8.0   \n",
      "3           -1.165268    27.911       -1.319497                    6.0   \n",
      "5            1.632132   285.129        0.621908                    7.0   \n",
      "6            1.121105    27.895       -1.157343                    6.0   \n",
      "7            0.265608    27.883       -1.445955                    6.0   \n",
      "8           -0.673168   348.952        0.870945                    8.0   \n",
      "9           -0.529323    27.889       -1.393471                    6.0   \n",
      "10          -0.915433    27.893       -1.157374                    6.0   \n",
      "11           0.458663   252.631        0.859773                    6.0   \n",
      "14           0.806918    27.955       -1.373292                    6.0   \n",
      "15           0.394311   306.234        1.049624                    7.0   \n",
      "17           0.167188   262.873       -0.390518                    6.0   \n",
      "18           0.379170    26.958       -0.893022                    6.0   \n",
      "22          -1.134985    26.985       -0.892324                    6.0   \n",
      "24          -0.313556   198.649       -0.779039                    7.0   \n",
      "25           0.398096   359.335        0.401103                    8.0   \n",
      "26          -0.631529   338.087        1.032765                    7.0   \n",
      "27          -0.453615   359.535        1.509086                    8.0   \n",
      "28          -0.964643    27.928       -1.048496                    6.0   \n",
      "32          -0.983570   216.511        0.089558                    5.0   \n",
      "33           2.548196   359.335        1.507363                    8.0   \n",
      "37          -1.199337   129.033       -0.589111                    4.0   \n",
      "38           0.352672   193.891        0.558741                    7.0   \n",
      "41           1.953890   384.000        0.505225                   10.0   \n",
      "44          -0.631529   359.029        0.399404                    8.0   \n",
      "45          -0.764017   306.310       -0.192289                    7.0   \n",
      "46           1.647274   302.247       -0.721699                    7.0   \n",
      "47          -0.949501   390.000        0.426953                    9.0   \n",
      "48          -0.521752   400.200        0.350341                    9.0   \n",
      "\n",
      "    Target_Flowrate  \n",
      "0          65.41240  \n",
      "2          65.41240  \n",
      "3           4.48860  \n",
      "5          42.15590  \n",
      "6           4.48860  \n",
      "7           4.48860  \n",
      "8          45.28330  \n",
      "9           4.48860  \n",
      "10          4.48860  \n",
      "11         42.15590  \n",
      "14          4.48860  \n",
      "15         45.28330  \n",
      "17         42.15590  \n",
      "18          4.48860  \n",
      "22          4.48860  \n",
      "24         29.54000  \n",
      "25         45.28330  \n",
      "26         45.28330  \n",
      "27         45.28330  \n",
      "28          4.48860  \n",
      "32         42.15590  \n",
      "33         45.28330  \n",
      "37         29.54000  \n",
      "38         29.54000  \n",
      "41         14.89245  \n",
      "44         45.28330  \n",
      "45         45.28330  \n",
      "46         45.28330  \n",
      "47         45.28330  \n",
      "48         45.28330  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN']\n",
    "ProductionTank254_df[numerical_cols] = scaler.fit_transform(ProductionTank254_df[numerical_cols])\n",
    "print(ProductionTank254_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58871e9d-b507-493d-8245-6443bda1dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Summary Statistics:\n",
      "            Tank_1       BATCHID      Material  Phase_duration  Phase_overrun  \\\n",
      "count    49.000000  4.900000e+01  4.900000e+01       49.000000      49.000000   \n",
      "mean   2501.489796  1.078403e+08  1.720107e+06       62.836735      51.755102   \n",
      "std       0.505076  1.503463e+05  4.177283e+05      117.697767     112.607084   \n",
      "min    2501.000000  1.075483e+08  1.006884e+06        3.000000       0.000000   \n",
      "25%    2501.000000  1.077116e+08  1.552603e+06        9.000000       2.000000   \n",
      "50%    2501.000000  1.078374e+08  1.756358e+06       14.000000       6.000000   \n",
      "75%    2502.000000  1.079499e+08  1.779699e+06       41.000000      32.000000   \n",
      "max    2502.000000  1.080848e+08  3.055706e+06      557.000000     549.000000   \n",
      "\n",
      "       Phase_start_delay     Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count          49.000000    49.000000       49.000000              49.000000   \n",
      "mean          597.836735   521.634918       28.099496               7.484694   \n",
      "std           673.955313   652.326703       26.987645               1.369694   \n",
      "min           109.000000    26.038000        0.645700               4.000000   \n",
      "25%           227.000000   198.649000        7.673600               6.000000   \n",
      "50%           433.000000   359.029000       25.644900               8.000000   \n",
      "75%           663.000000   398.813000       36.227600               8.500000   \n",
      "max          4187.000000  2066.121000      126.148500              10.000000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count        49.000000  \n",
      "mean         36.284592  \n",
      "std          18.564833  \n",
      "min           4.488600  \n",
      "25%          29.540000  \n",
      "50%          45.283300  \n",
      "75%          45.283300  \n",
      "max          65.412400  \n",
      "\n",
      "Cleaned DataFrame Summary Statistics:\n",
      "            Tank_1       BATCHID      Material  Phase_duration  Phase_overrun  \\\n",
      "count    30.000000  3.000000e+01  3.000000e+01    3.000000e+01   3.000000e+01   \n",
      "mean   2501.466667  1.078296e+08  1.722800e+06    7.401487e-18   6.291264e-17   \n",
      "std       0.507416  1.582043e+05  4.429780e+05    1.017095e+00   1.017095e+00   \n",
      "min    2501.000000  1.075483e+08  1.006884e+06   -1.521655e+00  -1.041517e+00   \n",
      "25%    2501.000000  1.076995e+08  1.534950e+06   -5.854803e-01  -7.584960e-01   \n",
      "50%    2501.000000  1.078310e+08  1.756358e+06   -2.734223e-01  -2.490584e-01   \n",
      "75%    2502.000000  1.079601e+08  1.779699e+06    6.181721e-01   3.169834e-01   \n",
      "max    2502.000000  1.080848e+08  3.055706e+06    2.757999e+00   3.486817e+00   \n",
      "\n",
      "       Phase_start_delay    Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count       3.000000e+01   30.000000    3.000000e+01              30.000000   \n",
      "mean        1.073216e-16  234.679033   -1.313764e-16               6.933333   \n",
      "std         1.017095e+00  159.794768    1.017095e+00               1.284747   \n",
      "min        -1.199337e+00   26.958000   -1.445955e+00               4.000000   \n",
      "25%        -8.463493e-01   27.934750   -8.928477e-01               6.000000   \n",
      "50%        -3.835858e-01  274.001000    2.199493e-01               7.000000   \n",
      "75%         4.435211e-01  359.258500    8.003070e-01               8.000000   \n",
      "max         2.548196e+00  519.796000    2.072368e+00              10.000000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count        30.000000  \n",
      "mean         31.382485  \n",
      "std          20.083902  \n",
      "min           4.488600  \n",
      "25%           4.488600  \n",
      "50%          42.155900  \n",
      "75%          45.283300  \n",
      "max          65.412400  \n"
     ]
    }
   ],
   "source": [
    "# For the original DataFrame\n",
    "print(\"Original DataFrame Summary Statistics:\")\n",
    "print(aggregated_total_durations_df2.describe())\n",
    "\n",
    "# After removing outliers\n",
    "print(\"\\nCleaned DataFrame Summary Statistics:\")\n",
    "print(ProductionTank254_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32eccb79-e88b-4cd5-baa7-968f0f166525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |    Test R2 |\n",
      "+====+=============================+=============+============+============+============+\n",
      "|  0 | Linear Regression           | 0.137619    |   0.67155  |  0.729247  |  0.760979  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  1 | Ridge Regression            | 0.139642    |   0.744395 |  0.725268  |  0.735051  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  2 | Lasso Regression            | 0.465565    |   2.8752   |  0.0840468 | -0.0233572 |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  3 | Random Forest Regressor     | 0.0944811   |   1.55731  |  0.814118  |  0.445715  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  4 | Gradient Boosting Regressor | 0.00381066  |   1.04226  |  0.992503  |  0.629032  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  5 | Decision Tree Regressor     | 0.116108    |   1.59104  |  0.771569  |  0.433708  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  6 | Bagging Regressor           | 0.0141469   |   1.04575  |  0.972167  |  0.627792  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  7 | AdaBoost Regressor          | 0.00528393  |   0.901166 |  0.989604  |  0.679252  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n",
      "|  8 | Extra Trees Regressor       | 6.08674e-31 |   1.38982  |  1         |  0.505329  |\n",
      "+----+-----------------------------+-------------+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank2203_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_start_delay'], axis=1)\n",
    "\n",
    "#y = df['Phase_start_delay']\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Tank_1','BATCHID','Material','Target_Phase_duration','Target_Flowrate','Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "#gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=5, subsample=0.8, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "#dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('254DEresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f92c41cc-63b5-4881-9886-35d8d3f00469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.263993\n",
      "  Std MSE: 0.367683\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.236546\n",
      "  Std MSE: 0.322560\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.108685\n",
      "  Std MSE: 0.803278\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.331461\n",
      "  Std MSE: 0.450138\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.277558\n",
      "  Std MSE: 0.398431\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.332648\n",
      "  Std MSE: 1.056682\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 23.023992\n",
      "  Std MSE: 31.492294\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.358852\n",
      "  Std MSE: 0.402389\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.415247\n",
      "  Std MSE: 0.458362\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.353923\n",
      "  Std MSE: 0.456179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "       # Save the results to an Excel file\n",
    "df.to_excel(\"25MT4DEmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model. You can then open this file with Excel to view the results.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "245d25b8-fb9d-46b2-8aef-b2c04bdf2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge Regression: {'alpha': 1.0}\n",
      "Best parameters for Lasso Regression: {'alpha': 0.01}\n",
      "Best parameters for Random Forest Regressor: {'max_depth': None, 'n_estimators': 300}\n",
      "Best parameters for Gradient Boosting Regressor: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best parameters for Decision Tree Regressor: {'max_depth': 20}\n",
      "Best parameters for Bagging Regressor: {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 50}\n",
      "                         Model     Train MSE  Test MSE  Train R2   Test R2\n",
      "0            Linear Regression  1.521957e-01  0.616053  0.700570  0.780731\n",
      "1             Ridge Regression  1.558813e-01  0.659616  0.693319  0.765226\n",
      "2             Lasso Regression  1.527990e-01  0.642389  0.699383  0.771358\n",
      "3      Random Forest Regressor  9.914417e-03  0.924436  0.980494  0.670970\n",
      "4  Gradient Boosting Regressor  1.478096e-08  1.040419  1.000000  0.629689\n",
      "5      Decision Tree Regressor  0.000000e+00  0.897129  1.000000  0.680689\n",
      "6            Bagging Regressor  1.421053e-02  0.904720  0.972042  0.677988\n",
      "7           AdaBoost Regressor  6.073878e-03  0.845305  0.988050  0.699135\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           |  0.152196   |   0.616053 |   0.70057  |  0.780731 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            |  0.155881   |   0.659616 |   0.693319 |  0.765226 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            |  0.152799   |   0.642389 |   0.699383 |  0.771358 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     |  0.00991442 |   0.924436 |   0.980494 |  0.67097  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor |  1.4781e-08 |   1.04042  |   1        |  0.629689 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     |  0          |   0.897129 |   1        |  0.680689 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           |  0.0142105  |   0.90472  |   0.972042 |  0.677988 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          |  0.00607388 |   0.845305 |   0.98805  |  0.699135 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Tank_1','BATCHID','Material','Phase_start_delay','Target_Phase_duration','Target_Flowrate','Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Ridge Regression: {ridge_grid.best_params_}\")\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Lasso Regression: {lasso_grid.best_params_}\")\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Random Forest Regressor: {rf_grid.best_params_}\")\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Gradient Boosting Regressor: {gb_grid.best_params_}\")\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Decision Tree Regressor: {dt_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Bagging Regressor: {bag_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('254DEtunresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ed45817-3e56-4903-95b6-b17311ea76f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|    | Model                     |   Train MSE |    Test MSE |     Train R2 |      Test R2 |\n",
      "+====+===========================+=============+=============+==============+==============+\n",
      "|  0 | LinearRegression          | 0.157211    | 0.428013    |  0.832213    |  0.400427    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  1 | Ridge                     | 0.160486    | 0.400038    |  0.828793    |  0.470337    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  2 | Lasso                     | 0.692597    | 1.05113     |  0.286961    | -0.625949    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  3 | RandomForestRegressor     | 0.0718097   | 0.50648     |  0.93285     |  0.370733    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  4 | GradientBoostingRegressor | 1.86678e-06 | 0.705527    |  0.999998    |  0.00254895  |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  5 | SVR                       | 1.05723     | 1.06292     | -0.0559831   | -0.195154    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  6 | MLPRegressor              | 5.31379e+12 | 5.37599e+12 | -6.68962e+12 | -1.49528e+13 |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  7 | DecisionTreeRegressor     | 0           | 0.934723    |  1           | -0.40378     |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  8 | BaggingRegressor          | 0.0719569   | 0.51668     |  0.932692    |  0.365424    |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n",
      "|  9 | AdaBoostRegressor         | 0.0188673   | 0.675052    |  0.981665    | -0.00140766  |\n",
      "+----+---------------------------+-------------+-------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Initialize k-fold cross-validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Iterate through each model and perform k-fold cross-validation\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    train_mse_list = []\n",
    "    test_mse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_mse_list.append(train_mse)\n",
    "        test_mse_list.append(test_mse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "    \n",
    "    mean_train_mse = sum(train_mse_list) / num_folds\n",
    "    mean_test_mse = sum(test_mse_list) / num_folds\n",
    "    mean_train_r2 = sum(train_r2_list) / num_folds\n",
    "    mean_test_r2 = sum(test_r2_list) / num_folds\n",
    "    \n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': mean_train_mse, 'Test MSE': mean_test_mse,\n",
    "                                    'Train R2': mean_train_r2, 'Test R2': mean_test_r2}, ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('254kfold_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "679c3009-feb0-46f5-97d2-d675bd6960ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |   0.269822  |    1.67464 |   0.469151 |  0.403953 |      0.394388 |     0.179806 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |   0.0243923 |    1.72608 |   0.95201  |  0.385646 |      0.228475 |     0.098102 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters for K-Nearest Neighbors: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for Support Vector Machine: {'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |   0         |   1.62472  |   1        |  0.421721 |      0.379059 |     0.185918 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |   0.0682734 |   0.541804 |   0.865679 |  0.807158 |      0.160777 |     0.146087 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('254mtknn_svm_results_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa377dcc-44b7-4da4-a08d-ea7023833fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |  0.00701487 |   0.454512 |   0.986199 |  0.838228 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |  0.00701487 |   0.454512 |   0.986199 |  0.838228 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|  1 | LSTM Neural Network   |  0.246346   |   2.03213  |   0.515339 |  0.276715 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('254LSTM SIMPLE Neural Network.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0e5bc91-aa9d-426e-9809-acd08395e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x00000243F1710E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x00000243F27E43A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best Simple NN Params: {'batch_size': 64, 'dense1_neurons': 128, 'dense2_neurons': 16, 'epochs': 50}\n",
      "Training MSE: 0.013156402524197688\n",
      "Training R^2: 0.9741160508251653\n",
      "Test MSE: 0.30709571984019474\n",
      "Test R^2: 0.8906969598071068\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "results_df.to_excel('254mtSnn_results_hyper_tuned.xlsx', index=False)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bba7e36c-312d-4c09-ac15-acb97cab1c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best LSTM Params: {'batch_size': 64, 'epochs': 100, 'lstm_neurons': 70}\n",
      "Training MSE for LSTM: 0.03981656387773805\n",
      "Training R^2 for LSTM: 0.9216647625494582\n",
      "Test MSE for LSTM: 0.8356938572901188\n",
      "Test R^2 for LSTM: 0.7025556744331409\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)\n",
    "results_df.to_excel('254mtSnn_lstm results_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71abb759-7778-46c1-a18b-93a64a17819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|    |   param_neurons_layer1 |   param_neurons_layer2 |   param_batch_size |   param_epochs |   mean_test_score |   std_test_score |   rank_test_score |\n",
      "+====+========================+========================+====================+================+===================+==================+===================+\n",
      "|  0 |                     32 |                     32 |                 32 |             30 |         -0.290854 |         0.198547 |                 2 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  1 |                     32 |                     16 |                 64 |            100 |         -0.48034  |         0.30252  |                 5 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  2 |                     32 |                     32 |                 64 |             50 |         -0.327433 |         0.181034 |                 3 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  3 |                     32 |                     16 |                 16 |             30 |         -0.388561 |         0.152861 |                 4 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  4 |                    128 |                     64 |                 32 |            100 |         -0.249369 |         0.166235 |                 1 |\n",
      "+----+------------------------+------------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "Best Simple NN Params: {'neurons_layer2': 64, 'neurons_layer1': 128, 'epochs': 100, 'batch_size': 32}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|    |   param_lstm_neurons |   param_batch_size |   param_epochs |   mean_test_score |   std_test_score |   rank_test_score |\n",
      "+====+======================+====================+================+===================+==================+===================+\n",
      "|  0 |                   30 |                 16 |             50 |         -0.461191 |         0.188082 |                 5 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  1 |                   50 |                 64 |             50 |         -0.432595 |         0.184357 |                 3 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  2 |                   70 |                 32 |             50 |         -0.457918 |         0.158964 |                 4 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  3 |                   70 |                 64 |            100 |         -0.307684 |         0.125321 |                 1 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "|  4 |                   30 |                 16 |            100 |         -0.42153  |         0.205643 |                 2 |\n",
      "+----+----------------------+--------------------+----------------+-------------------+------------------+-------------------+\n",
      "Best LSTM Params: {'lstm_neurons': 70, 'epochs': 100, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('simple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('254MTLSTM_SNNresults.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "761ac33d-8096-4601-854d-d7309d9eec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+======================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network | 0.000591086 |   0.606384 |   0.998837 |  0.784173 |\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "Best Score:  -0.2313365936279297\n",
      "Best Params:  {'neurons_layer3': 16, 'neurons_layer2': 32, 'neurons_layer1': 128, 'epochs': 100, 'batch_size': 32}\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                            |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+==================================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network             | 0.000591086 |   0.606384 |   0.998837 |  0.784173 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Dense Neural Network (Optimized) | 2.24062e-05 |   0.532893 |   0.999956 |  0.81033  |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Dense Neural Network (Optimized) | 2.24062e-05 |   0.532893 |   0.999956 |  0.81033  |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank254_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('neural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "results_df.to_excel('254mT DENSEresults_hyper_tuned.xlsx', index=False)\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ad1fa-8f2d-4b61-a826-dc2d5cf82662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5baa8a-80f9-47fd-9705-51e3c0324ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ded1392-3b34-44f0-8ce8-2c5218e064c7",
   "metadata": {},
   "source": [
    "Gum Ingredient Addition - 22MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1228d9c-d0a3-44e8-b6f2-1299dc072911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2c3d2b-e866-4a84-91fb-8c3da5aedc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19268a8f-87e5-41cf-9209-ef912a4ead27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Material    BATCHID Tank_1             Instruction_Step  \\\n",
       "0           0   1002150  107643491   2503         S3_BATCH_IN_PROGRESS   \n",
       "1           1   1002150  107643491   2503                   STEP1_CONS   \n",
       "2           2   1002150  107643491   2503  PLEASE VERIFY BULK ADDITION   \n",
       "3           3   1002150  107643491   2503                   STEP1_CONS   \n",
       "4           4   1002150  107643491   2503                   STEP1_CONS   \n",
       "\n",
       "  INGRED_ID                           INGRED_Name  Quantity       Phase_start  \\\n",
       "0       NaN                                   NaN     0.000  09/03/2022 10:42   \n",
       "1   1002565                         WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2       NaN                                   NaN     0.000  09/03/2022 11:16   \n",
       "3   1037802  S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4   1002818  S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "\n",
       "          Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0  09/03/2022 10:42               0                  0             1   \n",
       "1  09/03/2022 11:16              34                  0             2   \n",
       "2  09/03/2022 11:17               1                  0             3   \n",
       "3  09/03/2022 11:27              10                  0             4   \n",
       "4  09/03/2022 11:38              11                  0             5   \n",
       "\n",
       "   Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0          0.0000              NaN                      0            NaN   \n",
       "1        169.4118         733.5050                      8           26.0   \n",
       "2          0.0000              NaN                      3            0.0   \n",
       "3          0.5629           6.3182                      1            9.0   \n",
       "4          7.1605           6.3182                     12            0.0   \n",
       "\n",
       "   Deaeration Phase  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd80668-682b-40be-b18d-f1608e4f7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84fea0-9933-4710-afe2-74215bad517d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f81c0db5-212c-4570-80d7-72a11fbfeca7",
   "metadata": {},
   "source": [
    "## Addition of GUM Ingredients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f916a3-039c-4ba1-ad64-1194e757e8d3",
   "metadata": {},
   "source": [
    "## Examining the Phase Overrun duration times for the GUM ingredient addition - Addition of GUM ingredients to the specific production tanks based on their capacity\n",
    " This is completed manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242496b0-06a8-4820-87eb-ebe595125362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "0    2202  107867810             467          436.0                  0   \n",
      "1    2202  107899926            1030          974.0                  0   \n",
      "2    2202  107956670              60            0.0                  0   \n",
      "3    2202  107964410              67           11.0                  0   \n",
      "4    2202  107978116              37            5.0                  0   \n",
      "5    2202  107993270              80           19.0                  1   \n",
      "6    2202  107999494             419          363.0                  0   \n",
      "7    2202  108026759              67           11.0                  0   \n",
      "8    2202  108033603              38            0.0                  1   \n",
      "9    2202  108045117             155          127.0                  0   \n",
      "10   2202  108073632             472          432.0                  0   \n",
      "11   2203  107887071              57           33.0                  0   \n",
      "12   2203  107933869             104           72.0                  0   \n",
      "13   2203  107971404              18            0.0                  0   \n",
      "14   2203  107978117              49            0.0                  0   \n",
      "15   2203  107999492             673          608.0                  0   \n",
      "16   2203  108015838              96           45.0                  0   \n",
      "17   2203  108030821             464          392.0                  0   \n",
      "18   2203  108033608              43           15.0                  0   \n",
      "19   2203  108042636             155           99.0                  0   \n",
      "20   2203  108051514              18            0.0                  0   \n",
      "21   2203  108059029              81           39.0                  0   \n",
      "22   2203  108067819             331          295.0                  0   \n",
      "23   2203  108073631              42            0.0                  0   \n",
      "24   2204  107848868             233          205.0                  0   \n",
      "25   2204  107862335             110           66.0                  0   \n",
      "26   2204  107872112             115           87.0                  0   \n",
      "27   2204  107899925            1150         1094.0                  0   \n",
      "28   2204  107907563             144           79.0                  0   \n",
      "29   2204  107915806              91           28.0                  0   \n",
      "30   2204  107925352              88           60.0                  0   \n",
      "31   2204  107964387             128          100.0                  0   \n",
      "32   2204  107969769              73           22.0                  0   \n",
      "33   2204  107978118              81           25.0                  0   \n",
      "34   2204  107992045             292          264.0                  0   \n",
      "35   2204  107999493             643          587.0                  0   \n",
      "36   2204  108015839             197          115.0                  0   \n",
      "37   2204  108026760             140           84.0                  0   \n",
      "38   2204  108042635              29            0.0                  0   \n",
      "39   2204  108075449             349          284.0                  0   \n",
      "40   2204  108084749              23            0.0                  0   \n",
      "41   2205  107964409             218          162.0                  0   \n",
      "42   2205  108084750              21            0.0                  0   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "0   1144.778         31.1201                   18.0         26.66825  \n",
      "1   3000.000          2.9126                   56.0         53.60000  \n",
      "2   3896.000        104.1778                   41.0         38.53335  \n",
      "3   3000.000         44.7761                   56.0         53.60000  \n",
      "4   1145.000         56.4248                   18.0         26.66825  \n",
      "5   3500.000         98.2143                   32.5         53.60000  \n",
      "6   3000.000          7.1599                   56.0         53.60000  \n",
      "7   3000.000         44.7761                   56.0         53.60000  \n",
      "8   3500.000        253.5714                   32.5         53.60000  \n",
      "9   1500.000          9.6774                   28.0         53.60000  \n",
      "10  2019.350         34.5295                   20.0         29.95910  \n",
      "11  2019.313         95.7746                   20.0         29.95910  \n",
      "12  1144.731         34.3259                   18.0         26.66825  \n",
      "13  1500.000         83.3333                   28.0         53.60000  \n",
      "14  3000.000         61.2245                   56.0         53.60000  \n",
      "15  3500.000         15.6496                   32.5         53.60000  \n",
      "16  2338.000         41.5697                   25.5         38.53335  \n",
      "17  3280.000         14.7880                   36.0         35.30000  \n",
      "18  1500.000         34.8837                   28.0         53.60000  \n",
      "19  3000.000         19.3548                   56.0         53.60000  \n",
      "20  3000.000        166.6667                   56.0         53.60000  \n",
      "21  1771.000         41.7452                   22.0         35.30000  \n",
      "22  1144.879          6.0580                   18.0         26.66825  \n",
      "23  3502.000        166.7500                   32.5         53.60000  \n",
      "24  1500.000          6.4378                   28.0         53.60000  \n",
      "25  1773.000         51.8428                   22.0         35.30000  \n",
      "26  1500.000         13.0435                   28.0         53.60000  \n",
      "27  3000.000          2.6087                   56.0         53.60000  \n",
      "28  3500.000         50.5853                   32.5         53.60000  \n",
      "29  1773.000         62.1696                   21.0         26.30940  \n",
      "30  1500.000         17.0455                   28.0         53.60000  \n",
      "31  1500.000         11.7188                   28.0         53.60000  \n",
      "32  2339.000         60.2727                   25.5         38.53335  \n",
      "33  3000.000         37.0370                   56.0         53.60000  \n",
      "34  1500.000          5.1370                   28.0         53.60000  \n",
      "35  3000.000          4.6656                   56.0         53.60000  \n",
      "36  3897.000         31.7801                   41.0         38.53335  \n",
      "37  3000.000         21.4286                   56.0         53.60000  \n",
      "38  3000.000        103.4483                   56.0         53.60000  \n",
      "39  3500.000         40.2247                   32.5         53.60000  \n",
      "40  2200.000        153.5714                   25.0         34.23750  \n",
      "41  3000.000         13.7615                   56.0         53.60000  \n",
      "42  1500.000         71.4286                   28.0         53.60000  \n"
     ]
    }
   ],
   "source": [
    "specific_tanks = ['2202', '2203', '2204','2205']\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['1461896', '1254972', '1031006','1243269','1196706','1815609']\n",
    "filtered_data = data[(data['INGRED_ID'].isin(desired_steps)) & (data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'Material','BATCHID'])['Phase_overrun'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Visualization using bar plots\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=total_durations, x='Tank_1', y='Phase_overrun',ci=None)\n",
    "plt.title('Total Phase_overrun for Each Tank by Phase')\n",
    "plt.ylabel('Phase_overrun')\n",
    "plt.xlabel('Tank')\n",
    "plt.legend(title='Phase_overrun')\n",
    "plt.show()\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df4 = filtered_data.groupby(['Tank_1','BATCHID']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    " #Print the aggregated DataFrame\n",
    "print(aggregated_total_durations_df4)\n",
    "\n",
    "aggregated_total_durations_df4.to_csv('GUMADD22MT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5294662-ab9a-453a-acc0-358889c963a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.079864e+08</td>\n",
       "      <td>212.744186</td>\n",
       "      <td>168.325581</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>2450.861651</td>\n",
       "      <td>51.806314</td>\n",
       "      <td>35.953488</td>\n",
       "      <td>46.231895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.679871e+04</td>\n",
       "      <td>258.691220</td>\n",
       "      <td>253.534324</td>\n",
       "      <td>0.213083</td>\n",
       "      <td>875.561170</td>\n",
       "      <td>53.131109</td>\n",
       "      <td>14.364231</td>\n",
       "      <td>10.597624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.078489e+08</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1144.731000</td>\n",
       "      <td>2.608700</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>26.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.079453e+08</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>14.274750</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>36.916675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.079933e+08</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>37.037000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>53.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.080381e+08</td>\n",
       "      <td>262.500000</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>61.697050</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>53.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.080848e+08</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3897.000000</td>\n",
       "      <td>253.571400</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>53.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
       "count  4.300000e+01       43.000000      43.000000          43.000000   \n",
       "mean   1.079864e+08      212.744186     168.325581           0.046512   \n",
       "std    6.679871e+04      258.691220     253.534324           0.213083   \n",
       "min    1.078489e+08       18.000000       0.000000           0.000000   \n",
       "25%    1.079453e+08       58.500000      11.000000           0.000000   \n",
       "50%    1.079933e+08      104.000000      66.000000           0.000000   \n",
       "75%    1.080381e+08      262.500000     234.500000           0.000000   \n",
       "max    1.080848e+08     1150.000000    1094.000000           1.000000   \n",
       "\n",
       "          Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
       "count    43.000000       43.000000              43.000000        43.000000  \n",
       "mean   2450.861651       51.806314              35.953488        46.231895  \n",
       "std     875.561170       53.131109              14.364231        10.597624  \n",
       "min    1144.731000        2.608700              18.000000        26.309400  \n",
       "25%    1500.000000       14.274750              25.500000        36.916675  \n",
       "50%    3000.000000       37.037000              32.500000        53.600000  \n",
       "75%    3000.000000       61.697050              56.000000        53.600000  \n",
       "max    3897.000000      253.571400              56.000000        53.600000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_total_durations_df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d98595-caf8-487b-94c7-82d4b1927b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "2    2202  107956670              60            0.0                  0   \n",
      "3    2202  107964410              67           11.0                  0   \n",
      "4    2202  107978116              37            5.0                  0   \n",
      "7    2202  108026759              67           11.0                  0   \n",
      "9    2202  108045117             155          127.0                  0   \n",
      "11   2203  107887071              57           33.0                  0   \n",
      "12   2203  107933869             104           72.0                  0   \n",
      "13   2203  107971404              18            0.0                  0   \n",
      "14   2203  107978117              49            0.0                  0   \n",
      "16   2203  108015838              96           45.0                  0   \n",
      "18   2203  108033608              43           15.0                  0   \n",
      "19   2203  108042636             155           99.0                  0   \n",
      "21   2203  108059029              81           39.0                  0   \n",
      "24   2204  107848868             233          205.0                  0   \n",
      "25   2204  107862335             110           66.0                  0   \n",
      "26   2204  107872112             115           87.0                  0   \n",
      "28   2204  107907563             144           79.0                  0   \n",
      "29   2204  107915806              91           28.0                  0   \n",
      "30   2204  107925352              88           60.0                  0   \n",
      "31   2204  107964387             128          100.0                  0   \n",
      "32   2204  107969769              73           22.0                  0   \n",
      "33   2204  107978118              81           25.0                  0   \n",
      "34   2204  107992045             292          264.0                  0   \n",
      "36   2204  108015839             197          115.0                  0   \n",
      "37   2204  108026760             140           84.0                  0   \n",
      "38   2204  108042635              29            0.0                  0   \n",
      "39   2204  108075449             349          284.0                  0   \n",
      "41   2205  107964409             218          162.0                  0   \n",
      "42   2205  108084750              21            0.0                  0   \n",
      "\n",
      "    Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "2   3896.000        104.1778                   41.0         38.53335  \n",
      "3   3000.000         44.7761                   56.0         53.60000  \n",
      "4   1145.000         56.4248                   18.0         26.66825  \n",
      "7   3000.000         44.7761                   56.0         53.60000  \n",
      "9   1500.000          9.6774                   28.0         53.60000  \n",
      "11  2019.313         95.7746                   20.0         29.95910  \n",
      "12  1144.731         34.3259                   18.0         26.66825  \n",
      "13  1500.000         83.3333                   28.0         53.60000  \n",
      "14  3000.000         61.2245                   56.0         53.60000  \n",
      "16  2338.000         41.5697                   25.5         38.53335  \n",
      "18  1500.000         34.8837                   28.0         53.60000  \n",
      "19  3000.000         19.3548                   56.0         53.60000  \n",
      "21  1771.000         41.7452                   22.0         35.30000  \n",
      "24  1500.000          6.4378                   28.0         53.60000  \n",
      "25  1773.000         51.8428                   22.0         35.30000  \n",
      "26  1500.000         13.0435                   28.0         53.60000  \n",
      "28  3500.000         50.5853                   32.5         53.60000  \n",
      "29  1773.000         62.1696                   21.0         26.30940  \n",
      "30  1500.000         17.0455                   28.0         53.60000  \n",
      "31  1500.000         11.7188                   28.0         53.60000  \n",
      "32  2339.000         60.2727                   25.5         38.53335  \n",
      "33  3000.000         37.0370                   56.0         53.60000  \n",
      "34  1500.000          5.1370                   28.0         53.60000  \n",
      "36  3897.000         31.7801                   41.0         38.53335  \n",
      "37  3000.000         21.4286                   56.0         53.60000  \n",
      "38  3000.000        103.4483                   56.0         53.60000  \n",
      "39  3500.000         40.2247                   32.5         53.60000  \n",
      "41  3000.000         13.7615                   56.0         53.60000  \n",
      "42  1500.000         71.4286                   28.0         53.60000  \n"
     ]
    }
   ],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank22_df = pd.DataFrame(aggregated_total_durations_df4)\n",
    "#ProductionTank22_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank22_df = remove_outliers_iqr(ProductionTank22_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b6140e-6e99-4269-b228-9eaecabf6b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tank_1    BATCHID  Phase_duration  Phase_overrun  Phase_start_delay  \\\n",
      "2   2202  107956670       -0.681389      -0.930040                0.0   \n",
      "3   2202  107964410       -0.592607      -0.784464                0.0   \n",
      "4   2202  107978116       -0.973100      -0.863869                0.0   \n",
      "7   2202  108026759       -0.592607      -0.784464                0.0   \n",
      "9   2202  108045117        0.523506       0.750695                0.0   \n",
      "\n",
      "   Quantity  Flowrate_KGMIN  Target_Phase_duration  Target_Flowrate  \n",
      "2    3896.0        2.166530               0.422965        -0.807147  \n",
      "3    3000.0        0.035992               1.505259         0.691842  \n",
      "4    1145.0        0.453791              -1.236552        -1.987611  \n",
      "7    3000.0        0.035992               1.505259         0.691842  \n",
      "9    1500.0       -1.222880              -0.515023         0.691842  \n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate']\n",
    "ProductionTank22_df[numerical_cols] = scaler.fit_transform(ProductionTank22_df[numerical_cols])\n",
    "print(ProductionTank22_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149bc04e-5114-4058-b652-4ca75a32b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.00617133  | 0.00215359 |  0.99275   |  0.99846  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.0117591   | 0.0274705  |  0.986186  |  0.980356 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.840205    | 1.67604    |  0.0129771 | -0.198528 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0483132   | 0.133439   |  0.943244  |  0.904579 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 3.71497e-07 | 0.29032    |  1         |  0.792394 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           | 0.0879797  |  1         |  0.937086 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0501103   | 0.163911   |  0.941133  |  0.882788 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.0083402   | 0.174617   |  0.990202  |  0.875132 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 2.1588e-30  | 0.0644125  |  1         |  0.953939 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Load your dataset (replace 'aggregated_ProductionTank2202_dfGUM' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22AGresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeddfb33-6178-4e63-8629-6999a8394dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.014568\n",
      "  Std MSE: 0.008945\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.027331\n",
      "  Std MSE: 0.015915\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.455116\n",
      "  Std MSE: 0.828159\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.219094\n",
      "  Std MSE: 0.282571\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.208430\n",
      "  Std MSE: 0.292249\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.268857\n",
      "  Std MSE: 0.878851\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 3964397172824.661621\n",
      "  Std MSE: 4141805187748.892090\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.539899\n",
      "  Std MSE: 0.530484\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.163482\n",
      "  Std MSE: 0.137985\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.205201\n",
      "  Std MSE: 0.243316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    \n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "    \n",
    " # Save the results to an Excel file\n",
    "df.to_excel(\"22AGresultsCVmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc2f726-8a20-4557-bd8f-3c68f9d34fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Model     Train MSE  Test MSE  Train R2   Test R2\n",
      "0            Linear Regression  8.984278e-03  0.006364  0.990075  0.994433\n",
      "1             Ridge Regression  8.984579e-03  0.006462  0.990075  0.994347\n",
      "2             Lasso Regression  9.501180e-03  0.003874  0.989504  0.996611\n",
      "3      Random Forest Regressor  3.531121e-02  0.120355  0.960993  0.894708\n",
      "4  Gradient Boosting Regressor  2.110126e-16  0.091605  1.000000  0.919860\n",
      "5      Decision Tree Regressor  0.000000e+00  0.212122  1.000000  0.814426\n",
      "6            Bagging Regressor  2.758628e-02  0.098313  0.969527  0.913991\n",
      "7           AdaBoost Regressor  6.457413e-03  0.190478  0.992867  0.833362\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.00898428  | 0.00636397 |   0.990075 |  0.994433 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.00898458  | 0.00646158 |   0.990075 |  0.994347 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.00950118  | 0.00387433 |   0.989504 |  0.996611 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0353112   | 0.120355   |   0.960993 |  0.894708 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 2.11013e-16 | 0.091605   |   1        |  0.91986  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           | 0.212122   |   1        |  0.814426 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0275863   | 0.0983133  |   0.969527 |  0.913991 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.00645741  | 0.190478   |   0.992867 |  0.833362 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and targetProductionTank22_df\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22AGresultsTUNED.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b39f1-63f0-49c2-9afa-096aac660f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "453ed0f7-c8a5-4aad-82a2-bcd72d90050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.13\n",
      "Mean Absolute Error (MAE): 0.27\n",
      "R-squared (R2): 0.89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Drop the target variable and split data\n",
    "# Define features and targetProductionTank22_df\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model\n",
    "model = SVR()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (For example, using Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2615c632-eb53-463b-9f89-ee1ffe721022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.01\n",
      "Mean Absolute Error (MAE): 0.09\n",
      "R-squared (R2): 0.99\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAGDCAYAAABwRoerAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+GklEQVR4nO3debyUc//H8ddH9q1y57ZVQllCWbJv9bPmpji2spU72+2HnxSi1Vp0lO12W0LhVpEQkpAtWVokbZTQor2UVp3O5/fH94rTcZapZuaamfN+Ph7zODPXXDPXpzOnep/vau6OiIiIiGSWzeIuQERERET+SiFNREREJAMppImIiIhkIIU0ERERkQykkCYiIiKSgRTSRERERDKQQpqIpJWZfWRmV0b3LzGzoRv5Pu+YWYvkVldxmFkXM3sxBe/b0syGJ/t9RSoihTSRLGBmx5vZCDNbYmaLzOwzMzvCzI42s+Vmtn0Jr/nazK43s1pm5ma2LLr9ZGbtyrmeR++7zMxmmVkPM6uU7D+Xu//X3U8r77ySAoW7N3b3PsmuKV2isLrYzLZK8Py0hB8z28PMCsxsnxKee83M8lNdg4gECmkiGc7MdgTeAh4FdgL2AO4EVrv7F8BM4PxirzkIqAv0LXK4irtvH53b0cxOLefS9aPzTwYuBq4qobbNN+oPVcGZWS3gBMCBJvFWsz53nwV8AFxW9LiZ7QScCWRtMBbJNgppIplvXwB37+vua919pbsPdfdx0fN9gMuLveZyYLC7Lyz+Zu4+CpgAHJLIxd19MvApcFCRVrlWZjYdGAZgZv80s0lRy9C7Zrbnuteb2almNjlqBXwMsCLPrdc6ZGYHmtl7UWvhXDO7w8zOAO4ALopa9r6Jzi3abbqZmXUws5/NbJ6ZPW9mlaPn1tXcwsymm9kCM2tf5JpHmtkoM1saXbNHSd+H6M93VpHHm5vZfDM7zMy2NrMXzWyhmf1qZiPNbJcyvq2XA18AvYH1umzNrIaZDYzee6GZPWZmBwBPAMdE34Nfi38PSvl+PmxmM6I/22gzO6GMmorqQ7GQBjQDJrr7t2bWzsx+MLPfzGyimZ1b0psU+d5vXuRY8ZpL/NmxoGf0eS41s2+jXz5EKgyFNJHM9z2w1sz6mFljM6ta7PkXgBPNrAaEwEJo+SqxxcPMjgYOAqYmcnEzq0to9fm6yOGTgAOA082sKSFE5QE7EwJd3+i11YCBQAegGvADcFwp19kBeB8YAuwO1AY+cPchwH1Af3ff3t3rl/DyltGtEbA3sD3wWLFzjgf2I7QMdoqCD8DDwMPuviOwD/ByKd+KvkDzIo9PBxa4+xhC0KoM1AD+BlwLrCzlfSCEtP9Gt9PXBToLXcpvAT8DtQitpv3cfVL0np9H34MqZbx3USMJYXwn4CXgFTPbOoHXvQZUM7Pjixy7jD9/pn4g/ExUJrTqvmhmuyVY0x/K+tkBTgNOJPySUhm4EPjLLx0iuUwhTSTDuftSQsBw4GlgvpkNWvcfu7vPAD7iz5aPk4GtgLeLvdUCM1sJfA48DrxezqXHmNli4E2gF/Bckee6uPtyd19JCA9d3X2SuxcQAtUhUYvImcAEdx/g7muAh4A5pVzvLGCOuz/o7qvc/Td3/7KcGte5BOjh7tPcfRlwO9CsWHfsnVEr5DfAN8C6sLcGqG1m1dx9WdSFXJKXgCZmtm30+GL+DBRrCOGsdtTaOTr63P4iCj57Ai+7+2hC4Lk4evpIQkC9Jfr+rnL3jR6H5u4vuvtCdy9w9wcJPxf7JfC6lcArRC20ZlYHOJzwPcDdX3H3X9y90N37A1Oi2jdUWT87a4AdgP0Bi86ZvRHXEMlaCmkiWSD6D6qlu1cntILtTgg86xTtnrqM0PqyptjbVCO0MLUBGgJblHPZw9y9qrvv4+4d3L2wyHMzitzfE3g46ub7FVhE6NLcI6rzj3Pd3Yu9tqgahMCyMXYntD6t8zOwOVC0y7FoOFxB+F4AtCK01kyOuinPogTuPhWYBJwdBbUmRKGF0Jr5LtDPzH4xswfMrLTvbwtgqLsviB6/xJ9dnjWAn6PAssnMrG3Ulbgk+mwqE34OEtEHuCBqebsMeNfd50Xve7mZjS3ymR+0Ae9bVKk/O+4+jNAa+m9gnpk9ZWF8pkiFoZAmkmWiMWK9Cf8xrjMQqG5mjQhdRyV2dUatPD2AVcB1m1JGkfszgGvcvUqR2zbuPgKYTQgeQBhnVPRxMTMIXZXlXa8kvxD+w1+nJlAAzC3ndbj7FHdvDvwduB8YYGbblXL6ui7PpoTxWVOj91jj7ne6e13gWEKrYPFxgpjZNoRuu5PMbI6ZzQFaA/XNrD7he1DTSp6QUdL3YDmwbZHHuxa51gnArdH1qkZdpEsoMiawHMMJoakpcCnRz1TUyvU0cD3wt+h9x5fyvsujryXWSNk/O7j7I+5+OGESzL7ALQnWLpITFNJEMpyZ7W9mbcysevS4BiEo/NEt5+7LgQGELsmfo8kBZekG3Jrg+KTyPAHcbmYHRvVVNrMLoufeBg40s7woeNzI+v9JF/UWsJuZ3WRmW5nZDmZ2VPTcXKBWNN6uJH2B1ma2l4XlSNaNYSu3RcrMLjWznaOWwl+jw4WlnN6PMFbqX/zZioaZNTKzg6MxZUsJXXUlvcc5wFpC6Dgkuh1AGIt1OfAVIdh2M7PtLExIWDeGby4hiG9Z5P3GAnlmtq2Z1Sa0Cq6zAyGozgc2N7NOQMItUVGr5/OE4FqF0O0NsB0hMM6P/uxXsP4vDEXfYz4wC7jUzCqZ2T8J4/7WKfVnx8ISM0dFLZLLCb9YlPa5iOQkhTSRzPcbcBTwpZktJ4Sz8YRuy6L6EFqTnk/gPd8GFlPCshobyt1fI/xH3s/Mlka1NY6eWwBcQAiFC4E6wGelvM9vwKnA2YSuySmEiQAQxkcBLDSzMSW8/FlCl+MnwI+E/9BvSPCPcAYwwcyWESYRNIvGZJVU42zCmL5jgf5FntqVEJKXErpEP47qKa4F8Jy7T3f3OetuhG69SwitUWcTJk1MJyyvclH02mGEWblzzGxdV2lP4HdCgOtDmIiwzruESRjfE7p/V1F6V3Npnie0SvZ399XR92Ai8GD0fZgLHEwpn2nkKkIL2ELgQGDEuifK+tkhBMqnCT+nP0ev776B9YtkNQu/LImIiIhIJlFLmoiIiEgGUkgTERERyUAKaSIiIiIZSCFNREREJAMppImIiIhkoJIWTMxq1apV81q1asVdhoiIiEi5Ro8evcDddy7puZwLabVq1WLUqPLW8RQRERGJn5n9XNpz6u4UERERyUAKaSIiIiIZSCFNREREJAMppImIiIhkIIU0ERERkQykkCYiIiKSgRTSRERERDKQQpqIiIhIBlJIExEREclACmkiIiIiGSjWkGZmz5rZPDMbX8rzDc1siZmNjW6d0l2jiIiISBzibknrDZxRzjmfuvsh0e2uNNQkIiIiFd3MmTBsWKwlxBrS3P0TYFGcNYiIiIj8Yfly5v6rC2v22peFTVpyV6cCxo2Lp5S4W9IScYyZfWNm75jZgXEXIyIiIjmosBBefJHf996PXZ64k2/3Ops+//yEhUs2Jz+fWILa5um/5AYZA+zp7svM7EzgdaBO8ZPM7GrgaoCaNWumtUARERHJcp9/DjfdBF99xYLdDueV8/ux+MDjAaganTJwINSrl96yMrolzd2Xuvuy6P5gYAszq1bCeU+5ewN3b7DzzjunvU4RERHJQtOnw8UXw7HHwowZ0Ls3HU//ioUHHL/eaZUrh1PTLaNDmpntamYW3T+SUO/CeKsSERGRrLZsGXTsCPvtB6+9Fu5//z20aEGNPTdjyZL1T1+yBOLoqIu1u9PM+gINgWpmNhPoDGwB4O5PAOcD/zKzAmAl0MzdPaZyRUREJJsVFsILL8Dtt8Ps2dC8OXTrtl4Cy8uD/Pxwv3LlENAWL4ZWrdJfruVa5mnQoIGPGjUq7jJEREQkkwwfHsadjR4NRx4JDz0ExxxT4qnjxoUxaNOnh/yWl5e68WhmNtrdG5T0XKZPHBARERHZeD/+CLfdBq+8AnvsAS++GFrQNit9xFe9eumfJFAShTQRERHJPb/9Bl27Qo8eIZB16QJt28J228VdWcIU0kRERCR3rF0LvXtD+/Ywdy5cemkIa9Wrx13ZBlNIExERkdzw8cdh3NnYsWG82aBBYfxZlsroJThEREREyjVtGpx3HjRsCAsXQt++8NlnWR3QQCFNREREstXSpWFSwAEHwJAhcPfd8N130KwZhGVWs5q6O0VERCS7rF0Lzz4LHTrAvHnQogXcdx/svnvclSWVQpqIiIhkj2HDoHXrsJjZ8cfD229DgxKXGct66u4UERGRzDdlCpxzDpx8ctgG4OWX4ZNPcjaggUKaiIiIZLJffw3rmx14IHzwQVhOY/JkuOCCnBh3VhZ1d4qIiEjmKSiAp5+GTp3CjM1//hPuuQd23TXuytJGLWkiIiKSWd57Dw45BK67LrSgjR4NvXpVqIAGCmkiIiKSKb77Ds4+G047DVasgFdfhQ8/hEMPjbuyWCikiYiISLwWLQo7BRx0UNg14IEHYNIkyMvL+XFnZdGYNBEREYnHmjXw5JPQuXOYIHDllXDXXbDLLnFXlhHUkiYiIiLpN2QI1K8PN9wQxp+NGRMCmwLaHxTSREREJH0mTYIzz4TGjUNL2htvwPvvh8Am61FIExERkdRbuDC0mh18MIwYAQ8+CBMmQJMmFXrcWVk0Jk1ERERSZ80aePxx6NIlbIh+zTVw552w885xV5bxFNJEREQk+dxh8GBo0yYsrXHqqdCjR5jBKQlRd6eIiIgk1/jxcPrpcNZZIay99Ra8+64C2gZSSBMREZHkmD8/7BJQvz6MHAkPPRQC2z/+oXFnG0HdnSIiIrJpfv8dHnssrHG2bFkIal26wN/+FndlWU0hTURERDaOOwwaBG3bwtSpYVmN/HyoWzfuynKCujtFRERkw40bB6ecAuecA1tsESYJDB6sgJZECmkiIiKSuHnzwjIahx4KY8fCo4/CN9+EVjRJKnV3ioiISPlWr4ZHHoG774aVK+HGG6FTJ6haNe7KcpZCmoiIiJTOHV57DW65BaZNC8tq5OfDfvvFXVnOU3eniIiIlOzrr6FRIzjvPNhmm7DW2ZtvKqCliUKaiIiIrG/OHLjySjj88LC/5n/+E8afnXZa3JVVKOruFBERkWDVKujZE+67L4xBu/lm6NABqlSJu7IKSSFNRESkonOHAQPg1lvhp5+gaVPo3h3q1Im7sgpN3Z0iIiIV2ejRcOKJcOGFsMMO8P778PrrCmgZQCFNRESkIvrlF2jZEho0gO++gyefDBMFTj457sokou5OERGRimTlSnjwQejWDdasCV2cd9wBlSvHXZkUo5AmIiJSEbhD//5w220wfTrk5cEDD8A++8RdmZRC3Z0iIiK57quv4LjjoHlz2Gkn+OgjePVVBbQMp5AmIiKSq2bOhMsug6OOCrsFPPMMjBoFJ50Ud2WSAHV3ioiI5JoVK8ISGvffD4WFcPvt4bbDDnFXJhtAIU1ERCRXFBZC377Qrl1oRbvwwhDUatWKuzLZCOruFBERyQWffw7HHguXXgq77AKffBImCiigZS2FNBERkWw2fTpcfHEIaNOnQ+/eYaLACSfEXZlsInV3ioiIZKNly8ISGt27h8cdOoTlNbbfPt66JGkU0kRERLJJYSG88EKYCDB7dlhWo1s3qFkz7sokydTdKSIiki2GDw/LabRsCTVqwGefwUsvKaDlKIU0ERGRTPfTT3DRRWGc2ezZoSVt3UQByVnq7hQREclUv/0WujIffBA22wy6dIG2bWG77eKuTNIg1pBmZs8CZwHz3P2gEp434GHgTGAF0NLdx6S3ShERkTRbuxb69IH27WHOnLCsRteuUL0648bBwIFhImfNmmELznr14i5YUiHu7s7ewBllPN8YqBPdrgb+k4aaRERE4vPxx3DEEdCqVVjj7IsvQvdmFNDy82HxYqhePXzNz4dx4+IuWlIh1pDm7p8Ai8o4pSnwvAdfAFXMbLf0VCciIpJG06bB+edDw4awYEHYOWDEiDBRIDJwIFStGm6bbfbn/YED4ytbUifulrTy7AHMKPJ4ZnRMREQkNyxdGtY3O+AAeOcduPtumDwZmjUDs/VOnT4dKlde/+WVK4fjkntyYuKAmV1N6A6lpqYhi4hINli7Fp59NixCO28etGgB990Hu+9e6ktq1gxdnFWr/nlsyRKtwJGrMr0lbRZQo8jj6tGx9bj7U+7ewN0b7LzzzmkrTkREZKMMGwaHHQZXXw377gsjR4btnMoIaBAmCSxeHG6FhX/ez8tLT9mSXpke0gYBl1twNLDE3WfHXZSIiMhGmTIFzjkHTj45NIG9/HLYCL1Bg4ReXq9eWIGjalWYOTN8bdtWsztzVdxLcPQFGgLVzGwm0BnYAsDdnwAGE5bfmEpYguOKeCoVERHZBL/+CvfcA488AlttFbo1W7eGrbfe4LeqV0+hrKKINaS5e/Nynnfgf9NUjoiISHIVFECvXtCxIyxcCFdcEcLablqoQMqX6d2dIiIi2em99+DQQ+Ff/4K6dWH0aHjmGQU0SZhCmoiISDJ99x2cfTacdhosXw6vvgoffRQCm8gGUEgTERFJhsWLwzizgw4Kuwbcfz9MmhSmXhZb70wkETmxTpqIiEhsCgrgySehU6cQ1K66Cu66C3bZJe7KJMupJU1ERGRjDRkC9evD9deHr19/HQKbApokgUKaiIjIhpo0Cc48Exo3htWr4fXX4YMPQlATSRKFNBERkUQtXAg33ggHHxw2P8/PhwkToGlTjTuTpNOYNBERkfKsWQOPPw533hl2CrjmmnBfWxFKCimkiYiIlMYdBg+GNm3C0hqnnAI9e4YZnCIppu5OERGRkkyYAGecAWedFcLam2/C0KEKaJI2CmkiIiJFLVgA//u/YYPMr76Chx6Cb78NYU3jziSN1N0pIiIC8Pvv8NhjYY2zZcvguuugSxf429/irkwqKIU0ERGp2NZ1ZbZpA1Onhi7OBx8M+22KxEjdnSIiUnGNGwennhqW0Nh88zBJ4J13FNAkIyikiYhIxTNvXlhG49BDwy4Bjz4aAlvjxnFXJvIHdXeKiEjFsXo1PPII3HMPrFgBN9wQ9tzcaae4KxP5C4U0ERHJfe5h66a2bWHatDBTMz8f9tsv7spESqXuThERyW1ffw2NGkFeHmyzDbz7bpgooIAmGU4hTUREctOcOXDllXD44TB+fNjWaexYOO20uCsTSYi6O0VEJLesWhUWoL333jAGrXVr6NgRqlSJuzKRDaKQJiIiucEdXn0VbrkFfvopLKvRvTvUqRN3ZSIbRd2dIiKS/UaPhpNOggsugB12gPffDxMFFNAkiymkiYhI9vrlF7jiCjjiCJg8GZ58MkwUOPnkuCsT2WTq7hQRkeyzciX06AFdu8KaNaGL8447oHLluCsTSRqFNBERyR7u0L8/3HYbTJ8eltV44AHYZ5+4KxNJOnV3iohIdvjqKzj+eGjePOwQ8OGHYaKAAprkKIU0ERHJbDNnwuWXw1FHwQ8/QK9eMGoUNGwYd2UiKaXuThERyUwrVoQlNB54ANauhdtvD7cddoi7MpG0UEgTEZHMUlgIfftCu3ahFe2CC+D++2GvveKuTCSt1N0pIiKZ44sv4Nhj4dJLYZdd4JNP4OWXFdCkQlJIExGR+M2YAZdcAsccE2Zt9u4dJgqccELclYnERt2dIiISn2XLwpiz/PywvEaHDmF5je23j7sykdgppImISPoVFsKLL4aJAL/8As2aQbdusOeecVcmkjHU3SkiIun12WdhOY0WLaB69fC4b18FNJFiFNJERCQ9fvoJLrooLEg7eza88AJ8/nmYKCAif6HuThERSa3ffgtdmQ8+CJttBp07h702t9su7spEMppCmoiIpEZhIfTpEzY+nzMnzN7s2hVq1Ii7MpGsoJAmIiLJ98kn0Lo1jBkDRx8Nr78exqGJSMI0Jk1ERJJn2jQ4/3w46SSYPx9eeglGjFBAE9kIakkTEZFNt3Qp3Hcf9OwJm28Od98NN98M224bd2UiWUshTURENt7atfDcc9C+PcybF5bVuPde2GOPuCsTyXoKaSIisnE+/DCMO/vmGzjuOHjrLTjiiLirEskZCmkiIvKHceNg4MCwfWbNmpCXB/XqFTtp6tSwhMbrr4cFaPv3hwsuALM4ShbJWZo4ICIiQAho+fmweHHYCGDx4vB43LjohCVLQjirWxfefz+MQZs0CS68UAFNJAXUkiYiIkBoQataNdzgz6+vDyig3ohe0KkTLFgAV1wB99wDu+0WX7EiFYBCmoiIAKGLs3r19Y8duvB9Tnm+Nfw6Hk48MczePOyweAoUqWDKDWlmtg8w091Xm1lDoB7wvLv/mtrSREQknWrWDF2cVavC3xZ+z2lD27Lf92+yuMpeMGBAGKCmbk2RtElkTNqrwFozqw08BdQAXkrGxc3sDDP7zsymmlm7Ep5vaWbzzWxsdLsyGdcVEZG/ysuD1XMWc9IbN3Pd4wey548f0e+w+5k5dCKcd54CmkiaJdLdWejuBWZ2LvCouz9qZl9v6oXNrBLwb+BUYCYw0swGufvEYqf2d/frN/V6IiJShoIC6n36JI8N7UylXxfxyb5X8tXZd3P65btwcPHZnSKSFomEtDVm1hxoAZwdHdsiCdc+Epjq7tMAzKwf0BQoHtJERCSV3n037A4wcSKbN2oEPXtyUv36nBR3XSIVXCLdnVcAxwD3uvuPZrYX8EISrr0HMKPI45nRseLOM7NxZjbAzGok4boiIgIweTL84x9wxhmwenVY9+yDD6B+/bgrExESCGlR9+NtwJjo8Y/ufn+qC4u8CdRy93rAe0Cfkk4ys6vNbJSZjZo/f36aShMRyVKLFsH//R8cdBAMHx4WQ5swAZo21bgzkQxSbkgzs7OBscCQ6PEhZjYoCdeeRZiEsE716Ngf3H2hu6+OHvYCDi/pjdz9KXdv4O4Ndt555ySUJiKSg9asgUcegdq14bHH4Kqrwu4BbdrAVlvFXZ2IFJNId2cXwvixXwHcfSywdxKuPRKoY2Z7mdmWQDNgvfBnZkVXSmwCTErCdUVEKhZ3GDwYDj44tKAdfjiMHQv/+Q/oF1uRjJVISFvj7kuKHSvc1Au7ewFwPfAuIXy97O4TzOwuM2sSnXajmU0ws2+AG4GWm3pdEZEKZcIEaNw4jD1zhzffhKFDQ2ATkYyWyOzOCWZ2MVDJzOoQwtKIZFzc3QcDg4sd61Tk/u3A7cm4lohIhbJgAXTuDE8+CTvsEHYKuO462HLLuCsTkQQl0pJ2A3AgsBroCywFbkphTSIisrF+/z0Estq1Q0C79lqYMgVuukkBTSTLlNuS5u4rgPbRTUREMpE7vPVWmAQwZQqcfjr06AF168ZdmYhspET27vwQ8OLH3f1/UlKRiIhsmG+/hdatwxpn++8fJgk0bhx3VSKyiRIZk9a2yP2tgfOAgtSUIyIiCZs3Dzp1gqefhipV4NFH4ZprYItkbAojInFLpLtzdLFDn5nZVymqR0REyrN6dQhkd98NK1bADTeEsLbTTnFXJiJJlEh3Z9G/9ZsRFpStnLKKRESkZO7wxhvQti388ENYViM/P3RxikjOSaS7czRhTJoRujl/BFqlsigRESlm7Ngw7uyjj8JkgCFDwuQAEclZiXR37pWOQkREpARz50KHDvDMM6E78/HHw3ZOmyfyO7aIZLNS/5abWV5ZL3T3gckvR0REAFi1Ch56CO67D1auDK1oHTuGCQIiUiGU9avY2WU854BCmohIsrnDq6/CLbfATz9BkybQvTvsu2/clYlImpUa0tz9inQWIiJS4Y0ZE3YG+PTTsLfm++/DySfHXZWIxCShQQ1m9g/C1lBbrzvm7nelqigRkQpl9mxo3x5694Zq1cJ2Tq1aQaVKcVcmIjFKZAmOJ4BtgUZAL+B8QOukiYhsqpUrw9ZNXbuGPTfbtg1hrbJWORKRxDZYP9bdLwcWu/udwDGABkeIiGwsd+jfP6xv1qFDWEpj0iR44AEFNBH5QyIhbWX0dYWZ7Q6sAXZLXUkiIjls5Eg4/nho1iwsqfHhh2GiwD77xF2ZiGSYRELaW2ZWBegOjAF+Al5KYU0iIrln1ixo0QKOPDLsFtCrF4waBQ0bxl2ZiGSostZJG0wIYz3dfRnwqpm9BWzt7kvSVaCISFZbsSJs3XT//VBQAO3awe23w447xl2ZiGS4slrSngT+AUwzs5fN7FzAFdBERBLgDi+9BPvtB507h302J08OkwQU0EQkAaWGNHd/w92bA7WAV4HLgelm9pyZnZqm+kREss8XX8Cxx8Ill8Df/w6ffAIvvwx7aZc9EUlcuWPS3H2Fu/d393OB04BDgCGpLkxEJOvMmBGC2THHwM8/w3PPhYkCJ5wQd2UikoUSWSdtF+BCoBlhVufLQMvUliUikkWWLw/LZ3TvHro5O3SA226D7bePuzIRyWJlTRy4CmgO7Efo7rzF3UekqzARkYxXWAj//W+YDPDLL2FZjW7dYM89465MRHJAWS1pxwBdgQ/cvTBN9YiIZIcRI8I+myNHwhFHhDFnxx0Xd1UikkPK2mD9n+ksREQkK/z8c+jK7N8f9tgDXngBLr4YNktk2UkRkcQltMG6iEiFt2xZ6MrMzw+BrHNnuOUW2G67uCsTkRylkCYiUpbCQnj++bAA7Zw5YfZm165Qo0bclYlIjitr4sBOZb3Q3RclvxwRkQzyySfQujWMGQNHHQWvvQZHHx13VSJSQZTVkjYacMCAmsDi6H4VYDqgVRlFJDf9+CPceisMGBBazP77X2jeHMzirkxEKpCydhzYy933Bt4Hznb3au7+N+AsYGi6ChQRSZulS8NyGvvvD4MHw113ha2cLr5YAU1E0i6R6UhHu/vgdQ/c/R3g2NSVJCKSZmvXQq9eUKdO2Ai9WTP4/nvo2BG23Tbu6kSkgkpk4sAvZtYBeDF6fAnwS+pKEhFJo48+CuudffNNWOfsrbfCumciIjFLpCWtObAz8BowMLrfPJVFiYik3A8/QF4eNGoEv/4a1j379FMFNBHJGOW2pEWzOP/PzLZz9+VpqElEJHWWLIF774WHHoIttwz3W7eGbbaJuzIRkfWU25JmZsea2URgUvS4vpk9nvLKRESSqaAAnnwyjDvLz4fLLoMpU+COOxTQRCQjJdLd2RM4HVgI4O7fACemsigRkaT64AM47DC49lo44AAYNQqeeQZ22y3uykRESpXQZnPuPqPYobUpqEVEJLmmTIGmTeGUU8K2TgMGhIkChx0Wd2UiIuVKJKTNMLNjATezLcysLVHXp4hIRlq8GG6+GQ48ED78MOy5OXEinHee1jsTkayRyBIc1wIPA3sAswgL2V6XyqJERDZKQQE89RR06gSLFsGVV8Ldd8Muu8RdmYjIBkskpO3n7pcUPWBmxwGfpaYkEZGN8O67ofVs4kRo2BB69oRDDom7KhGRjZZId+ejCR4TEUm/yZPhH/+AM86A1avDJujDhimgiUjWK7UlzcyOIWz/tLOZ3VzkqR2BSqkuTESkTIsWwZ13wuOPh62b8vPh+uthq63irkxEJCnK6u7cEtg+OmeHIseXAuensigRkVKtWQNPPAGdO4eFaa++OoS1v/897spERJKq1JDm7h8DH5tZb3f/OY01iYiU7J13wrizyZPDsho9esDBB8ddlYhISiQyJq2XmVVZ98DMqprZu6krSUSkmAkTwpizM8+EtWvhzTdh6FAFNBHJaYmEtGru/uu6B+6+GFC/goik3oIFYZxZ/frw5Zdhxub48XDWWVrvTERyXiIhrdDMaq57YGZ7Ap66kkSkwvv997ABep06YfzZtdeG3QNuuilsii4iUgEksk5ae2C4mX0MGHACcHVKqxKRiskd3noL2rQJoez008O4s7p1465MRCTtym1Jc/chwGFAf6AfcLi7J2VMmpmdYWbfmdlUM2tXwvNbmVn/6PkvzaxWMq4rIhno22/htNOgSROoVAkGD4YhQxTQRKTCKjWkmdn+0dfDgJrAL9GtZnRsk5hZJeDfQGOgLtDczIr/a9wKWOzutYGewP2bel0RyTDz58O//hUWnx09Gh55BMaNg8aN465MRCRWZXV3tgGuAh4s4TkH/mcTr30kMNXdpwGYWT+gKTCxyDlNgS7R/QHAY2Zm7q4xcSLZbvVqePTRsLfmihVhgkDnzrDTTnFXJiKSEcpaJ+2q6GujFF17D2BGkcczgaNKO8fdC8xsCfA3YEHRk8zsaqJxcjVr1kREMpg7vPEGtG0LP/wQtnTKz4f994+7MhGRjFLWtlB5Zb3Q3Qcmv5yN4+5PAU8BNGjQQK1sIpnqm2+gdWv48MMw1mzIkDA5QERE/qKs7s6zo69/J+zhOSx63AgYAWxqSJsF1CjyuHp0rKRzZprZ5kBlYOEmXldE0m3uXOjYEXr1Ct2Z//532M5p80QmmIuIVExldXdeAWBmQ4G67j47erwb0DsJ1x4J1DGzvQhhrBlwcbFzBgEtgM8J+4UO03g0kSyyahU8/DDcey+sXBla0Tp0gKpV465MRCTjJfJrbI11AS0ylzDbc5NEY8yuB94FKgHPuvsEM7sLGOXug4BngBfMbCqwiBDkRCTTucPAgXDLLfDjj2FZje7dYd99465MRCRrJBLSPoj26uwbPb4IeD8ZF3f3wcDgYsc6Fbm/CrggGdcSkTQZMya0mH3yCRx0ELz3XtgMXURENki5Ic3drzezc4ETo0NPuftrqS1LRLLO7NnQvj307g3VqoXtnFq10rgzEZGNlOi/nmOA39z9fTPb1sx2cPffUlmYiGSJlSvDxuf33Rf23GzbNoS1ypXjrkxEJKuVuy2UmV1FWEj2yejQHsDrKaxJRLKBO/TvDwccEELZaafBxInwwAMKaCIiSVBuSAP+FzgOWArg7lMIy3KISEU1ciSccAI0awZVqsCwYWGiQO3acVcmIpIzEglpq93993UPovXKtAyGSEU0axa0aAFHHglTpoR1z0aPhkap2phERKTiSmRM2sdmdgewjZmdClwHvJnaskQko6xYAQ8+CN26QUEBtGsHt98OO+4Yd2UiIjkrkZB2G3Al8C1wDWHJjF6pLEpEMoQ79OsHt90GM2bA+eeHMWd77RV3ZSIiOa/MkGZmlYAJ7r4/8HR6ShKRjPDFF2G9sy++gMMOgxdfhBNPLP91IiKSFGWOSXP3tcB3ZrbJOwyISJaYMQMuvRSOOQZ++gmeey5MFFBAExFJq0S6O6sCE8zsK2D5uoPu3iRlVYlI+i1fHrZueuABKCwMy2q0awfbbx93ZSIiFVIiIa1jyqsQkfgUFsJ//xsmAsyaBRddBPffD3vuGXdlIiIVWqkhzcy2Bq4FahMmDTzj7gXpKkxE0mDECLjpptCdecQRYXHa446LuyoREaHsMWl9gAaEgNYYeDAtFYlI6v38MzRvHgLZrFnw/PNhgoACmohIxiiru7Ouux8MYGbPAF+lpyQRSZlly8JaZw8+CGbQqRPceitst13clYmISDFlhbQ16+64e4GZpaEcEUmJwsLQWnbHHTB7NlxyCXTtCjVqxF2ZiIiUoqyQVt/Mlkb3jbDjwNLovru7lhoXyQaffhrWOxs9Go46KuyxefTRcVclIiLlKDWkuXuldBYiIkn2449hp4BXXoHq1cMMzubNQzeniIhkvESW4BCRbLJ0aejK7NkTKlWCu+6CNm1g223jrkxERDaAQppIrli7Fnr3DovQzp0Ll18O990He+wRd2UiIrIRFNJEcsFHH4VxZ2PHwrHHwptvhnXPREQka5W5d6eIZLgffoC8PGjUCBYvhn79YPhwBTQRkRygkCaSjZYsCeub1a0LQ4fCvffCpElhSydNDBARyQnq7hTJJmvXQq9e0LEjLFgALVuGgLbbbnFXJiIiSaaWNJFs8cEHcOihcO21sP/+MGoUPPusApqISI5SSBPJdFOmQNOmcMop8NtvMGAAfPwxHHZY3JWJiEgKKaSJZKpffw3rmx14IHz4Ydhzc9IkOO88jTsTEakANCZNJNMUFMDTT4dxZ4sWQatWcPfdsOuucVcmIiJppJY0kUwydCgccghcdx0cfDCMGRMCmwKaiEiFo5AmkgkmT4azzoLTT4dVq+C112DYsBDYRESkQlJIE4nTokVw002h1ezTT6F7d5gwAc45R+POREQqOI1JE4nDmjXwxBPQpUuYIHDVVWEj9L//Pe7KREQkQ6glTSTd3nkH6tWDG28M656NHRsCmwKaiIgUoZAmki4TJ0LjxnDmmWHngEGD4L33QleniIhIMQppIqm2YAFcf31oPfviC+jZE8aPh7PP1rgzEREplcakiaTK77/D44/DnXeGnQKuvTaMQatWLe7KREQkCyikiSSbO7z9dtgt4Pvv4bTToEePsHOAiIhIgtTdKZJM48eHtc7WdWW+/TYMGaKAJiIiG0whTSQZ5s+Hf/0L6teHUaPgkUfg22/DJAGNOxMRkY2g7k6RTfH77/Doo2GNs+XLwwSBzp1hp53irkxERLKcQprIxnAPS2i0bQtTp4YWs/x8OOCAuCsTEZEcoe5OkQ31zTdw8slh66Yttwxjzt5+WwFNRESSSiFNJFFz58LVV4ddAsaNg3//OwS200+PuzIREclB6u4UKc/q1fDww3DPPbByZdgQvWNHqFo17spERCSHKaSJlMYdBg6EW26BH3+EJk2ge3fYd9+4KxMRkQpA3Z0iJfn6a2jYEM4/H7bbLuyx+cYbCmgiIpI2CmkiRc2eDa1aweGHhw3Rn3giBLZTTom7MhERqWDU3SkCsGpV2Pj8vvvCGLQ2baBDB6hcOe7KRESkgoolpJnZTkB/oBbwE3Chuy8u4by1wLfRw+nu3iRdNUoF4Q6vvAK33go//wznngsPPAC1a8ddmYiIVHBxdXe2Az5w9zrAB9Hjkqx090OimwKaJNeoUXDCCXDRRVClCgwbFiYKKKCJiEgGiCukNQX6RPf7AOfEVIdURL/8Ai1bwhFHwJQp8PTTMHo0NGoUd2UiIiJ/iCuk7eLus6P7c4BdSjlvazMbZWZfmNk5pb2ZmV0dnTdq/vz5ya5VcsWKFXD33VCnDvTtC7fdFkLalVdCpUpxVyciIrKelI1JM7P3gV1LeKp90Qfu7mbmpbzNnu4+y8z2BoaZ2bfu/kPxk9z9KeApgAYNGpT2XlJRuUO/fiGUzZgRltW4/37Ye++4KxMRESlVykKau5e6ZoGZzTWz3dx9tpntBswr5T1mRV+nmdlHwKHAX0KaSKm+/BJat4bPPw/bOb34Ipx4YtxViYiIlCuu7s5BQIvofgvgjeInmFlVM9squl8NOA6YmLYKJbvNmAGXXgpHHx12C3juuTBRQAFNRESyRFwhrRtwqplNAU6JHmNmDcysV3TOAcAoM/sG+BDo5u4KaVK25cuhSxfYbz8YMADat4fvvw8TBTbT2s0iIpI9Ylknzd0XAieXcHwUcGV0fwRwcJpLk2xVWAgvvQTt2sGsWWFZjfvvhz33jLsyERGRjaKmBcl+n38OxxwDl10Gu+0Gw4eHiQIKaCIiksUU0iR7/fwzNG8Oxx4LM2dCnz5hosBxx8VdmYiIyCbT3p2SfZYtC12Z+fnhcadOYVun7baLty4REZEkUkiT7FFYCC+8ALffDrNnw8UXQ9euULNm3JWJiIgknUKaZIfhw+Gmm8L2TUcdFfbYPProuKsSERFJGY1Jk8z2449w4YVhI/S5c+G//4URIxTQREQk56klTTLTb7+FrswePcK+mnfeCW3bwrbbbvBbjRsXGt6mTw89o3l5UK9eCmoWERFJIrWkSWZZuxaeeSZsgt61a1jv7Pvvw+SAjQxo+fmweDFUrx6+5ueH4yIiIplMIU0yx8cfQ4MGcOWVsM8+YTmNPn1gjz02+i0HDoSqVcNts83+vD9wYBLrFhERSQGFNInfDz/AeedBw4awaFFYiHb4cDjyyE1+6+nToXLl9Y9VrhyOi4iIZDKFNInP0qVw221Qty68+y7ccw9Mnhy6OM2ScomaNWHJkvWPLVmiVTtERCTzKaRJ+q1dC089BbVrQ/fucMklYdxZ+/awzTZJvVReXhiHtnhxWGZt3f28vKReRkREJOkU0iS9hg2Dww6Da66B/feHkSPh2Wdh991Tcrl69cKk0KpVw85RVauGx5rdKSIimU5LcEh6TJkCt9wCb7wBtWrBK6+EcWhJ6tYsS716CmUiIpJ91JImqfXrr9CmDRx4IHzwAXTrBpMmwfnnpyWgiYiIZCu1pElqFBTA00+H9c0WLoRWreDuu2HXXeOuTEREJCuoJU2Sb+hQOOQQuO46OOggGDMmBDYFNBERkYQppEnyfPcdnHUWnH46rFoFr70WJgocckjclYmIiGQdhTTZdIsWwU03hVazTz8Ny2pMmADnnKNxZyIiIhtJY9Jk461ZA08+CZ07hwkCV10Fd90Ff/973JWJiIhkPbWkycYZMgTq14cbboBDD4Wvv4YnnlBAExERSRKFNNkwEydC48bhVlAQ1j177z0tRCYiIpJkCmmSmIULQ6tZvXrw+efQoweMHw9NmmjcmYiISApoTJqUbc0aePxx6NIFfvstbOd0551QrVrclYmIiOQ0hTQpmTu8/XbY6PK77+C000Lr2YEHxl2ZiIhIhaDuTvmr8ePDWmdnnx0ev/12mCiggCYiIpI2Cmnyp/nzwy4B9evDqFHw8MPw7bdw5pkadyYiIpJm6u4U+P13ePTRsLfmsmVw/fVh7bOddoq7MhERkQpLIa0ic4dBg8K4s6lTQ4tZfj4ccEDclYmIiFR46u6sqMaNg1NOCVs3bbEFvPNOGHumgCYiIpIRFNIqmnnzwjIahx4K33wDjz0WAtsZZ8RdmYiIiBSh7s6KYvXqMBHgnntg5Ur4v/+Djh2hatW4KxMREZESKKTlOnd47TW45RaYNi0sq5GfD/vuG3dlIiIiUgZ1d+ayr7+GRo3gvPNg221h6NAwUUABTUREJOMppOWiOXOgVSs4/HCYMAGeeCIEtlNPjbsyERERSZC6O3PJqlXQsyfcd18Yg9amDbRvD1WqxF2ZiIiIbCCFtFzgDgMGwK23wk8/hWU1uneH2rXjrkxEREQ2kro7s92oUXDiiXDhhVC5MgwbFiYKKKCJiIhkNYW0bPXLL9CyJRxxBHz/PTz9NIweHSYKiIiISNZTd+cGGjcOBg6E6dOhZk3Iy4N69dJYwMqV8OCD0K0brFkDt90Gd9wBO+6YxiJEREQk1dSStgHGjQtLjC1eDNWrh6/5+eF4yrlDv36w335hEdrGjWHSpBDWFNBERERyjkLaBhg4MCzQX7UqbLbZn/cHDkzxhb/8Eo47Dpo3h2rV4OOP4ZVXYO+9U3xhERERiYtC2gaYPj2MzS+qcuVwPCVmzoTLLoOjj4Yff4Rnn4WRI8NEAREREclpCmkboGZNWLJk/WNLloTjSbViBdx5Z9gZ4JVXwpiz77+HK66ASpWSfDERERHJRAppGyAvL4xDW7wYCgv/vJ+Xl6QLFBbCiy+GcWddukCTJjB5Mtx7L+ywQ5IuIiIiItlAIW0D1KsHbduGcWgzZ4avbdsmaXbn55/DMceE7s1dd4VPPw0TBWrVSsKbi4iISLbREhwbqF69JC+5MX06tGsHffvC7rtDnz5w6aVhZoKIiIhUWLEkATO7wMwmmFmhmTUo47wzzOw7M5tqZu3SWWPKLVsWltLYb7+wQ0DHjvDdd3D55QpoIiIiEltL2nggD3iytBPMrBLwb+BUYCYw0swGufvE9JSYIoWF8MILcPvtMHs2XHwxdO2agtkHIiIiks1iCWnuPgnAzMo67UhgqrtPi87tBzQFsjekDR8OrVuH/TaPOgpefTWMQxMREREpJpP71fYAZhR5PDM69hdmdrWZjTKzUfPnz09LcRvkp5/goovghBNgzpwwg3PECAU0ERERKVXKWtLM7H1g1xKeau/ubyTzWu7+FPAUQIMGDTyZ771JfvstdGX26BHWN7vzzjAddNtt465MREREMlzKQpq7n7KJbzELqFHkcfXoWOZbuzbM0rzjDpg7Nyyrcd99YcNPERERkQRkcnfnSKCOme1lZlsCzYBBMddUvo8/hiOOgFatwt6aX34Jzz+vgCYiIiIbJK4lOM41s5nAMcDbZvZudHx3MxsM4O4FwPXAu8Ak4GV3nxBHvQmZNg3OPx8aNoSFC8NCtJ99BkceGXdlIiIikoXMPXOGcCVDgwYNfNSoUem74NKlYdumhx6CLbYIS2vcfDNss036ahAREZGsZGaj3b3ENWO148DGWrsWnn0WOnSAefOgZcsQ1nbfPe7KREREJAcopG2MYcPCemfjxsHxx8PgwXD44XFXJSIiIjlEIW1DLV0KeXlhd/VXXoHzzoOyF+UVERER2WAKaRtqxx1h6NCwy/rWW8ddjYiIiOQohbSNoRmbIiIikmKZvE6aiIiISIWlkCYiIiKSgdTdGbNx42DgQJg+HWrWDHMS6tWLuyoRERGJm1rSYjRuHOTnw+LFYdeoxYvD43Hj4q5MRERE4qaQFqOBA8NKHlWrwmab/Xl/4MC4KxMREZG4KaTFaPp0qFx5/WOVK4fjIiIiUrEppMWoZk1YsmT9Y0uWhOMiIiJSsSmkxSgvL4xDW7wYCgv/vJ+XF3dlIiIiEjeFtBjVqwdt24ZxaDNnhq9t22p2p4iIiGgJjtjVq6dQJiIiIn+lljQRERGRDKSQJiIiIpKBFNJEREREMpBCmoiIiEgGUkgTERERyUAKaSIiIiIZSCFNREREJAMppImIiIhkIIU0ERERkQykkCYiIiKSgczd464hqcxsPvBz3HWUoRqwIO4iRJ9DhtDnkDn0WWQGfQ6ZIZ2fw57uvnNJT+RcSMt0ZjbK3RvEXUdFp88hM+hzyBz6LDKDPofMkCmfg7o7RURERDKQQpqIiIhIBlJIS7+n4i5AAH0OmUKfQ+bQZ5EZ9Dlkhoz4HDQmTURERCQDqSVNREREJAMppKWYmV1gZhPMrNDMSp0pYmZnmNl3ZjbVzNqls8aKwMx2MrP3zGxK9LVqKeetNbOx0W1QuuvMVeX9fJvZVmbWP3r+SzOrFUOZOS+Bz6Glmc0v8nfgyjjqzHVm9qyZzTOz8aU8b2b2SPQ5jTOzw9JdY0WQwOfQ0MyWFPn70CndNSqkpd54IA/4pLQTzKwS8G+gMVAXaG5mddNTXoXRDvjA3esAH0SPS7LS3Q+Jbk3SV17uSvDnuxWw2N1rAz2B+9NbZe7bgH9n+hf5O9ArrUVWHL2BM8p4vjFQJ7pdDfwnDTVVRL0p+3MA+LTI34e70lDTehTSUszdJ7n7d+WcdiQw1d2nufvvQD+gaeqrq1CaAn2i+32Ac+IrpcJJ5Oe76OczADjZzCyNNVYE+ncmQ7j7J8CiMk5pCjzvwRdAFTPbLT3VVRwJfA6xU0jLDHsAM4o8nhkdk+TZxd1nR/fnALuUct7WZjbKzL4ws3PSU1rOS+Tn+49z3L0AWAL8LS3VVRyJ/jtzXtTFNsDMaqSnNClG/ydkjmPM7Bsze8fMDkz3xTdP9wVzkZm9D+xawlPt3f2NdNdTUZX1ORR94O5uZqVNa97T3WeZ2d7AMDP71t1/SHatIhnqTaCvu682s2sIrZv/E3NNInEZQ/g/YZmZnQm8TuiCThuFtCRw91M28S1mAUV/Y60eHZMNUNbnYGZzzWw3d58ddRvMK+U9ZkVfp5nZR8ChgELapknk53vdOTPNbHOgMrAwPeVVGOV+Du5e9HveC3ggDXXJX+n/hAzg7kuL3B9sZo+bWTV3T9vequruzAwjgTpmtpeZbQk0AzSzMLkGAS2i+y2Av7RwmllVM9squl8NOA6YmLYKc1ciP99FP5/zgWGuRRyTrdzPodi4pybApDTWJ38aBFwezfI8GlhSZLiGpImZ7bpubKyZHUnITGn95VEtaSlmZucCjwI7A2+b2Vh3P93Mdgd6ufuZ7l5gZtcD7wKVgGfdfUKMZeeibsDLZtYK+Bm4ECBaFuVad78SOAB40swKCX8Zu7m7QtomKu3n28zuAka5+yDgGeAFM5tKGMjbLL6Kc1OCn8ONZtYEKCB8Di1jKziHmVlfoCFQzcxmAp2BLQDc/QlgMHAmMBVYAVwRT6W5LYHP4XzgX2ZWAKwEmqX7l0ftOCAiIiKSgdTdKSIiIpKBFNJEREREMpBCmoiIiEgGUkgTERERyUAKaSIiIiIZSCFNRLKGmZ1jZm5m+ydw7k1mtu0mXKulmT1W7FgtM5tpZpsVOz7WzI4q5X1qmdn4ja1DRCouhTQRySbNgeHR1/LcBGx0SCuJu/8ETAdOWHcsCow7uPuXybyWiIhCmohkBTPbHjgeaEWRxW7NrJKZ5ZvZ+Ghj8BvM7EZgd+BDM/swOm9Zkdecb2a9o/tnm9mXZva1mb1vZruUU0pf1l9stxnQL2ox+9TMxkS3Y0v4M6zXOmdmb5lZw+j+aWb2efTaV6I/L2bWzcwmRn+2/MS/YyKS7bTjgIhki6bAEHf/3swWmtnh7j4auBqoBRwSraq/k7svMrObgUYJ7LM3HDja3d3MrgRuBdqUcf7LwFgzu8HdC4CLgAsI+8Ge6u6rzKwOIcw1SOQPFm1D1gE4xd2Xm9ltwM1m9m/gXGD/qL4qibyfiOQGhTQRyRbNgYej+/2ix6OBU4AnosCEuy/awPetDvSP9q3cEvixrJPdfW40xuxkM5sLFLj7eDOrDDxmZocAa4F9N6CGo4G6wGfRVoFbAp8DS4BVwDNm9hbw1gb9yUQkqymkiUjGM7OdgP8BDjYzJ+w96WZ2ywa8TdE98LYucv9RoIe7D4q6Hrsk8F7rujznRvcBWkeP6xOGkqwq4XUFrD/MZF0dBrzn7n8Zaxdt7HwyYR/B6wnfBxGpADQmTUSywfnAC+6+p7vXcvcahBavE4D3gGvMbHP4I9AB/AbsUOQ95prZAdHMzHOLHK8MzIrut0iwnoGEDbAvIrTqrXuf2e5eCFxGCJLF/QQcYmabmVkN4Mjo+BfAcWZWO/ozbGdm+0bj0iq7+2BCCKyfYH0ikgMU0kQkGzQHXit27NXoeC/CjMtxZvYNcHH0/FPAkHUTB4B2hO7CEcDsIu/TBXjFzEYD5Y1fA8DdfyV0R85192nR4ceBFlEN+wPLS3jpZ4RwORF4BBgTvd98oCXQ18zGRe+9PyFkvhUdGw7cnEh9IpIbzN3LP0tERERE0kotaSIiIiIZSCFNREREJAMppImIiIhkIIU0ERERkQykkCYiIiKSgRTSRERERDKQQpqIiIhIBlJIExEREclA/w9NpX3trLnT4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_svr(X_train, y_train):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Hyperparameters grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }\n",
    "    \n",
    "    # Using GridSearchCV to find the best hyperparameters\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_svr = grid_search.best_estimator_\n",
    "    return best_svr, scaler\n",
    "\n",
    "def evaluate_svr(svr_model, scaler, X_test, y_test):\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = svr_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"R-squared (R2): {r2:.2f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # diagonal line\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('SVR Predictions vs Actual Values')\n",
    "    plt.show()\n",
    "\n",
    "# Training the SVR model\n",
    "best_svr, scaler = train_svr(X_train, y_train)\n",
    "\n",
    "# Evaluating the trained SVR model\n",
    "evaluate_svr(best_svr, scaler, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77d602-79cc-47f7-a981-dac688b93f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_22AGresultsTUNED_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c656673-0a5b-475d-97ae-3bbaa992b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('22AGresultsTUNEDLSTMSNN Neural Network.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5b179-af34-4625-bac3-c6a6ec9f3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24204c6-bc01-4af8-804b-c48500e73e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c10b8-8696-401c-9245-f50092361d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('simple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('22AGresultsLSTMTUNED.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48131581-c234-4961-a88b-0589f5350c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df2)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_start_delay'], axis=1)\n",
    "y = df['Phase_start_delay']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('neural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results_df.to_excel('22AGTdenseNN_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

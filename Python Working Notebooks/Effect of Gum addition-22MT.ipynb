{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ded1392-3b34-44f0-8ce8-2c5218e064c7",
   "metadata": {},
   "source": [
    "### Gum Ingredient Addition - 22MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1228d9c-d0a3-44e8-b6f2-1299dc072911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2c3d2b-e866-4a84-91fb-8c3da5aedc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19268a8f-87e5-41cf-9209-ef912a4ead27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Material    BATCHID  Tank_1             Instruction_Step  \\\n",
       "0           0   1002150  107643491    2503         S3_BATCH_IN_PROGRESS   \n",
       "1           1   1002150  107643491    2503                   STEP1_CONS   \n",
       "2           2   1002150  107643491    2503  PLEASE VERIFY BULK ADDITION   \n",
       "3           3   1002150  107643491    2503                   STEP1_CONS   \n",
       "4           4   1002150  107643491    2503                   STEP1_CONS   \n",
       "\n",
       "  INGRED_ID                           INGRED_Name  Quantity       Phase_start  \\\n",
       "0       NaN                                   NaN     0.000  09/03/2022 10:42   \n",
       "1   1002565                         WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2       NaN                                   NaN     0.000  09/03/2022 11:16   \n",
       "3   1037802  S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4   1002818  S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "\n",
       "          Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0  09/03/2022 10:42               0                  0             1   \n",
       "1  09/03/2022 11:16              34                  0             2   \n",
       "2  09/03/2022 11:17               1                  0             3   \n",
       "3  09/03/2022 11:27              10                  0             4   \n",
       "4  09/03/2022 11:38              11                  0             5   \n",
       "\n",
       "   Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0          0.0000              NaN                      0            NaN   \n",
       "1        169.4118         733.5050                      8           26.0   \n",
       "2          0.0000              NaN                      3            0.0   \n",
       "3          0.5629           6.3182                      1            9.0   \n",
       "4          7.1605           6.3182                     12            0.0   \n",
       "\n",
       "   Deaeration Phase  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd80668-682b-40be-b18d-f1608e4f7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c0db5-212c-4570-80d7-72a11fbfeca7",
   "metadata": {},
   "source": [
    "## Addition of GUM Ingredients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f916a3-039c-4ba1-ad64-1194e757e8d3",
   "metadata": {},
   "source": [
    "## Examining the Phase Overrun duration times for the GUM ingredient addition - Addition of GUM ingredients to the specific production tanks based on their capacity\n",
    " This is completed manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242496b0-06a8-4820-87eb-ebe595125362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "specific_tanks = [2202, 2203, 2204,2205]\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['1461896', '1254972', '1031006','1243269','1196706','1815609']\n",
    "filtered_data = data[(data['INGRED_ID'].isin(desired_steps)) & (data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'Material','BATCHID'])['Phase_overrun'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "#print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Visualization using bar plots\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=total_durations, x='Tank_1', y='Phase_overrun',ci=None)\n",
    "plt.title('Total Phase_overrun for Each Tank by Phase')\n",
    "plt.ylabel('Phase_overrun')\n",
    "plt.xlabel('Tank')\n",
    "plt.legend(title='Phase_overrun')\n",
    "plt.show()\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df4 = filtered_data.groupby(['Tank_1','BATCHID']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    " #Print the aggregated DataFrame\n",
    "#print(aggregated_total_durations_df4)\n",
    "\n",
    "#aggregated_total_durations_df4.to_csv('GUMADD22MT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5294662-ab9a-453a-acc0-358889c963a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated_total_durations_df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d98595-caf8-487b-94c7-82d4b1927b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank22_df = pd.DataFrame(aggregated_total_durations_df4)\n",
    "#ProductionTank22_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank22_df = remove_outliers_iqr(ProductionTank22_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "#print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b6140e-6e99-4269-b228-9eaecabf6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate']\n",
    "ProductionTank22_df[numerical_cols] = scaler.fit_transform(ProductionTank22_df[numerical_cols])\n",
    "#print(ProductionTank22_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149bc04e-5114-4058-b652-4ca75a32b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.00617133  | 0.00215359 |  0.99275   |  0.99846  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.0117591   | 0.0274705  |  0.986186  |  0.980356 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.840205    | 1.67604    |  0.0129771 | -0.198528 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0483132   | 0.133439   |  0.943244  |  0.904579 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 3.71497e-07 | 0.29032    |  1         |  0.792394 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           | 0.0879797  |  1         |  0.937086 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0501103   | 0.163911   |  0.941133  |  0.882788 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.0083402   | 0.174617   |  0.990202  |  0.875132 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 2.1588e-30  | 0.0644125  |  1         |  0.953939 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Load your dataset (replace 'aggregated_ProductionTank2202_dfGUM' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22AGresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeddfb33-6178-4e63-8629-6999a8394dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 0.014568\n",
      "  Std MSE: 0.008945\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 0.027331\n",
      "  Std MSE: 0.015915\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.455116\n",
      "  Std MSE: 0.828159\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.208502\n",
      "  Std MSE: 0.232579\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.234378\n",
      "  Std MSE: 0.313583\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 1.268857\n",
      "  Std MSE: 0.878851\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 8383186672529.679688\n",
      "  Std MSE: 7126388111812.278320\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.539899\n",
      "  Std MSE: 0.530484\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.163482\n",
      "  Std MSE: 0.137985\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.205201\n",
      "  Std MSE: 0.243316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    \n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "    \n",
    " # Save the results to an Excel file\n",
    "df.to_excel(\"22AGresultsCVmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc2f726-8a20-4557-bd8f-3c68f9d34fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge Regression: {'alpha': 0.01}\n",
      "Best parameters for Lasso Regression: {'alpha': 0.01}\n",
      "Best parameters for Random Forest Regressor: {'max_depth': 10, 'n_estimators': 200}\n",
      "Best parameters for Gradient Boosting Regressor: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 200}\n",
      "Best parameters for Decision Tree Regressor: {'max_depth': 20}\n",
      "Best parameters for Bagging Regressor: {'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 200}\n",
      "                         Model     Train MSE  Test MSE  Train R2   Test R2\n",
      "0            Linear Regression  6.171334e-03  0.002154  0.992750  0.998460\n",
      "1             Ridge Regression  6.172357e-03  0.002257  0.992749  0.998386\n",
      "2             Lasso Regression  7.588032e-03  0.003796  0.991086  0.997286\n",
      "3      Random Forest Regressor  3.603034e-02  0.088870  0.957674  0.936450\n",
      "4  Gradient Boosting Regressor  2.198951e-16  0.333031  1.000000  0.761852\n",
      "5      Decision Tree Regressor  0.000000e+00  0.184395  1.000000  0.868140\n",
      "6            Bagging Regressor  4.113468e-02  0.127361  0.951677  0.908925\n",
      "7           AdaBoost Regressor  8.340196e-03  0.174617  0.990202  0.875132\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.00617133  | 0.00215359 |   0.99275  |  0.99846  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.00617236  | 0.00225707 |   0.992749 |  0.998386 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.00758803  | 0.00379551 |   0.991086 |  0.997286 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.0360303   | 0.0888697  |   0.957674 |  0.93645  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 2.19895e-16 | 0.333031   |   1        |  0.761852 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0           | 0.184395   |   1        |  0.86814  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0411347   | 0.127361   |   0.951677 |  0.908925 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.0083402   | 0.174617   |   0.990202 |  0.875132 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and targetProductionTank22_df\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Ridge Regression: {ridge_grid.best_params_}\")\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Lasso Regression: {lasso_grid.best_params_}\")\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Random Forest Regressor: {rf_grid.best_params_}\")\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Gradient Boosting Regressor: {gb_grid.best_params_}\")\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Decision Tree Regressor: {dt_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Bagging Regressor: {bag_grid.best_params_}\")\n",
    "\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22AGresultsTUNED.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b39f1-63f0-49c2-9afa-096aac660f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "453ed0f7-c8a5-4aad-82a2-bcd72d90050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.05\n",
      "Mean Absolute Error (MAE): 0.86\n",
      "R-squared (R2): -0.11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Drop the target variable and split data\n",
    "# Define features and targetProductionTank22_df\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define the model\n",
    "model = SVR()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model (For example, using Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2615c632-eb53-463b-9f89-ee1ffe721022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.01\n",
      "Mean Absolute Error (MAE): 0.05\n",
      "R-squared (R2): 0.99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_svr(X_train, y_train):\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Hyperparameters grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.01, 0.1, 1],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }\n",
    "    \n",
    "    # Using GridSearchCV to find the best hyperparameters\n",
    "    svr = SVR()\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_svr = grid_search.best_estimator_\n",
    "    return best_svr, scaler\n",
    "\n",
    "def evaluate_svr(svr_model, scaler, X_test, y_test):\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_pred = svr_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"R-squared (R2): {r2:.2f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # diagonal line\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('SVR Predictions vs Actual Values')\n",
    "    plt.show()\n",
    "\n",
    "# Training the SVR model\n",
    "best_svr, scaler = train_svr(X_train, y_train)\n",
    "\n",
    "# Evaluating the trained SVR model\n",
    "evaluate_svr(best_svr, scaler, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f77d602-79cc-47f7-a981-dac688b93f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |    0.360504 |   0.617133 |   0.576501 |  0.558692 |      0.539965 |     0.677587 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |    0.151405 |   0.52183  |   0.822139 |  0.626843 |      0.535488 |     0.823391 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters for K-Nearest Neighbors: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for Support Vector Machine: {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "|                        | Model                  |   Train MSE |   Test MSE |   Train R2 |   Test R2 |   CV MSE Mean |   CV MSE Std |\n",
      "+========================+========================+=============+============+============+===========+===============+==============+\n",
      "| K-Nearest Neighbors    | K-Nearest Neighbors    |  0          | 0.620109   |   1        |  0.556564 |      0.531956 |   0.66264    |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n",
      "| Support Vector Machine | Support Vector Machine |  0.00819813 | 0.00801767 |   0.990369 |  0.994267 |      0.017501 |   0.00387387 |\n",
      "+------------------------+------------------------+-------------+------------+------------+-----------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_22AGresultsTUNED_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c656673-0a5b-475d-97ae-3bbaa992b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |  0.00881247 |   0.177217 |   0.989648 |  0.873273 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                 |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=======================+=============+============+============+===========+\n",
      "|  0 | Simple Neural Network |  0.00881247 |   0.177217 |   0.989648 |  0.873273 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n",
      "|  1 | LSTM Neural Network   |  0.362935   |   0.786263 |   0.573645 |  0.437748 |\n",
      "+----+-----------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('22AGresultsLSTMSNN Neural Network.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac5b179-af34-4625-bac3-c6a6ec9f3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001DF16B24DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000001DF16A13CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best Simple NN Params: {'batch_size': 16, 'dense1_neurons': 128, 'dense2_neurons': 32, 'epochs': 50}\n",
      "Training MSE: 0.0005472223500017657\n",
      "Training R^2: 0.999357155675095\n",
      "Test MSE: 0.054074730319941734\n",
      "Test R^2: 0.9613314857530553\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e24204c6-bc01-4af8-804b-c48500e73e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best LSTM Params: {'batch_size': 32, 'epochs': 100, 'lstm_neurons': 50}\n",
      "Training MSE for LSTM: 0.09222057186495636\n",
      "Training R^2 for LSTM: 0.8916647478621891\n",
      "Test MSE for LSTM: 0.272725602101412\n",
      "Test R^2 for LSTM: 0.8049755631148119\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c10b8-8696-401c-9245-f50092361d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('simple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('22AGresultsLSTMTUNED.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48131581-c234-4961-a88b-0589f5350c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+======================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network |  4.4424e-05 | 0.00259779 |          0 |         0 |\n",
      "+----+----------------------+-------------+------------+------------+-----------+\n",
      "Best Score:  -0.0014405873759339254\n",
      "Best Params:  {'neurons_layer3': 16, 'neurons_layer2': 32, 'neurons_layer1': 128, 'epochs': 50, 'batch_size': 64}\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                            |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+==================================+=============+============+============+===========+\n",
      "|  0 | Dense Neural Network             | 4.4424e-05  | 0.00259779 |          0 |         0 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Dense Neural Network (Optimized) | 1.06013e-05 | 0.00181827 |          0 |         0 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Dense Neural Network (Optimized) | 1.06013e-05 | 0.00181827 |          0 |         0 |\n",
      "+----+----------------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_start_delay'], axis=1)\n",
    "y = df['Phase_start_delay']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('neural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('22AGTdenseNN_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bc1bd-b91b-4f09-8da2-a39a7fdbda5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

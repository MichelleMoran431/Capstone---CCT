{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef380bb-177f-42b5-9089-23d028473262",
   "metadata": {},
   "source": [
    "### Agitation on Production tanks - 22MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351e04f5-c156-43f5-b04f-7aa88e1e6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Supress Warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#The last line of code helps in suppressing the unnecessary warnings.\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac75ad5-8489-43d2-a1c5-a7912cb763ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection:\n",
    "# Using the Specify Absolute Path: If the file is located in a different directory, you can specify the absolute path to the file when reading it using pd.read_csv():\n",
    "import pandas as pd\n",
    "file_path = r'C:\\Users\\User\\Desktop\\Thesis 2023\\Capstone---CCT\\Python Working Notebooks\\ProductionDataupdated1.csv'\n",
    "ProductionTank = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a42ef6-82d3-4d16-a479-1f451969c5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Material</th>\n",
       "      <th>BATCHID</th>\n",
       "      <th>Tank_1</th>\n",
       "      <th>Instruction_Step</th>\n",
       "      <th>INGRED_ID</th>\n",
       "      <th>INGRED_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Phase_start</th>\n",
       "      <th>Phase_end</th>\n",
       "      <th>Phase_duration</th>\n",
       "      <th>Phase_start_delay</th>\n",
       "      <th>Phase_row_no</th>\n",
       "      <th>Flowrate_KGMIN</th>\n",
       "      <th>Target_Flowrate</th>\n",
       "      <th>Target_Phase_duration</th>\n",
       "      <th>Phase_overrun</th>\n",
       "      <th>Deaeration Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>S3_BATCH_IN_PROGRESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002565</td>\n",
       "      <td>WATER TREATED</td>\n",
       "      <td>5760.000</td>\n",
       "      <td>09/03/2022 10:42</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>169.4118</td>\n",
       "      <td>733.5050</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>PLEASE VERIFY BULK ADDITION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>09/03/2022 11:16</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1037802</td>\n",
       "      <td>S813     SOD BENZOATE          XFX25</td>\n",
       "      <td>5.629</td>\n",
       "      <td>09/03/2022 11:17</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1002150</td>\n",
       "      <td>107643491</td>\n",
       "      <td>2503</td>\n",
       "      <td>STEP1_CONS</td>\n",
       "      <td>1002818</td>\n",
       "      <td>S651     CITRIC ACID ANH    BG XFX25</td>\n",
       "      <td>78.766</td>\n",
       "      <td>09/03/2022 11:27</td>\n",
       "      <td>09/03/2022 11:38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7.1605</td>\n",
       "      <td>6.3182</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Material    BATCHID  Tank_1             Instruction_Step  \\\n",
       "0           0   1002150  107643491    2503         S3_BATCH_IN_PROGRESS   \n",
       "1           1   1002150  107643491    2503                   STEP1_CONS   \n",
       "2           2   1002150  107643491    2503  PLEASE VERIFY BULK ADDITION   \n",
       "3           3   1002150  107643491    2503                   STEP1_CONS   \n",
       "4           4   1002150  107643491    2503                   STEP1_CONS   \n",
       "\n",
       "  INGRED_ID                           INGRED_Name  Quantity       Phase_start  \\\n",
       "0       NaN                                   NaN     0.000  09/03/2022 10:42   \n",
       "1   1002565                         WATER TREATED  5760.000  09/03/2022 10:42   \n",
       "2       NaN                                   NaN     0.000  09/03/2022 11:16   \n",
       "3   1037802  S813     SOD BENZOATE          XFX25     5.629  09/03/2022 11:17   \n",
       "4   1002818  S651     CITRIC ACID ANH    BG XFX25    78.766  09/03/2022 11:27   \n",
       "\n",
       "          Phase_end  Phase_duration  Phase_start_delay  Phase_row_no  \\\n",
       "0  09/03/2022 10:42               0                  0             1   \n",
       "1  09/03/2022 11:16              34                  0             2   \n",
       "2  09/03/2022 11:17               1                  0             3   \n",
       "3  09/03/2022 11:27              10                  0             4   \n",
       "4  09/03/2022 11:38              11                  0             5   \n",
       "\n",
       "   Flowrate_KGMIN  Target_Flowrate  Target_Phase_duration  Phase_overrun  \\\n",
       "0          0.0000              NaN                      0            NaN   \n",
       "1        169.4118         733.5050                      8           26.0   \n",
       "2          0.0000              NaN                      3            0.0   \n",
       "3          0.5629           6.3182                      1            9.0   \n",
       "4          7.1605           6.3182                     12            0.0   \n",
       "\n",
       "   Deaeration Phase  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductionTank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf73d0c-7499-465d-8d22-5701d012c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProductionTank.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d952e0-5808-4a32-bbe3-848e6474712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tank_1  BATCHID\n",
      "0     2201       37\n",
      "1     2202       24\n",
      "2     2203       25\n",
      "3     2204       24\n",
      "4     2205       27\n",
      "5     2301       58\n",
      "6     2302       57\n",
      "7     2303       57\n",
      "8     2304       48\n",
      "9     2305       57\n",
      "10    2501       51\n",
      "11    2502       49\n",
      "12    2503       97\n",
      "13    2504       99\n",
      "14    2601       43\n",
      "15    2602       32\n",
      "16    2603       36\n",
      "17    2604       28\n"
     ]
    }
   ],
   "source": [
    "#data = pd.DataFrame(ProductionTank) \n",
    "# Count the unique materialsProductionTank produced by each tank\n",
    "Batch_counts =ProductionTank.groupby('Tank_1')['BATCHID'].nunique().reset_index()\n",
    "print(Batch_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee0451f-b3d0-4dc9-8ba6-a840ab93cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font settings\n",
    "plt.rc('axes', titlesize=16, titleweight='bold', labelsize=14, labelweight='bold')  # For axes title and labels\n",
    "plt.rc('xtick', labelsize=12)  # For x-axis tick labels\n",
    "plt.rc('ytick', labelsize=12)  # For y-axis tick labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00cc340d-2365-4260-ad2b-13912e94dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|     |   Tank_1 |   BATCHID | Instruction_Step   |   Phase_duration |\n",
      "+=====+==========+===========+====================+==================+\n",
      "|   0 |     2202 | 107867810 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   1 |     2202 | 107867810 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   2 |     2202 | 107867810 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   3 |     2202 | 107899926 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   4 |     2202 | 107899926 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   5 |     2202 | 107899926 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   6 |     2202 | 107949892 | STEP1_AGITATION    |              120 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   7 |     2202 | 107956670 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   8 |     2202 | 107956670 | STEP2_AGITATION    |               21 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|   9 |     2202 | 107956670 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  10 |     2202 | 107963677 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  11 |     2202 | 107963677 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  12 |     2202 | 107964410 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  13 |     2202 | 107964410 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  14 |     2202 | 107964410 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  15 |     2202 | 107978116 | STEP1_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  16 |     2202 | 107978116 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  17 |     2202 | 107978116 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  18 |     2202 | 107993270 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  19 |     2202 | 107993270 | STEP2_AGITATION    |                5 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  20 |     2202 | 107993270 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  21 |     2202 | 107999494 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  22 |     2202 | 107999494 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  23 |     2202 | 107999494 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  24 |     2202 | 108026759 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  25 |     2202 | 108026759 | STEP2_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  26 |     2202 | 108026759 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  27 |     2202 | 108033603 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  28 |     2202 | 108033603 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  29 |     2202 | 108033603 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  30 |     2202 | 108045117 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  31 |     2202 | 108045117 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  32 |     2202 | 108045117 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  33 |     2202 | 108073632 | STEP1_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  34 |     2202 | 108073632 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  35 |     2202 | 108073632 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  36 |     2203 | 107887071 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  37 |     2203 | 107887071 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  38 |     2203 | 107887071 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  39 |     2203 | 107933869 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  40 |     2203 | 107933869 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  41 |     2203 | 107933869 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  42 |     2203 | 107949891 | STEP1_AGITATION    |              120 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  43 |     2203 | 107963676 | STEP2_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  44 |     2203 | 107963676 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  45 |     2203 | 107971404 | STEP1_AGITATION    |               61 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  46 |     2203 | 107971404 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  47 |     2203 | 107971404 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  48 |     2203 | 107978117 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  49 |     2203 | 107978117 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  50 |     2203 | 107978117 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  51 |     2203 | 107999492 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  52 |     2203 | 107999492 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  53 |     2203 | 107999492 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  54 |     2203 | 108015838 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  55 |     2203 | 108015838 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  56 |     2203 | 108015838 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  57 |     2203 | 108030821 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  58 |     2203 | 108030821 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  59 |     2203 | 108030821 | STEP3_AGITATION    |                5 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  60 |     2203 | 108033608 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  61 |     2203 | 108033608 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  62 |     2203 | 108033608 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  63 |     2203 | 108042636 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  64 |     2203 | 108042636 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  65 |     2203 | 108042636 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  66 |     2203 | 108051514 | STEP1_AGITATION    |               61 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  67 |     2203 | 108051514 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  68 |     2203 | 108051514 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  69 |     2203 | 108059029 | STEP1_AGITATION    |              105 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  70 |     2203 | 108059029 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  71 |     2203 | 108059029 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  72 |     2203 | 108067819 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  73 |     2203 | 108067819 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  74 |     2203 | 108067819 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  75 |     2203 | 108073631 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  76 |     2203 | 108073631 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  77 |     2203 | 108073631 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  78 |     2204 | 107848868 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  79 |     2204 | 107848868 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  80 |     2204 | 107848868 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  81 |     2204 | 107862335 | STEP1_AGITATION    |              105 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  82 |     2204 | 107862335 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  83 |     2204 | 107862335 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  84 |     2204 | 107872112 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  85 |     2204 | 107872112 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  86 |     2204 | 107872112 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  87 |     2204 | 107899925 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  88 |     2204 | 107899925 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  89 |     2204 | 107899925 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  90 |     2204 | 107907563 | STEP1_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  91 |     2204 | 107907563 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  92 |     2204 | 107907563 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  93 |     2204 | 107915806 | STEP1_AGITATION    |              105 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  94 |     2204 | 107915806 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  95 |     2204 | 107915806 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  96 |     2204 | 107925352 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  97 |     2204 | 107925352 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  98 |     2204 | 107925352 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "|  99 |     2204 | 107964387 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 100 |     2204 | 107964387 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 101 |     2204 | 107964387 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 102 |     2204 | 107969769 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 103 |     2204 | 107969769 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 104 |     2204 | 107969769 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 105 |     2204 | 107978118 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 106 |     2204 | 107978118 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 107 |     2204 | 107978118 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 108 |     2204 | 107992045 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 109 |     2204 | 107992045 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 110 |     2204 | 107992045 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 111 |     2204 | 107999493 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 112 |     2204 | 107999493 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 113 |     2204 | 107999493 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 114 |     2204 | 108015839 | STEP1_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 115 |     2204 | 108015839 | STEP2_AGITATION    |               20 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 116 |     2204 | 108015839 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 117 |     2204 | 108026760 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 118 |     2204 | 108026760 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 119 |     2204 | 108026760 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 120 |     2204 | 108042635 | STEP1_AGITATION    |               61 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 121 |     2204 | 108042635 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 122 |     2204 | 108042635 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 123 |     2204 | 108075449 | STEP1_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 124 |     2204 | 108075449 | STEP2_AGITATION    |               21 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 125 |     2204 | 108075449 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 126 |     2204 | 108084749 | STEP1_AGITATION    |               61 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 127 |     2204 | 108084749 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 128 |     2204 | 108084749 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 129 |     2205 | 107964409 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 130 |     2205 | 107964409 | STEP2_AGITATION    |               30 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 131 |     2205 | 107964409 | STEP3_AGITATION    |                0 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 132 |     2205 | 108084750 | STEP1_AGITATION    |               60 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 133 |     2205 | 108084750 | STEP2_AGITATION    |               31 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n",
      "| 134 |     2205 | 108084750 | STEP3_AGITATION    |                1 |\n",
      "+-----+----------+-----------+--------------------+------------------+\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "data = pd.DataFrame(ProductionTank)\n",
    "specific_tanks = [2202, 2203, 2204,2205]\n",
    "\n",
    "# Filter the dataframe for desired instruction steps\n",
    "desired_steps = ['STEP1_AGITATION', 'STEP2_AGITATION','STEP3_AGITATION']\n",
    "filtered_data = data[(data['Instruction_Step'].isin(desired_steps)) & (data['Tank_1'].isin(specific_tanks))]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total phase duration for each desired instruction step for each tank and material\n",
    "total_durations = filtered_data.groupby(['Tank_1', 'BATCHID','Instruction_Step'])['Phase_duration'].sum().reset_index()\n",
    "\n",
    "# Present in table format\n",
    "print(tabulate(total_durations, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Visualization using bar plots\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=total_durations, x='Tank_1', y='Phase_duration', ci=None)\n",
    "plt.title('Total Phase_duration for Each Tank by Phase')\n",
    "plt.ylabel('Phase_duration')\n",
    "plt.xlabel('Tank')\n",
    "plt.legend(title='Phase_duration')\n",
    "#plt.show()\n",
    "\n",
    "#Aggregate data per tank\n",
    "aggregated_total_durations_df2 = filtered_data.groupby(['Tank_1','BATCHID']).agg({\n",
    "  #  'BATCHID': 'count',\n",
    "    # 'Material': 'count',\n",
    "    'Phase_duration': 'sum',\n",
    "    'Phase_overrun': 'sum',\n",
    "    'Phase_start_delay':'sum',\n",
    "    'Quantity':'sum',\n",
    "    'Flowrate_KGMIN':'sum',\n",
    "    'Target_Phase_duration':'mean',\n",
    "    'Target_Flowrate':'mean'\n",
    "}).reset_index()\n",
    "\n",
    " #Print the aggregated DataFrame\n",
    "#print(aggregated_total_durations_df2)\n",
    "\n",
    "aggregated_total_durations_df2.to_csv('Agitation22MT.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c827824-d055-4ce5-a232-697b9b4bddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "#aggregated_total_durations_df2.dropna(inplace=True)  # Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dd2246-274f-43c0-8e34-ce1380e376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling du# Handling duplicates\n",
    "#aggregated_total_durations_df2.drop_duplicates(inplace=True)  # Remove duplicate rowsplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e85f8ce-adf8-4eaf-a000-2d08075992b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank22_df = pd.DataFrame(aggregated_total_durations_df2)\n",
    "ProductionTank22_df\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank22_df = remove_outliers_iqr(ProductionTank22_df, col)\n",
    "# Display the cleaned DataFrame\n",
    "#print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428e9a42-19bc-4112-81e2-99af032d3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns where you want to detect and remove outliers\n",
    "ProductionTank22_df1 = pd.DataFrame(aggregated_total_durations_df2)\n",
    "\n",
    "columns_to_check = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay', 'Flowrate_KGMIN', 'Target_Phase_duration']\n",
    "\n",
    "# Define a function to remove outliers using IQR\n",
    "def remove_outliers_iqr(data, column, iqr_multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - iqr_multiplier * IQR\n",
    "    upper_bound = Q3 + iqr_multiplier * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "   ProductionTank22_df1 = remove_outliers_iqr(ProductionTank22_df1, col)\n",
    "# Display the cleaned DataFrame\n",
    "#print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea6a804-d22e-41f5-9e07-92934bbc8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay']\n",
    "ProductionTank22_df[numerical_cols] = scaler.fit_transform(ProductionTank22_df[numerical_cols])\n",
    "#print(ProductionTank22_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a54f7fa-6e37-4bf9-9293-59a84406c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical variables (if needed)\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#numerical_cols = ['Phase_duration', 'Phase_overrun', 'Phase_start_delay']\n",
    "#aggregated_total_durations_df2[numerical_cols] = scaler.fit_transform(aggregated_total_durations_df2[numerical_cols])\n",
    "#print(aggregated_total_durations_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58871e9d-b507-493d-8245-6443bda1dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Tank_1       BATCHID  Phase_duration  Phase_overrun  \\\n",
      "count    47.000000  4.700000e+01       47.000000      47.000000   \n",
      "mean   2203.170213  1.079839e+08       78.680851       0.489362   \n",
      "std       0.892460  6.440374e+04       27.072452       0.655158   \n",
      "min    2202.000000  1.078489e+08       31.000000       0.000000   \n",
      "25%    2202.000000  1.079499e+08       51.000000       0.000000   \n",
      "50%    2203.000000  1.079781e+08       90.000000       0.000000   \n",
      "75%    2204.000000  1.080336e+08       91.000000       1.000000   \n",
      "max    2205.000000  1.080848e+08      135.000000       3.000000   \n",
      "\n",
      "       Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count          47.000000      47.0            47.0              47.000000   \n",
      "mean          452.425532       0.0             0.0              26.515957   \n",
      "std          1225.688161       0.0             0.0               9.795010   \n",
      "min             0.000000       0.0             0.0              15.000000   \n",
      "25%             1.000000       0.0             0.0              16.666667   \n",
      "50%             1.000000       0.0             0.0              30.000000   \n",
      "75%             2.000000       0.0             0.0              30.000000   \n",
      "max          4670.000000       0.0             0.0              60.000000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count              0.0  \n",
      "mean               NaN  \n",
      "std                NaN  \n",
      "min                NaN  \n",
      "25%                NaN  \n",
      "50%                NaN  \n",
      "75%                NaN  \n",
      "max                NaN  \n",
      "            Tank_1       BATCHID  Phase_duration  Phase_overrun  \\\n",
      "count    34.000000  3.400000e+01    3.400000e+01   3.400000e+01   \n",
      "mean   2203.058824  1.079867e+08   -2.449021e-16  -1.306145e-17   \n",
      "std       0.885615  6.410490e+04    1.015038e+00   1.015038e+00   \n",
      "min    2202.000000  1.078623e+08   -1.820294e+00  -8.997354e-01   \n",
      "25%    2202.000000  1.079584e+08   -1.071473e+00  -8.997354e-01   \n",
      "50%    2203.000000  1.079851e+08    3.887257e-01  -8.997354e-01   \n",
      "75%    2204.000000  1.080404e+08    4.261667e-01   8.997354e-01   \n",
      "max    2205.000000  1.080848e+08    2.073571e+00   2.699206e+00   \n",
      "\n",
      "       Phase_start_delay  Quantity  Flowrate_KGMIN  Target_Phase_duration  \\\n",
      "count       3.400000e+01      34.0            34.0              34.000000   \n",
      "mean        3.265362e-17       0.0             0.0              25.674020   \n",
      "std         1.015038e+00       0.0             0.0               6.872620   \n",
      "min        -1.377061e+00       0.0             0.0              15.000000   \n",
      "25%        -1.011279e+00       0.0             0.0              16.666667   \n",
      "50%         8.606630e-02       0.0             0.0              30.000000   \n",
      "75%         8.606630e-02       0.0             0.0              30.000000   \n",
      "max         1.549193e+00       0.0             0.0              33.750000   \n",
      "\n",
      "       Target_Flowrate  \n",
      "count              0.0  \n",
      "mean               NaN  \n",
      "std                NaN  \n",
      "min                NaN  \n",
      "25%                NaN  \n",
      "50%                NaN  \n",
      "75%                NaN  \n",
      "max                NaN  \n"
     ]
    }
   ],
   "source": [
    "# For the original DataFrame\n",
    "#print(\"Original DataFrame Summary Statistics:\")\n",
    "print(aggregated_total_durations_df2.describe())\n",
    "\n",
    "# After removing outliers\n",
    "#print(\"\\nCleaned DataFrame Summary Statistics:\")\n",
    "print(ProductionTank22_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32eccb79-e88b-4cd5-baa7-968f0f166525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|    | Model                       |   Train MSE |   Test MSE |   Train R2 |   Test R2 |\n",
      "+====+=============================+=============+============+============+===========+\n",
      "|  0 | Linear Regression           | 0.767061    |    1.23227 |  0.249173  |  -2.10786 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  1 | Ridge Regression            | 0.76738     |    1.22855 |  0.248861  |  -2.09849 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  2 | Lasso Regression            | 0.939935    |    1.41431 |  0.0799577 |  -2.56696 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  3 | Random Forest Regressor     | 0.398769    |    1.202   |  0.60967   |  -2.03152 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  4 | Gradient Boosting Regressor | 0.0190554   |    1.08005 |  0.981348  |  -1.72395 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  5 | Decision Tree Regressor     | 0.222726    |    1.26031 |  0.781988  |  -2.17857 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  6 | Bagging Regressor           | 0.0759034   |    1.34945 |  0.925703  |  -2.4034  |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  7 | AdaBoost Regressor          | 0.00353958  |    1.67155 |  0.996535  |  -3.21575 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n",
      "|  8 | Extra Trees Regressor       | 1.69916e-30 |    1.55063 |  1         |  -2.91078 |\n",
      "+----+-----------------------------+-------------+------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank2203_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate','Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun','Flowrate_KGMIN','Target_Phase_duration','Target_Flowrate','Phase_start_delay'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred_train = ridge_model.predict(X_train)\n",
    "ridge_pred_test = ridge_model.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred_train = lasso_model.predict(X_train)\n",
    "lasso_pred_test = lasso_model.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "\n",
    "# RandomForest Regressor\n",
    "#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model = RandomForestRegressor(n_estimators=50, max_depth=10, min_samples_split=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "#gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=5, subsample=0.8, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred_train = gb_model.predict(X_train)\n",
    "gb_pred_test = gb_model.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Decision Tree Regressor\n",
    "#dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred_train = dt_model.predict(X_train)\n",
    "dt_pred_test = dt_model.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "\n",
    "# Bagging Regressor (based on Decision Trees by default)\n",
    "bag_model = BaggingRegressor(n_estimators=100, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "bag_pred_train = bag_model.predict(X_train)\n",
    "bag_pred_test = bag_model.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "\n",
    "# AdaBoost Regressor\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "ada_pred_train = ada_model.predict(X_train)\n",
    "ada_pred_test = ada_model.predict(X_test)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "et_pred_train = et_model.predict(X_train)\n",
    "et_pred_test = et_model.predict(X_test)\n",
    "et_train_mse = mean_squared_error(y_train, et_pred_train)\n",
    "et_test_mse = mean_squared_error(y_test, et_pred_test)\n",
    "et_train_r2 = r2_score(y_train, et_pred_train)\n",
    "et_test_r2 = r2_score(y_test, et_pred_test)\n",
    "results_df = results_df.append({'Model': 'Extra Trees Regressor', 'Train MSE': et_train_mse, 'Test MSE': et_test_mse, 'Train R2': et_train_r2, 'Test R2': et_test_r2}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22AGresults.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f92c41cc-63b5-4881-9886-35d8d3f00469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Mean MSE: 1.500890\n",
      "  Std MSE: 0.774948\n",
      "\n",
      "Ridge:\n",
      "  Mean MSE: 1.465161\n",
      "  Std MSE: 0.750921\n",
      "\n",
      "Lasso:\n",
      "  Mean MSE: 1.175429\n",
      "  Std MSE: 0.427696\n",
      "\n",
      "RandomForestRegressor:\n",
      "  Mean MSE: 0.716250\n",
      "  Std MSE: 0.249666\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Mean MSE: 0.438652\n",
      "  Std MSE: 0.261456\n",
      "\n",
      "SVR:\n",
      "  Mean MSE: 2.172086\n",
      "  Std MSE: 0.447346\n",
      "\n",
      "MLPRegressor:\n",
      "  Mean MSE: 4911373875207.076172\n",
      "  Std MSE: 6025855681363.345703\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  Mean MSE: 0.585941\n",
      "  Std MSE: 0.563603\n",
      "\n",
      "AdaBoostRegressor:\n",
      "  Mean MSE: 0.675100\n",
      "  Std MSE: 0.322171\n",
      "\n",
      "BaggingRegressor:\n",
      "  Mean MSE: 0.686962\n",
      "  Std MSE: 0.216823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models with their respective hyperparameters\n",
    "# Initialize models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert negative MSE back to positive\n",
    "    mean_mse = mse_scores.mean()\n",
    "    std_mse = mse_scores.std()\n",
    "    print(f\"{model_name}:\\n  Mean MSE: {mean_mse:.6f}\\n  Std MSE: {std_mse:.6f}\\n\")\n",
    "    # Save the results to an Excel file\n",
    "df.to_excel(\"22MTmodel_results.xlsx\", index=False)\n",
    "#a file named model_results.xlsx in the current working directory containing the mean and standard deviation of the MSE for each model. You can then open this file with Excel to view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da28b3d-32ab-46a4-b615-bbe5213aac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge Regression: {'alpha': 10.0}\n",
      "Best parameters for Lasso Regression: {'alpha': 0.1}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-99ca0b8acda3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mrf_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mrf_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mrf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[0mbest_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mrf_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    820\u001b[0m                     )\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    477\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         indices = _generate_sample_indices(\n\u001b[0m\u001b[0;32m    177\u001b[0m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0msample_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Load your dataset (replace 'ProductionTank2202_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df)\n",
    "\n",
    "# Define features and targetProductionTank22_df\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred_train = lr_model.predict(X_train)\n",
    "lr_pred_test = lr_model.predict(X_test)\n",
    "lr_train_mse = mean_squared_error(y_train, lr_pred_train)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_pred_test)\n",
    "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_pred_test)\n",
    "results_df = results_df.append({'Model': 'Linear Regression', 'Train MSE': lr_train_mse, 'Test MSE': lr_test_mse, 'Train R2': lr_train_r2, 'Test R2': lr_test_r2}, ignore_index=True)\n",
    "\n",
    "# Ridge Regression with Hyperparameter Tuning\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "best_ridge = ridge_grid.best_estimator_\n",
    "ridge_pred_train = best_ridge.predict(X_train)\n",
    "ridge_pred_test = best_ridge.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_pred_train)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_pred_test)\n",
    "ridge_train_r2 = r2_score(y_train, ridge_pred_train)\n",
    "ridge_test_r2 = r2_score(y_test, ridge_pred_test)\n",
    "results_df = results_df.append({'Model': 'Ridge Regression', 'Train MSE': ridge_train_mse, 'Test MSE': ridge_test_mse, 'Train R2': ridge_train_r2, 'Test R2': ridge_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Ridge Regression: {ridge_grid.best_params_}\")\n",
    "\n",
    "# Lasso Regression with Hyperparameter Tuning\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "best_lasso = lasso_grid.best_estimator_\n",
    "lasso_pred_train = best_lasso.predict(X_train)\n",
    "lasso_pred_test = best_lasso.predict(X_test)\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pred_train)\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pred_test)\n",
    "lasso_train_r2 = r2_score(y_train, lasso_pred_train)\n",
    "lasso_test_r2 = r2_score(y_test, lasso_pred_test)\n",
    "results_df = results_df.append({'Model': 'Lasso Regression', 'Train MSE': lasso_train_mse, 'Test MSE': lasso_test_mse, 'Train R2': lasso_train_r2, 'Test R2': lasso_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Lasso Regression: {lasso_grid.best_params_}\")\n",
    "\n",
    "# Random Forest Regressor with Hyperparameter Tuning\n",
    "rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(), rf_params, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_pred_train = best_rf.predict(X_train)\n",
    "rf_pred_test = best_rf.predict(X_test)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pred_train)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Random Forest Regressor', 'Train MSE': rf_train_mse, 'Test MSE': rf_test_mse, 'Train R2': rf_train_r2, 'Test R2': rf_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Random Forest Regressor: {rf_grid.best_params_}\")\n",
    "\n",
    "# Gradient Boosting Regressor with Hyperparameter Tuning\n",
    "gb_params = {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(), gb_params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_pred_train = best_gb.predict(X_train)\n",
    "gb_pred_test = best_gb.predict(X_test)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pred_train)\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pred_test)\n",
    "gb_train_r2 = r2_score(y_train, gb_pred_train)\n",
    "gb_test_r2 = r2_score(y_test, gb_pred_test)\n",
    "gb_feature_importance = rf_model.feature_importances_\n",
    "results_df = results_df.append({'Model': 'Gradient Boosting Regressor', 'Train MSE': gb_train_mse, 'Test MSE': gb_test_mse, 'Train R2': gb_train_r2, 'Test R2': gb_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Gradient Boosting Regressor: {gb_grid.best_params_}\")\n",
    "\n",
    "# Decision Tree Regressor with Hyperparameter Tuning\n",
    "dt_params = {'max_depth': [None, 10, 20]}\n",
    "dt_grid = GridSearchCV(DecisionTreeRegressor(), dt_params, cv=5)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "dt_pred_train = best_dt.predict(X_train)\n",
    "dt_pred_test = best_dt.predict(X_test)\n",
    "dt_train_mse = mean_squared_error(y_train, dt_pred_train)\n",
    "dt_test_mse = mean_squared_error(y_test, dt_pred_test)\n",
    "dt_train_r2 = r2_score(y_train, dt_pred_train)\n",
    "dt_test_r2 = r2_score(y_test, dt_pred_test)\n",
    "results_df = results_df.append({'Model': 'Decision Tree Regressor', 'Train MSE': dt_train_mse, 'Test MSE': dt_test_mse, 'Train R2': dt_train_r2, 'Test R2': dt_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Decision Tree Regressor: {dt_grid.best_params_}\")\n",
    "\n",
    "# Bagging Regressor with Hyperparameter Tuning\n",
    "bag_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "bag_grid = GridSearchCV(BaggingRegressor(random_state=42), bag_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "bag_grid.fit(X_train, y_train)\n",
    "bag_best = bag_grid.best_estimator_\n",
    "\n",
    "# Using the best estimator from GridSearch to make predictions\n",
    "bag_pred_train = bag_best.predict(X_train)\n",
    "bag_pred_test = bag_best.predict(X_test)\n",
    "bag_train_mse = mean_squared_error(y_train, bag_pred_train)\n",
    "bag_test_mse = mean_squared_error(y_test, bag_pred_test)\n",
    "bag_train_r2 = r2_score(y_train, bag_pred_train)\n",
    "bag_test_r2 = r2_score(y_test, bag_pred_test)\n",
    "results_df = results_df.append({'Model': 'Bagging Regressor', 'Train MSE': bag_train_mse, 'Test MSE': bag_test_mse, 'Train R2': bag_train_r2, 'Test R2': bag_test_r2}, ignore_index=True)\n",
    "print(f\"Best parameters for Bagging Regressor: {bag_grid.best_params_}\")\n",
    "\n",
    "# AdaBoost Regressor with Hyperparameter Tuning\n",
    "ada_model = AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "ada_grid = GridSearchCV(AdaBoostRegressor(random_state=42), ada_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ada_model.fit(X_train, y_train)\n",
    "#ada_best = ada_grid.best_estimator_\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "#ada_pred_train = best_ada.predict(X_train)\n",
    "#ada_pred_test = best_ada.predict(X_test)\n",
    "\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pred_train)\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pred_test)\n",
    "ada_train_r2 = r2_score(y_train, ada_pred_train)\n",
    "ada_test_r2 = r2_score(y_test, ada_pred_test)\n",
    "results_df = results_df.append({'Model': 'AdaBoost Regressor', 'Train MSE': ada_train_mse, 'Test MSE': ada_test_mse, 'Train R2': ada_train_r2, 'Test R2': ada_test_r2}, ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results_df)\n",
    "# Print the results DataFrame in tabulated form\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22 TUN results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12b9e0-85ac-4627-99ba-da44d2b96d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "def plot_predictions(models, actual, predictions, model_names):\n",
    "    fig, ax = plt.subplots(len(models), 2, figsize=(15, 5*len(models)))\n",
    "    \n",
    "    for i, (model, pred, name) in enumerate(zip(models, predictions, model_names)):\n",
    "        # Scatter plot of predicted vs actual\n",
    "        ax[i][0].scatter(actual, pred, alpha=0.5)\n",
    "        ax[i][0].plot([min(actual), max(actual)], [min(actual), max(actual)], '--', lw=2, color='red')\n",
    "        ax[i][0].set_title(f'{name} Predicted vs Actual')\n",
    "        ax[i][0].set_xlabel('Actual')\n",
    "        ax[i][0].set_ylabel('Predicted')\n",
    "\n",
    "        # Residuals plot\n",
    "        residuals = actual - pred\n",
    "        ax[i][1].scatter(pred, residuals, alpha=0.5)\n",
    "        ax[i][1].hlines(0, min(pred), max(pred), colors='red', linestyles='--', lw=2)\n",
    "        ax[i][1].set_title(f'{name} Residuals Plot')\n",
    "        ax[i][1].set_xlabel('Predicted')\n",
    "        ax[i][1].set_ylabel('Residuals')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Collecting models and their predictions\n",
    "models_list = [best_gb, best_rf, best_dt]\n",
    "predictions_list = [dt_pred_test,gb_pred_test,rf_pred_test]\n",
    "model_names = ['Gradient Boosting Regressor', 'Decision Tree Regressor','Random Forest']\n",
    "\n",
    "# Plotting\n",
    "plot_predictions(models_list, y_test, predictions_list, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f084a9-4d0e-4bde-a378-b69ef1f12cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df1)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "# Define features and target\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "# Initialize k-fold cross-validator\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=1.0),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    BaggingRegressor(n_estimators=100, random_state=42),\n",
    "    AdaBoostRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Iterate through each model and perform k-fold cross-validation\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    train_mse_list = []\n",
    "    test_mse_list = []\n",
    "    train_r2_list = []\n",
    "    test_r2_list = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        train_mse_list.append(train_mse)\n",
    "        test_mse_list.append(test_mse)\n",
    "        train_r2_list.append(train_r2)\n",
    "        test_r2_list.append(test_r2)\n",
    "    \n",
    "    mean_train_mse = sum(train_mse_list) / num_folds\n",
    "    mean_test_mse = sum(test_mse_list) / num_folds\n",
    "    mean_train_r2 = sum(train_r2_list) / num_folds\n",
    "    mean_test_r2 = sum(test_r2_list) / num_folds\n",
    "    \n",
    "    results_df = results_df.append({'Model': model_name, 'Train MSE': mean_train_mse, 'Test MSE': mean_test_mse,\n",
    "                                    'Train R2': mean_train_r2, 'Test R2': mean_test_r2}, ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22MT AGITkfold_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fd160-eb65-40c4-9d5f-c872fd7d0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you've loaded 'ProductionTank22_df2' somewhere in your code\n",
    "df = pd.DataFrame(ProductionTank22_df1)\n",
    "\n",
    "#X = df.drop(['Phase_overrun'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "# Define features and target\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2', 'CV MSE Mean', 'CV MSE Std'])\n",
    "\n",
    "# Function to perform model training, prediction and storing results\n",
    "def evaluate_model(model, name):\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    pred_train = model.predict(X_train_scaled)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results_df.loc[name] = [name, train_mse, test_mse, train_r2, test_r2, cv_mean, cv_std]\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "evaluate_model(knn_model, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVR(kernel='rbf')\n",
    "evaluate_model(svm_model, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('knn_svm_results.xlsx', index=False)\n",
    "\n",
    "def hypertune_model(model, params, name):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    evaluate_model(best_model, name)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "hypertune_model(KNeighborsRegressor(), knn_params, 'K-Nearest Neighbors')\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['rbf', 'linear', 'poly'],\n",
    "    'degree': [2, 3],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "hypertune_model(SVR(), svm_params, 'Support Vector Machine')\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "results_df.to_excel('22MT AGITIknn_svm_results_hyper_tuned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889f7b6-acfe-4d3f-ac8d-454b30c26660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df1)\n",
    "\n",
    "# Define features and target\n",
    "#X = df.drop(['Phase_overrun', 'Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "#y = df['Phase_overrun']\n",
    "\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate','Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Simple Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "#results_df.to_excel('ag22Simple Neural Network.xlsx', index=False)\n",
    "\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Assuming X_train_scaled and X_test_scaled are already prepared\n",
    "\n",
    "# Reshape input data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define LSTM model\n",
    "def build_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the LSTM\n",
    "lstm = build_lstm()\n",
    "lstm.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_lstm = lstm.predict(X_train_reshaped)\n",
    "pred_test_lstm = lstm.predict(X_test_reshaped)\n",
    "train_mse_lstm = mean_squared_error(y_train, pred_train_lstm)\n",
    "test_mse_lstm = mean_squared_error(y_test, pred_test_lstm)\n",
    "train_r2_lstm = r2_score(y_train, pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, pred_test_lstm)\n",
    "results_df = results_df.append({'Model': 'LSTM Neural Network', 'Train MSE': train_mse_lstm,\n",
    "                                'Test MSE': test_mse_lstm, 'Train R2': train_r2_lstm, 'Test R2': test_r2_lstm},\n",
    "                               ignore_index=True)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "results_df.to_excel('22MTAGILSTMSNN Neural Network.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27023951-254d-4491-93a3-72df8845c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ... [your data loading, preprocessing, etc.]\n",
    "\n",
    "# Define a parameter grid to search through\n",
    "param_grid = {\n",
    "    'dense1_neurons': [32, 64, 128],\n",
    "    'dense2_neurons': [16, 32, 64],\n",
    "    'epochs': [30, 50],\n",
    "    'batch_size': [16, 32, 64],\n",
    "}\n",
    "\n",
    "# Adjust the function to take the hyperparameters as parameters\n",
    "def build_simple_nn(dense1_neurons=64, dense2_neurons=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense1_neurons, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(dense2_neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasRegressor\n",
    "simple_nn_model = KerasRegressor(build_fn=build_simple_nn, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "simple_nn_search = GridSearchCV(estimator=simple_nn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds = simple_nn_search.best_estimator_.predict(X_train_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds = simple_nn_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Training R^2:\", train_r2)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test R^2:\", test_r2)\n",
    "\n",
    "# Here, you can use simple_nn_search_result.best_estimator_ to make predictions and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271adab4-cc99-4c54-8fce-8be3b9184c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the LSTM model for grid search\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Grid search hyperparameters\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = GridSearchCV(estimator=lstm_model, param_grid=lstm_param_grid, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "\n",
    "# Predict using the best model on training data\n",
    "train_preds_lstm = lstm_search_result.best_estimator_.predict(X_train_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the training data\n",
    "train_mse_lstm = mean_squared_error(y_train, train_preds_lstm)\n",
    "train_r2_lstm = r2_score(y_train, train_preds_lstm)\n",
    "\n",
    "# Predict using the best model on test data\n",
    "test_preds_lstm = lstm_search_result.best_estimator_.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the MSE and R2 for the test data\n",
    "test_mse_lstm = mean_squared_error(y_test, test_preds_lstm)\n",
    "test_r2_lstm = r2_score(y_test, test_preds_lstm)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training MSE for LSTM:\", train_mse_lstm)\n",
    "print(\"Training R^2 for LSTM:\", train_r2_lstm)\n",
    "print(\"Test MSE for LSTM:\", test_mse_lstm)\n",
    "print(\"Test R^2 for LSTM:\", test_r2_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ab188-8317-44a4-a226-cf4e3744fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U keras-tuner\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameters grid for Simple Neural Network\n",
    "def create_simple_nn(neurons_layer1=64, neurons_layer2=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "simple_nn_param_grid = {\n",
    "    'neurons_layer1': [32, 64, 128],\n",
    "    'neurons_layer2': [16, 32, 64],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "simple_nn_model = KerasRegressor(build_fn=create_simple_nn, verbose=0)\n",
    "simple_nn_search = RandomizedSearchCV(estimator=simple_nn_model, param_distributions=simple_nn_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "simple_nn_search_result = simple_nn_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display results for Simple NN\n",
    "simple_nn_results = pd.DataFrame(simple_nn_search_result.cv_results_)[['param_neurons_layer1', 'param_neurons_layer2', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(simple_nn_results, headers='keys', tablefmt='grid'))\n",
    "# Save results DataFrame to an Excel file\n",
    "simple_nn_results.to_excel('optsimple_nn.xlsx', index=False)\n",
    "print(\"Best Simple NN Params:\", simple_nn_search_result.best_params_)\n",
    "\n",
    "# Define hyperparameters grid for LSTM\n",
    "def create_lstm(lstm_neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_neurons, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "lstm_param_grid = {\n",
    "    'lstm_neurons': [30, 50, 70],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [30, 50, 100]\n",
    "}\n",
    "\n",
    "lstm_model = KerasRegressor(build_fn=create_lstm, verbose=0)\n",
    "lstm_search = RandomizedSearchCV(estimator=lstm_model, param_distributions=lstm_param_grid, n_iter=5, cv=3, verbose=1)\n",
    "lstm_search_result = lstm_search.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Display results for LSTM\n",
    "lstm_results = pd.DataFrame(lstm_search_result.cv_results_)[['param_lstm_neurons', 'param_batch_size', 'param_epochs', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "print(tabulate(lstm_results, headers='keys', tablefmt='grid'))\n",
    "print(\"Best LSTM Params:\", lstm_search_result.best_params_)\n",
    "# Save results DataFrame to an Excel file\n",
    "lstm_results.to_excel('ranAGLSTM_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564986f-9686-42c9-9894-29dbfb0a1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load your dataset (replace 'ProductionTank22_df2' with your actual dataset)\n",
    "df = pd.DataFrame(ProductionTank22_df1)\n",
    "\n",
    "# Define features and target\n",
    "# Define features and target\n",
    "# Define features and target\n",
    "X = df.drop(['Phase_overrun','Target_Flowrate', 'Target_Phase_duration'], axis=1)\n",
    "y = df['Phase_overrun']\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train MSE', 'Test MSE', 'Train R2', 'Test R2'])\n",
    "\n",
    "# Define a simple feedforward neural network\n",
    "def build_simple_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Train and evaluate the simple neural network\n",
    "simple_nn = build_simple_nn()\n",
    "simple_nn.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "pred_train_simple_nn = simple_nn.predict(X_train_scaled)\n",
    "pred_test_simple_nn = simple_nn.predict(X_test_scaled)\n",
    "train_mse_simple_nn = mean_squared_error(y_train, pred_train_simple_nn)\n",
    "test_mse_simple_nn = mean_squared_error(y_test, pred_test_simple_nn)\n",
    "train_r2_simple_nn = r2_score(y_train, pred_train_simple_nn)\n",
    "test_r2_simple_nn = r2_score(y_test, pred_test_simple_nn)\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network', 'Train MSE': train_mse_simple_nn,\n",
    "                                'Test MSE': test_mse_simple_nn, 'Train R2': train_r2_simple_nn, 'Test R2': test_r2_simple_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save results DataFrame to an Excel file\n",
    "results_df.to_excel('22agddneural_network_results1.xlsx', index=False)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def create_model(neurons_layer1=128, neurons_layer2=64, neurons_layer3=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_layer1, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(Dense(neurons_layer2, activation='relu'))\n",
    "    model.add(Dense(neurons_layer3, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [20, 50, 100],\n",
    "    'neurons_layer1': [64, 128, 256],\n",
    "    'neurons_layer2': [32, 64, 128],\n",
    "    'neurons_layer3': [16, 32, 64]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3)\n",
    "random_search_result = random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Score: \", random_search_result.best_score_)\n",
    "print(\"Best Params: \", random_search_result.best_params_)\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "#Remember that the parameters given above are just examples; you can expand or restrict the grid as per your computational capability and needs. Also, depending on the number of combinations and the size of your data, this can take a significant amount of time to run.\n",
    "\n",
    "\n",
    "best_nn = random_search_result.best_estimator_.model\n",
    "pred_train_best_nn = best_nn.predict(X_train_scaled)\n",
    "pred_test_best_nn = best_nn.predict(X_test_scaled)\n",
    "\n",
    "train_mse_best_nn = mean_squared_error(y_train, pred_train_best_nn)\n",
    "test_mse_best_nn = mean_squared_error(y_test, pred_test_best_nn)\n",
    "train_r2_best_nn = r2_score(y_train, pred_train_best_nn)\n",
    "test_r2_best_nn = r2_score(y_test, pred_test_best_nn)\n",
    "\n",
    "results_df = results_df.append({'Model': 'Dense Neural Network (Optimized)', 'Train MSE': train_mse_best_nn,\n",
    "                                'Test MSE': test_mse_best_nn, 'Train R2': train_r2_best_nn, 'Test R2': test_r2_best_nn},\n",
    "                               ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "results_df.to_excel('22MTAGdenseNNopt_results.xlsx', index=False)\n",
    "print(tabulate(results_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873204c-1e04-470f-817a-3aeb66134ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
